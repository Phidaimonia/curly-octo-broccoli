{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtKotjXjVJRV"
   },
   "source": [
    "Based on tensorflow starter code from https://www.kaggle.com/alexozerin/end-to-end-baseline-tf-estimator-lb-0-72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iofpintREkxd",
    "outputId": "96aa3a6f-e9e7-4bae-ba24-52ab07223e11"
   },
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "#%pip install keras_tqdm\n",
    "#%pip install tensorflow-addons\n",
    "#%pip install tensorflow-io\n",
    "#%pip install numba\n",
    "#%pip install tqdm\n",
    "#%pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zch7gOTgVJRd",
    "outputId": "1c69f19a-22d7-4337-a132-7ed42b097edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8281443102595769706\n",
      "xla_global_id: -1\n",
      "]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import array \n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Conv2D, Flatten, MaxPooling2D, Conv1D, MaxPooling1D, Add, Concatenate, LocallyConnected1D\n",
    "from keras.layers import Activation, BatchNormalization, GlobalMaxPooling1D, GlobalMaxPool2D, GlobalAveragePooling1D\n",
    "from keras.layers import Dense, Dropout, Reshape, LSTM, Layer, LayerNormalization, InputLayer, Permute, GRU, Cropping1D\n",
    "from keras.layers import TimeDistributed, Conv2DTranspose, UpSampling2D, MultiHeadAttention, Embedding, Rescaling, Masking\n",
    "from keras.layers import ZeroPadding1D, ZeroPadding2D, GaussianNoise, DepthwiseConv2D, Cropping2D, RepeatVector, RNN, AveragePooling2D\n",
    "from keras.layers import Conv1DTranspose, GlobalMaxPooling1D, DepthwiseConv1D\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.constraints import max_norm\n",
    "from keras import activations, losses\n",
    "\n",
    "import fast_attention\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.optimizers import LAMB \n",
    "import tensorflow_io as tfio\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from numba import jit, njit, prange\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "\n",
    "\n",
    "from random import *\n",
    "import math\n",
    "\n",
    "\n",
    "#from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TerminateOnNaN\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc as gc\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "projDir = ''\n",
    "\n",
    "\n",
    "model_dtype = \"float32\"\n",
    "\n",
    "K.set_floatx(model_dtype)\n",
    "K.set_epsilon(1e-6)\n",
    "tf.keras.mixed_precision.experimental.set_policy(model_dtype)\n",
    "\n",
    "tf.config.run_functions_eagerly(False)\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "DEVICE = \"/device:CPU:0\"\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded candles: (5679762, 3)\n",
      "M15 candles: (378650, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load all\n",
    "\n",
    "\n",
    "candles = pd.read_csv(\"history.csv\")\n",
    "candles = candles.to_numpy()\n",
    "candles = fixGaps(candles)\n",
    "print(\"Loaded candles:\", candles.shape)     # [high, low, time]\n",
    "\n",
    "M15_candles = convertToM15(candles)\n",
    "M15_candles = tf.convert_to_tensor(M15_candles, dtype=tf.float32)\n",
    "print(\"M15 candles:\", M15_candles.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.00574257225\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Candles -> points\n",
    "\n",
    "@jit(nopython=True, parallel=False)\n",
    "def candlesToPoints(candles, ds_size=-1):\n",
    "\n",
    "    point_sequence = candles[:ds_size, 0:2].flatten()                           # create HLHLHL... sequence                              \n",
    "    \n",
    "    mask = np.ones(point_sequence.shape, np.bool8)\n",
    "    \n",
    "    for i in prange(len(point_sequence)-1):                                     # remove double H/Ls using mask\n",
    "        if point_sequence[i] == point_sequence[i+1]:\n",
    "            mask[i] = False\n",
    "            \n",
    "    point_sequence = point_sequence[mask]                                       # apply mask\n",
    "    mask = np.ones(point_sequence.shape, np.bool8)\n",
    "    \n",
    "    for i in prange(len(point_sequence)-3):                                     # remove double moves\n",
    "        if not mask[i]:\n",
    "            continue\n",
    "        \n",
    "        if (point_sequence[i] == point_sequence[i+2]) and (point_sequence[i+1] == point_sequence[i+3]):\n",
    "            mask[i] = False\n",
    "            mask[i+1] = False\n",
    "            \n",
    "    return point_sequence[mask] \n",
    "    \n",
    "\n",
    "def fixGaps(candles):\n",
    "  \n",
    "    candle_count = candles.shape[-1]\n",
    "    \n",
    "    for i in range(candle_count-1):\n",
    "        c1, c2 = candles[i], candles[i+1]\n",
    "        \n",
    "        if c2[1] < c1[0]:                       # second candle high is lower than first candle low\n",
    "            candles[i+1, 1] = c1[0]             # fill the gap\n",
    "            \n",
    "        if c2[0] > c1[1]:                       # second candle low is higher than first candle high\n",
    "            candles[i+1, 0] = c1[1]\n",
    "    \n",
    "    return candles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# M1 Candles -> M15 candles\n",
    "def convertToM15(candles):\n",
    "    TF = 15\n",
    "    candles_count = candles.shape[0] // TF      \n",
    "\n",
    "    tmp = candles[:candles_count*TF]\n",
    "    \n",
    "    tmp = np.reshape(tmp, newshape=[candles_count, TF, candles.shape[1]])[:, :, :2]     # split into 15m intervals  (N,15,2)\n",
    "    tmp = np.reshape(tmp, newshape=[candles_count, TF * 2]) # flatten last two axes to (N, 30), this contains both highs and lows\n",
    "\n",
    "    lows = np.amin(tmp, axis=-1, keepdims=True)             \n",
    "    highs = np.amax(tmp, axis=-1, keepdims=True)\n",
    "\n",
    "    return np.concatenate((lows, highs), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)      # Positional encoding\n",
    "def int2vec(num, maxNum, dim):\n",
    "    \n",
    "    x = tf.cast(num / maxNum * 3.14159265358, dtype=tf.float32)   # 0...2PI\n",
    "    \n",
    "    w = tf.range(dim, delta=1, dtype=tf.float32)\n",
    "    w = tf.math.pow(2.0, w)                         # 1, 2, 4, 8...\n",
    "    \n",
    "    return tf.concat([tf.math.sin(x * w), tf.math.cos(x * w)], 0)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def vec2emb(seq, emb_dim=8):\n",
    "    sequence_length = tf.shape(seq)[0]\n",
    "    seq = tf.reshape(seq, [-1])\n",
    "    \n",
    "    x = tf.cast(seq * 3.14159265358, dtype=tf.float32)   # 0...2PI\n",
    "    \n",
    "    w = tf.range(emb_dim, delta=1, dtype=tf.float32)\n",
    "    w = tf.math.pow(2.0, w)                         # 1, 2, 4, 8...\n",
    "    \n",
    "    w = tf.expand_dims(w, axis=0)\n",
    "    w = tf.tile(w, multiples=(tf.shape(x)[0], 1)) \n",
    "\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    x = tf.tile(x, multiples=(1, emb_dim)) \n",
    "\n",
    "    seq = tf.concat([tf.math.sin(x * w), tf.math.cos(x * w)], 1)\n",
    "    \n",
    "    seq = tf.reshape(seq, [sequence_length, -1])\n",
    "    return seq\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)      # Positional encoding 2\n",
    "def int2bin(inp: tf.Tensor, maxInp: tf.float32, N: tf.int32):\n",
    "\n",
    "    inp = tf.cast(inp, dtype=tf.float32) \n",
    "    maxInp = tf.cast(maxInp, dtype=tf.float32) \n",
    "\n",
    "    x = tf.cast(inp / maxInp * tf.math.pow(2.0, N), dtype=tf.int32)   \n",
    "    \n",
    "    x_bin = tf.math.floormod(tf.bitwise.right_shift(x, tf.range(N)), 2)\n",
    "                               \n",
    "    return tf.reverse(x_bin, axis=[0])    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)      # Positional encoding 2\n",
    "def int2binVec(inp: tf.Tensor, maxInp: tf.float32, N: tf.int32):\n",
    "\n",
    "    sequence_length = tf.shape(inp)[0]\n",
    "    \n",
    "    inp = tf.cast(inp, dtype=tf.float32) \n",
    "    maxInp = tf.cast(maxInp, dtype=tf.float32) \n",
    "    \n",
    "    x = tf.cast(inp / maxInp * tf.math.pow(2.0, N-1), dtype=tf.int32)   # normalize to integers 0-255 for N=8 \n",
    "\n",
    "    expanded_range = tf.reshape(tf.range(N), [1, N])\n",
    "    expanded_range = tf.tile(expanded_range, (sequence_length, 1))      \n",
    "    \n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    \n",
    "    shifted = tf.bitwise.right_shift(x, expanded_range)\n",
    "    x_bin = tf.math.floormod(shifted, 2)\n",
    "    \n",
    "    return tf.reverse(x_bin, axis=[1])      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#@tf.function(jit_compile=False)\n",
    "def relativePosition(seq, emb_dim=8):\n",
    "    \n",
    "    sequence_length = tf.shape(seq)[0]\n",
    "    seq = tf.reshape(seq, [-1])\n",
    "    \n",
    "\n",
    "    pos_indices = tf.range(sequence_length * 2, delta=1, dtype=tf.int32)\n",
    "    price_indices = tf.argsort(seq, axis=-1)\n",
    "    \n",
    "    #print(\"Position indexes\", pos_indices)\n",
    "    #print(\"Sorted indices shape\", tf.shape(price_indices))\n",
    "\n",
    "    #print(\"Seq len\", sequence_length)\n",
    "    \n",
    "    pos_emb = int2binVec(pos_indices, sequence_length, emb_dim)\n",
    "    price_emb = int2binVec(price_indices, sequence_length, emb_dim)\n",
    "    \n",
    "    #HL_emb = tf.expand_dims(tf.math.mod(pos_indices, 2), axis=-1)    # every second index is a H\n",
    "    \n",
    "    #seq = tf.concat([pos_emb, price_emb, HL_emb], 1)\n",
    "    seq = tf.concat([pos_emb, price_emb], 1)\n",
    "    \n",
    "    #seq = tf.reshape(seq, [sequence_length, -1])\n",
    "    return seq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#@tf.function(jit_compile=False) # random sequencing doesn't work with JIT\n",
    "def get_random_seq(samples : tf.Tensor) -> tf.Tensor:       \n",
    "\n",
    "    dataset_size = tf.shape(samples)[0]\n",
    "    sequence_length = 128\n",
    "    embedding_size = 8      # bits required to encode every index - log(sequence length * 2)\n",
    "\n",
    "    i = tf.random.uniform([], minval=0, maxval=dataset_size - sequence_length * 2 - 1, dtype=tf.int32)\n",
    "     \n",
    "    seq = samples[i:(i+sequence_length)]\n",
    "    \n",
    "    min_val = tf.math.reduce_min(seq)\n",
    "    max_val = tf.math.reduce_max(seq)\n",
    "    \n",
    "    seq = (seq - min_val) / (max_val - min_val + 1e-6)\n",
    "    \n",
    "    #flip = tf.random.uniform([], 1, dtype=tf.bool)\n",
    "    \n",
    "    #seq = \n",
    "    \n",
    "    seq = relativePosition(seq, embedding_size)\n",
    "    \n",
    "    seq = tf.cast(seq, dtype=tf.float32) \n",
    "\n",
    "    return seq      # output dim - (sequence_length*2, embedding_size*2+1)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def check_reaction(PA : tf.Tensor, entry : tf.float32, stop : tf.float32):          # exception for unnormalized PA\n",
    "    \"\"\"\n",
    "    PA - normalized to 0-1\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    entry_size = tf.abs(entry-stop)\n",
    "    tg = entry + entry_size     # only for longs\n",
    "    \n",
    "    points = tf.reshape(PA, [-1])\n",
    "\n",
    "\n",
    "    if tf.reduce_min(PA[0]) < entry:           # longs - wrong levels\n",
    "        return tf.constant([0.0])\n",
    "    \n",
    "    \n",
    "    if tf.reduce_min(PA) > entry:           # entry level is below the whole PA\n",
    "        return tf.constant([0.0])\n",
    "    \n",
    "    beyond_entry = tf.less(points, entry)\n",
    "    beyond_stop = tf.less(points, stop)\n",
    "    beyond_target = tf.greater(points, tg)\n",
    "\n",
    "   \n",
    "    entry_index = tf.reduce_min(tf.where(beyond_entry))\n",
    "    stop_index = tf.reduce_min(tf.where(beyond_stop))\n",
    "    \n",
    "    \n",
    "    if entry_index < 0:\n",
    "        return tf.constant([0.0])                                # entry not hit -> return\n",
    "    \n",
    "    if stop_index < 0:\n",
    "        stop_index = tf.cast(tf.shape(points)[0], tf.int64)    #tf.constant(tf.shape(points)[0], dtype=tf.int64)       # stop not hit, now check if target got hit\n",
    " \n",
    "    \n",
    "    target_index = tf.reduce_min(tf.where(beyond_target[entry_index:])) + entry_index    # we have to zero out the PA that happened before entry was hit (entry_index). Because target can get hit before entry has been\n",
    "    \n",
    "    \n",
    "    if target_index < 0:\n",
    "        target_index = tf.cast(tf.shape(points)[0], tf.int64)     # target not hit\n",
    "        \n",
    "        \n",
    "    if abs(target_index-stop_index) < 2:\n",
    "        return tf.constant([0.0])     # neither got hit -> filled, but not reached TG yet -> return 0\n",
    "    \n",
    "    #if abs(target_index-entry_index) < 2:\n",
    "    #    return [seq, price_vector, 0.0]     # entry and TG hit inside same candle -> can't tell which was hit first\n",
    "    \n",
    "    \n",
    "    if target_index < stop_index:\n",
    "        return tf.constant([1.0])     # TG hit first\n",
    "    else:\n",
    "        return tf.constant([0.0])    # stop hit first\n",
    "    \n",
    "\n",
    "    \n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def get_random_trade(samples : tf.Tensor):      \n",
    "    \n",
    "    dataset_size = tf.shape(samples)[0]\n",
    "    sequence_length = 256\n",
    "    look_ahead_length = 512     # how far in future to look for reaction\n",
    "\n",
    "    i = tf.random.uniform([], minval=0, maxval=dataset_size - sequence_length * 3 - 1, dtype=tf.int32)\n",
    "     \n",
    "    \n",
    "    PA = samples[i:(i+sequence_length)]\n",
    "    future_PA = samples[(i+sequence_length):(i+sequence_length+look_ahead_length)]\n",
    "    \n",
    "    min_val = tf.math.reduce_min(PA)\n",
    "    max_val = tf.math.reduce_max(PA)\n",
    "    \n",
    "    PA = (PA - min_val) / (max_val - min_val + 1e-6)                      # normalizujeme PA a Future_PA do stejnych souradnic\n",
    "    future_PA = (future_PA - min_val) / (max_val - min_val + 1e-6)\n",
    "    \n",
    "    \n",
    "    min_stop_size = 0.05\n",
    "    max_stop_size = 0.2\n",
    "    \n",
    "    \n",
    "    chart_start_price = tf.reduce_min(PA[-1])  # minimum posledni svice ze sekvence\n",
    "    \n",
    "    if chart_start_price < 0.5:         # pokud je konec PA (nebo zacatek future_PA) moc blizko k dolni mezi, pak invertujeme svice\n",
    "        PA = -1.0 * PA + 1.0\n",
    "        future_PA = -1.0 * future_PA + 1.0\n",
    "        chart_start_price = tf.reduce_min(future_PA[0]) \n",
    "        #tf.print(\"Inverted!\")\n",
    "    \n",
    "    \n",
    "\n",
    "    entry_size = tf.random.uniform([], minval=min_stop_size, maxval=max_stop_size, dtype=tf.float32) * chart_start_price\n",
    "    entry = tf.random.uniform([], minval=entry_size, maxval=chart_start_price-entry_size, dtype=tf.float32)   # rezerva pro stop a target\n",
    "    \n",
    "    stop = entry - entry_size    \n",
    "     \n",
    "    res = check_reaction(future_PA, entry=entry, stop=stop)\n",
    "    \n",
    "    #tf.print(tf.shape(PA))\n",
    "    \n",
    "    return PA, future_PA, res, tf.stack([entry, stop])\n",
    "\n",
    "\n",
    "########################################3\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=False) # random sequencing doesn't work with JIT\n",
    "def get_random_seq_diffusion(samples : tf.Tensor) -> tf.Tensor:       \n",
    "\n",
    "    dataset_size = tf.shape(samples)[0]\n",
    "    sequence_length = 128\n",
    "    max_steps = 200\n",
    "    std_mod = 0.01\n",
    "\n",
    "    i = tf.random.uniform([], minval=0, maxval=dataset_size - sequence_length - 1, dtype=tf.int32)\n",
    "    seq = samples[i:(i+sequence_length)]\n",
    "    \n",
    "    min_val = tf.math.reduce_min(seq)\n",
    "    max_val = tf.math.reduce_max(seq)\n",
    "    \n",
    "    seq = (seq - min_val) / (max_val - min_val + 1e-6)\n",
    "    \n",
    "    no_embed_seq = seq\n",
    "    \n",
    "    #seq = (seq - tf.reduce_mean(seq)) / tf.math.reduce_std(seq)\n",
    "    \n",
    "    #seq = vec2emb(seq, emb_dim=8)\n",
    "    #tf.print(tf.shape(seq))\n",
    "    #### otput: (sequence_length*2, emb_dim*2)\n",
    "    \n",
    "    \n",
    "    #seq = (seq - tf.reduce_mean(seq)) / tf.math.reduce_std(seq)\n",
    "    \n",
    "    step = tf.cast(tf.random.uniform([], minval=1, maxval=max_steps, dtype=tf.int32), tf.float32)\n",
    "    \n",
    "    #step = 199.0\n",
    "    \n",
    "    alpha_t = 1.0\n",
    "    for i in tf.range(step):\n",
    "        alpha_t *= 1.0 - i / tf.cast(max_steps, tf.float32) * std_mod\n",
    "    \n",
    "    noise = tf.random.normal(tf.shape(seq), mean=0.0, stddev = 1.0, dtype=tf.float32)\n",
    "    \n",
    "    X = tf.sqrt(alpha_t) * seq + tf.sqrt(1.0 - alpha_t) * noise\n",
    "    \n",
    "    #min_val = tf.math.reduce_min(X)\n",
    "    #max_val = tf.math.reduce_max(X)\n",
    "    #X = (X - min_val) / (max_val - min_val + 1e-6) * 2.0 - 1.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    #X = (X - tf.reduce_mean(X)) / tf.math.reduce_std(X)\n",
    "    #X = tf.clip_by_value(X, -8.0, 8.0)\n",
    "    \n",
    "    \n",
    "    return X, noise, step, seq, no_embed_seq\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "tmp_PA = M15_candles[512:768]\n",
    "\n",
    "min_val = tf.math.reduce_min(tmp_PA)\n",
    "max_val = tf.math.reduce_max(tmp_PA) \n",
    "    \n",
    "tmp_PA = (tmp_PA - min_val) / (max_val - min_val + 1e-6)   \n",
    "\n",
    "entry = 0.095\n",
    "stop_size = 0.05\n",
    "\n",
    "\n",
    "#tmp = get_random_trade(M15_candles)  \n",
    "#tf.print(check_reaction(PA=tmp_PA, entry=entry, stop=entry-stop_size)) \n",
    "\n",
    "#x = 0.0\n",
    "\n",
    "#for i in range(1000):\n",
    "#    x += check_reaction(PA=tmp_PA, entry=entry, stop=entry-stop_size)\n",
    "\n",
    "\n",
    "#x, y, result, levels = get_random_trade(M15_candles)\n",
    "#tf.print(result, levels)\n",
    "#tf.print(x.shape)\n",
    "\n",
    "#entry = levels[0]\n",
    "#stop_size = entry - levels[1]\n",
    "\n",
    "get_random_seq_diffusion(M15_candles)\n",
    "\n",
    "\n",
    "#fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "#for i in range(x.shape[0]):\n",
    "#    plt.plot((i, i), (x[i, 0], x[i, 1]), color=\"blue\")\n",
    "#    plt.plot((i+x.shape[0], i+x.shape[0]), (y[i, 0], y[i, 1]), color=\"red\")\n",
    "\n",
    "\n",
    "#plt.plot((256, 511), (entry, entry), color=\"blue\")\n",
    "#plt.plot((256, 511), (entry-stop_size, entry-stop_size), color=\"red\")\n",
    "#plt.plot((256, 511), (entry+stop_size, entry+stop_size), color=\"green\")\n",
    "\n",
    "\n",
    "\n",
    "seq_augm, noise, step, orig, no_emb_seq = get_random_seq_diffusion(M15_candles)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(seq_augm.shape[0]):\n",
    "    plt.plot((i, i), (seq_augm[i, 0], seq_augm[i, 1]), color=\"blue\")\n",
    "    plt.plot((i, i), (orig[i, 0], orig[i, 1]), color=\"red\")\n",
    "    #plt.plot((i, i), (noise[i, 0], noise[i, 1]), color=\"black\")\n",
    "    #plt.plot((i, i), (seq_augm[i, 0] - noise[i, 0], seq_augm[i, 1] - noise[i, 1]), color=\"black\")\n",
    "    \n",
    "    \n",
    "#print(seq_augm[:10, 0])\n",
    "#print(noise[:10, 0])\n",
    "\n",
    "tf.print(step, tf.reduce_mean(noise))\n",
    "\n",
    "\n",
    "\n",
    "#x1 = get_random_seq(M15_candles)\n",
    "#print(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M15 dataset\n",
    "\n",
    "\n",
    "\n",
    "M15_data = tf.data.Dataset.from_tensor_slices([M15_candles])\n",
    "\n",
    "M15_data = (\n",
    "    M15_data.repeat()\n",
    "    .map(get_random_seq_diffusion, num_parallel_calls=16)       # get_random_seq_diffusion, get_random_trade\n",
    ")\n",
    "\n",
    "#M15_data = tf.data.Dataset.zip((M15_data, M15_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kTBJBicAVJRr"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "exp_name = \"test_price_AE\"\n",
    "\n",
    "                \n",
    "callbacks = [EarlyStopping(monitor='loss',\n",
    "                           patience=400,\n",
    "                           verbose=1,\n",
    "                           mode='min'),\n",
    "             ReduceLROnPlateau(monitor='loss',\n",
    "                               factor=0.1,\n",
    "                               patience=100,\n",
    "                               verbose=1,\n",
    "                               min_delta=0.00001,\n",
    "                               mode='min'),\n",
    "             TerminateOnNaN()]\n",
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir gdrive/Shareddrives/edu_VAD/Anton/VAD_project/logs,   TensorBoard(log_dir= projDir + './logs', histogram_freq=0, write_graph=True)\n",
    "\n",
    "#              ModelCheckpoint(monitor='accuracy',\n",
    "#                             filepath= projDir + 'weights/{}'.format(exp_name) + '_{epoch:04d}.hdf5',\n",
    "#                             save_best_only=False,\n",
    "#                             save_freq=50,      # every 5 epochs\n",
    "#                             save_weights_only=True,\n",
    "#                             mode='max')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SyQ9j9YjVJRs",
    "outputId": "4a2d8be7-57e7-458c-db4d-52f8db3cbf08"
   },
   "outputs": [],
   "source": [
    "# Architecture\n",
    "\n",
    "with tf.device(DEVICE):\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    \n",
    "    class TransformerBlock(Layer):\n",
    "        def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "            super(TransformerBlock, self).__init__()\n",
    "\n",
    "            self.num_heads = num_heads\n",
    "            self.embed_dim = embed_dim\n",
    "            self.ff_dim = ff_dim\n",
    "            self.dropout_rate = rate\n",
    "\n",
    "            self.att = fast_attention.Attention(num_heads=num_heads, hidden_size=embed_dim, attention_dropout=rate)\n",
    "            \n",
    "            self.ffn = Sequential(\n",
    "                [Dense(ff_dim, activation=\"ReLU\", kernel_constraint=max_norm(10.0), bias_constraint=max_norm(10.0)),        # LeakyReLU\n",
    "                 Dense(embed_dim, kernel_constraint=max_norm(10.0), bias_constraint=max_norm(10.0)),]\n",
    "            )\n",
    "            self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "            self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "            self.dropout1 = Dropout(rate)\n",
    "            self.dropout2 = Dropout(rate)\n",
    "\n",
    "        @tf.function(jit_compile=False, experimental_follow_type_hints=False)\n",
    "        def call(self, inputs, training=True):\n",
    "            attn_output = self.att(inputs, inputs, bias=None)\n",
    "            attn_output = self.dropout1(attn_output, training=training)\n",
    "            out1 = self.layernorm1(inputs + attn_output)                    # layernorm\n",
    "            ffn_output = self.ffn(out1)    \n",
    "            ffn_output = self.dropout2(ffn_output, training=training)\n",
    "            return self.layernorm2(inputs + out1 + ffn_output)     \n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(TransformerBlock, self).get_config()\n",
    "            cfg.update({'num_heads': self.num_heads,\n",
    "                        'embed_dim': self.embed_dim,\n",
    "                        'ff_dim': self.ff_dim,\n",
    "                          'dropout_rate': self.dropout_rate})\n",
    "            return cfg\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    class PositionEmbedding(Layer):\n",
    "        def __init__(self, maxlen, embed_dim):\n",
    "            super(PositionEmbedding, self).__init__()\n",
    "            self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "            self.maxlen = maxlen\n",
    "\n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, x):\n",
    "            #maxlen = tf.shape(x)[-1]\n",
    "            positions = tf.range(start=0, limit=self.maxlen, delta=1)\n",
    "            positions = self.pos_emb(positions)\n",
    "            return x + positions\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(PositionEmbedding, self).get_config()\n",
    "            cfg.update({'pos_emb': self.pos_emb,\n",
    "                        'maxlen': self.maxlen})\n",
    "            return cfg\n",
    "        \n",
    "        \n",
    "    \n",
    "    class InstanceNorm(Layer):\n",
    "        def __init__(self):\n",
    "            super(InstanceNorm, self).__init__()\n",
    "\n",
    "\n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, x):\n",
    "\n",
    "            return (x - tf.reduce_mean(x, axis=0)) / (tf.math.reduce_std(x, axis=0) + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def FFT_loss_1D(y_true, y_pred):\n",
    "            \n",
    "        spec1 = tf.signal.fft(tf.cast(y_true, dtype=tf.dtypes.complex64)) / (y_true.shape[-1] ** 0.5)\n",
    "        spec2 = tf.signal.fft(tf.cast(y_pred, dtype=tf.dtypes.complex64)) / (y_pred.shape[-1] ** 0.5)\n",
    "\n",
    "        return  tf.math.reduce_mean(tf.math.log(1.0 + tf.cast(tf.abs(spec1-spec2), dtype=tf.float32))) * 100 \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    class InvertedResidual1D(Layer):\n",
    "        def __init__(self, filters, strides, expansion_factor=2, trainable=True,\n",
    "                    name=None, **kwargs):\n",
    "            super(InvertedResidual1D, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "            self.filters = filters\n",
    "            self.strides = strides\n",
    "            self.expansion_factor = expansion_factor\t# allowed to be decimal value\n",
    "            self.act = tf.nn.leaky_relu  #tf.nn.leaky_relu\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            input_channels = int(input_shape[-1])\n",
    "            \n",
    "            l2_reg = 0.0\n",
    "            \n",
    "            self.ptwise_conv1 = Conv1D(filters=int(input_channels*self.expansion_factor), kernel_size=1, use_bias=True, \n",
    "                                       kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "        \n",
    "            self.dwise = DepthwiseConv1D(kernel_size=5, strides=self.strides, padding='same', use_bias=True, \n",
    "                                        kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "            \n",
    "            self.ptwise_conv2 = Conv1D(filters=self.filters, kernel_size=1, use_bias=True, \n",
    "                                       kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "\n",
    "            self.bn1 = LayerNormalization()\n",
    "            self.bn2 = LayerNormalization()\n",
    "            \n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, input_x):\n",
    "\n",
    "            x = self.ptwise_conv1(input_x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.act(x)\n",
    "\n",
    "            x = self.dwise(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.act(x)\n",
    "\n",
    "            x = self.ptwise_conv2(x)\n",
    "\n",
    "\n",
    "            if input_x.shape[1:] == x.shape[1:]:\n",
    "                x += input_x\n",
    "            return x\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(InvertedResidual1D, self).get_config()\n",
    "            cfg.update({'filters': self.filters,\n",
    "                        'strides': self.strides,\n",
    "                        'expansion_factor': self.expansion_factor})\n",
    "            return cfg\n",
    "        \n",
    "        \n",
    "        \n",
    "    class UNetBlock1D(Layer):\n",
    "        def __init__(self, filters, trainable=True,\n",
    "                    name=None, **kwargs):\n",
    "            super(UNetBlock1D, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "            self.filters = filters\n",
    "            #self.act = tf.nn.leaky_relu\n",
    "\n",
    "        def build(self, input_shape):\n",
    "                       \n",
    "            \n",
    "            self.residual = Conv1D(filters=int(self.filters), kernel_size=1, use_bias=True, \n",
    "                                       kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "            \n",
    "            self.conv1 = Conv1D(filters=self.filters, kernel_size=3, use_bias=True, padding=\"SAME\",\n",
    "                                       kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "            \n",
    "            self.conv2 = Conv1D(filters=self.filters, kernel_size=3, use_bias=True, padding=\"SAME\",\n",
    "                                       kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "            \n",
    "\n",
    "            self.norm1 = LayerNormalization()\n",
    "            self.norm2 = LayerNormalization()\n",
    "\n",
    "        def call(self, input_x):\n",
    "\n",
    "            x = self.norm1(input_x)\n",
    "            x = tf.nn.leaky_relu(x)\n",
    "            x = self.conv1(x)\n",
    "            \n",
    "            x = self.norm2(x)\n",
    "            x = tf.nn.leaky_relu(x)\n",
    "            x = self.conv2(x)\n",
    "            \n",
    "            if input_x.shape[1:-1] == x.shape[1:-1]:\n",
    "                x += self.residual(input_x)\n",
    "            \n",
    "            return x\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(UNetBlock1D, self).get_config()\n",
    "            cfg.update({'filters': self.filters})\n",
    "            return cfg\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class RandomMask(Layer):\n",
    "        def __init__(self, maxLen=64, masked_rate=0.75):\n",
    "            super(RandomMask, self).__init__()\n",
    "\n",
    "            self.maskedRate = masked_rate\n",
    "            self.rnd = tf.random.get_global_generator()\n",
    "            self.maxLen = maxLen\n",
    "            self.trainable = False\n",
    "\n",
    "        #@tf.function(jit_compile=False)\n",
    "        def call(self, inputs, training=None):\n",
    "            \n",
    "            batch_size = tf.shape(inputs)[-3]   # or 0 ?\n",
    "            mask = self.rnd.uniform(shape=(batch_size, self.maxLen,), minval=0.0, maxval=1.0, dtype=model_dtype)      # stateless_uniform\n",
    "            mask = tf.cast(tf.math.greater(mask, self.maskedRate), dtype=model_dtype) \n",
    "            \n",
    "            mask = tf.expand_dims(mask, axis=-1)\n",
    "            mask = tf.tile(mask, multiples=(1, 1, tf.shape(inputs)[-1]))        # expand the last dimension\n",
    "            \n",
    "            if training: \n",
    "                return tf.math.multiply(inputs, mask), mask\n",
    "            \n",
    "            return inputs, tf.ones(tf.shape(inputs))        # ones = no mask\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(RandomMask, self).get_config()\n",
    "            cfg.update({'maskedRate': self.maskedRate,\n",
    "                        'maxLen': self.maxLen})\n",
    "            return cfg\n",
    "        \n",
    "    \n",
    "    class RestoreUnmaskedTokens(Layer):\n",
    "        def __init__(self, maxLen=64):\n",
    "            super(RestoreUnmaskedTokens, self).__init__()\n",
    "\n",
    "            self.rnd = tf.random.get_global_generator()\n",
    "            self.maxLen = maxLen\n",
    "            self.trainable = False\n",
    "\n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, inputs, training=None):\n",
    "            \n",
    "            reconstructed, original, mask = inputs\n",
    "            \n",
    "            rec = tf.math.multiply(reconstructed, 1.0 - mask)\n",
    "            remain = tf.math.multiply(original, mask)\n",
    "            \n",
    "            if training: \n",
    "                return rec + remain\n",
    "            \n",
    "            return reconstructed\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(RestoreUnmaskedTokens, self).get_config()\n",
    "            cfg.update({'maxLen': self.maxLen})\n",
    "            return cfg\n",
    "        \n",
    "        \n",
    "    \n",
    "    class ConstantLayer(Layer):\n",
    "        def __init__(self, latent_len = 128, embed_dim = 64, trainable=True, name=None, **kwargs):\n",
    "            super(ConstantLayer, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "            self.latent_len = latent_len\n",
    "            self.embed_dim = embed_dim\n",
    "\n",
    "        def build(self, input_shape):\n",
    "\n",
    "            self.latent_array = self.add_weight(\n",
    "                shape=(self.latent_len, self.embed_dim),\n",
    "                initializer=\"random_normal\",\n",
    "                trainable=True,\n",
    "            )                           \n",
    "            \n",
    "            \n",
    "        def call(self, input_x):\n",
    "            bs = tf.shape(input_x)[0]\n",
    "            x = tf.expand_dims(self.latent_array, axis=0)\n",
    "            \n",
    "            return tf.tile(x, multiples=(bs, 1, 1))\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(ConstantLayer, self).get_config()\n",
    "            cfg.update({'latent_len': self.latent_len, \n",
    "                        'embed_dim': self.embed_dim})\n",
    "            return cfg\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_35 (InputLayer)          [(None, 128, 2)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 128, 32)      224         ['input_35[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 64, 32)       2080        ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " u_net_block1d_60 (UNetBlock1D)  (None, 64, 32)      7392        ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " u_net_block1d_61 (UNetBlock1D)  (None, 64, 32)      7392        ['u_net_block1d_60[0][0]']       \n",
      "                                                                                                  \n",
      " transformer_block_6 (Transform  (None, 64, 32)      12576       ['u_net_block1d_61[0][0]']       \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " transformer_block_7 (Transform  (None, 64, 32)      12576       ['transformer_block_6[0][0]']    \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 32, 32)       2080        ['transformer_block_7[0][0]']    \n",
      "                                                                                                  \n",
      " u_net_block1d_62 (UNetBlock1D)  (None, 32, 32)      7392        ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " u_net_block1d_63 (UNetBlock1D)  (None, 32, 32)      7392        ['u_net_block1d_62[0][0]']       \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)       (None, 1, 8)         1600        ['input_36[0][0]']               \n",
      "                                                                                                  \n",
      " transformer_block_8 (Transform  (None, 32, 32)      12576       ['u_net_block1d_63[0][0]']       \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " reshape_65 (Reshape)           (None, 8)            0           ['embedding_16[0][0]']           \n",
      "                                                                                                  \n",
      " transformer_block_9 (Transform  (None, 32, 32)      12576       ['transformer_block_8[0][0]']    \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " repeat_vector_8 (RepeatVector)  (None, 16, 8)       0           ['reshape_65[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 16, 32)       2080        ['transformer_block_9[0][0]']    \n",
      "                                                                                                  \n",
      " reshape_66 (Reshape)           (None, 16, 8)        0           ['repeat_vector_8[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 16, 40)       0           ['conv1d_7[0][0]',               \n",
      "                                                                  'reshape_66[0][0]']             \n",
      "                                                                                                  \n",
      " transformer_block_10 (Transfor  (None, 16, 40)      16968       ['concatenate_12[0][0]']         \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_11 (Transfor  (None, 16, 40)      16968       ['transformer_block_10[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_12 (Transfor  (None, 16, 40)      16968       ['transformer_block_11[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_13 (Transfor  (None, 16, 40)      16968       ['transformer_block_12[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_14 (Transfor  (None, 16, 40)      16968       ['transformer_block_13[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " conv1d_transpose (Conv1DTransp  (None, 32, 32)      2592        ['transformer_block_14[0][0]']   \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 32, 32)      0           ['conv1d_transpose[0][0]',       \n",
      " mbda)                                                            'transformer_block_9[0][0]']    \n",
      "                                                                                                  \n",
      " u_net_block1d_64 (UNetBlock1D)  (None, 32, 32)      7392        ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " u_net_block1d_65 (UNetBlock1D)  (None, 32, 32)      7392        ['u_net_block1d_64[0][0]']       \n",
      "                                                                                                  \n",
      " transformer_block_15 (Transfor  (None, 32, 32)      12576       ['u_net_block1d_65[0][0]']       \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_16 (Transfor  (None, 32, 32)      12576       ['transformer_block_15[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " conv1d_transpose_1 (Conv1DTran  (None, 64, 32)      2080        ['transformer_block_16[0][0]']   \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 64, 32)      0           ['conv1d_transpose_1[0][0]',     \n",
      " mbda)                                                            'transformer_block_7[0][0]']    \n",
      "                                                                                                  \n",
      " u_net_block1d_66 (UNetBlock1D)  (None, 64, 32)      7392        ['tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " u_net_block1d_67 (UNetBlock1D)  (None, 64, 32)      7392        ['u_net_block1d_66[0][0]']       \n",
      "                                                                                                  \n",
      " transformer_block_17 (Transfor  (None, 64, 32)      12576       ['u_net_block1d_67[0][0]']       \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_18 (Transfor  (None, 64, 32)      12576       ['transformer_block_17[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " conv1d_transpose_2 (Conv1DTran  (None, 128, 32)     2080        ['transformer_block_18[0][0]']   \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 128, 32)     0           ['conv1d_transpose_2[0][0]',     \n",
      " mbda)                                                            'conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dense_98 (Dense)               (None, 128, 64)      2112        ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " dense_99 (Dense)               (None, 128, 32)      2080        ['dense_98[0][0]']               \n",
      "                                                                                                  \n",
      " dense_100 (Dense)              (None, 128, 16)      528         ['dense_99[0][0]']               \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 128, 2)       34          ['dense_100[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_67 (Reshape)           (None, 128, 2)       0           ['dense_101[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 264,154\n",
      "Trainable params: 264,154\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################ encoder\n",
    "\n",
    "inp_dim = 2\n",
    "sequence_length = 128\n",
    "embed_dim = 64\n",
    "core_seq_len = 32\n",
    "repeat_count = 3\n",
    "\n",
    "patch_size = 3\n",
    "\n",
    "\n",
    "inp = Input(shape=[sequence_length, inp_dim])\n",
    "step = Input(shape=[1])\n",
    "\n",
    "\n",
    "x = inp    \n",
    "\n",
    "#x = Reshape([sequence_length // patch_factor, inp_dim * patch_factor])(x)\n",
    "\n",
    "y = Embedding(input_dim=200, output_dim=8)(step)\n",
    "y = Reshape([8])(y)\n",
    "y = RepeatVector(16)(y)\n",
    "y = Reshape([16, 8])(y)\n",
    "\n",
    "\n",
    "x128 = Conv1D(32, 3, activation=\"tanh\", padding=\"same\")(x)\n",
    "\n",
    "x64 = Conv1D(32, 2, strides=2, padding=\"same\")(x128)      # downsample\n",
    "\n",
    "x64 = UNetBlock1D(32)(x64)\n",
    "x64 = UNetBlock1D(32)(x64)\n",
    "x64 = TransformerBlock(32, 4, 128)(x64)\n",
    "x64 = TransformerBlock(32, 4, 128)(x64)\n",
    "\n",
    "x32 = Conv1D(32, 2, strides=2, padding=\"same\")(x64)      # downsample\n",
    "\n",
    "x32 = UNetBlock1D(32)(x32)\n",
    "x32 = UNetBlock1D(32)(x32)\n",
    "x32 = TransformerBlock(32, 4, 128)(x32)\n",
    "x32 = TransformerBlock(32, 4, 128)(x32)\n",
    "\n",
    "x16 = Conv1D(32, 2, strides=2, padding=\"same\")(x32)      # downsample\n",
    "\n",
    "x16 = Concatenate(axis=-1)([x16, y]) \n",
    "\n",
    "x16 = TransformerBlock(40, 4, 128)(x16)\n",
    "x16 = TransformerBlock(40, 4, 128)(x16)\n",
    "x16 = TransformerBlock(40, 4, 128)(x16)\n",
    "x16 = TransformerBlock(40, 4, 128)(x16)\n",
    "y16 = TransformerBlock(40, 4, 128)(x16)\n",
    "\n",
    "\n",
    "y32 = Conv1DTranspose(32, kernel_size=2, strides=2, padding=\"SAME\")(y16)        # upsample\n",
    "y32 = y32 + x32\n",
    "\n",
    "y32 = UNetBlock1D(32)(y32)\n",
    "y32 = UNetBlock1D(32)(y32)\n",
    "y32 = TransformerBlock(32, 4, 128)(y32)\n",
    "y32 = TransformerBlock(32, 4, 128)(y32)\n",
    "\n",
    "y64 = Conv1DTranspose(32, kernel_size=2, strides=2, padding=\"SAME\")(y32)        # upsample\n",
    "y64 = y64 + x64\n",
    "\n",
    "y64 = UNetBlock1D(32)(y64)\n",
    "y64 = UNetBlock1D(32)(y64)\n",
    "y64 = TransformerBlock(32, 4, 128)(y64)\n",
    "y64 = TransformerBlock(32, 4, 128)(y64)\n",
    "\n",
    "y128 = Conv1DTranspose(32, kernel_size=2, strides=2, padding=\"SAME\")(y64)        # upsample\n",
    "y128 = y128 + x128\n",
    "\n",
    "\n",
    "x = Dense(64, activation = 'tanh')(y128)\n",
    "x = Dense(32, activation = 'tanh')(x)\n",
    "x = Dense(16, activation = 'tanh')(x)\n",
    "x = Dense(inp_dim, activation = 'linear')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x = Dense(64, activation = 'LeakyReLU')(x)      # , kernel_regularizer=l2(l2_reg), bias_regularizer=l2(l2_reg)\n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)\n",
    "#x = Dense(32, activation = 'LeakyReLU')(x)\n",
    "\n",
    "#x = PositionEmbedding(sequence_length // patch_factor, 32)(x)\n",
    "#x = TransformerBlock(32, 12, 512)(x)\n",
    "\n",
    "#x = Concatenate(axis=2)([x, y]) \n",
    "\n",
    "#x = PositionEmbedding(sequence_length // patch_factor, 40)(x)\n",
    "#x = TransformerBlock(40, 12, 512)(x)\n",
    "\n",
    "#x = Conv2D(32, (1, 3), activation=\"LeakyReLU\", padding=\"same\")(x)\n",
    "\n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)         \n",
    "#x = Dense(64, activation = 'LeakyReLU')(x)\n",
    "#x = Dense(inp_dim * patch_factor, activation = 'linear')(x)\n",
    "\n",
    "#x = Reshape([sequence_length * inp_dim])(x)\n",
    "#x = LayerNormalization()(x)\n",
    "x = Reshape([sequence_length, inp_dim])(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x = RestoreUnmaskedTokens()([x, inp, mask])            \n",
    "#x = Concatenate(axis=2)([x, y]) \n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)         \n",
    "\n",
    "#x = LayerNormalization()(x)\n",
    "\n",
    "#x = GRU(16, return_sequences=False)(x)\n",
    "\n",
    "#x = PositionEmbedding(sequence_length, 16)(x)\n",
    "#x = MultiHeadAttention(num_heads=4, key_dim=16)(y, x)\n",
    "\n",
    "#x = GRU(16, return_sequences=True)(x)\n",
    "\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outp = x\n",
    "\n",
    "encoder = Model([inp, step], outp, name=\"encoder\")\n",
    "\n",
    "\n",
    "class GCLAMB(LAMB):\n",
    "    def get_gradients(self, loss, params):  # gradient centralization\n",
    "        grads = []\n",
    "        gradients = super().get_gradients()\n",
    "        for grad in gradients:\n",
    "            grad_len = len(grad.shape)\n",
    "            if grad_len > 1:\n",
    "                axis = list(range(grad_len - 1))\n",
    "                grad -= tf.reduce_mean(grad, axis=axis, keep_dims=True)\n",
    "            grads.append(grad)\n",
    "\n",
    "        return grads\n",
    "\n",
    "\n",
    "#SWA = tfa.optimizers.SWA\n",
    "opt = GCLAMB(learning_rate=0.001)\n",
    "\n",
    "\n",
    "\n",
    "#encoder.compile(optimizer=opt, loss=FFT_loss_1D, metrics=[tf.keras.metrics.MeanSquaredError(), FFT_loss_1D])     # tf.keras.losses.MSE\n",
    "#encoder.build(input_shape=[None, sequence_length, inp_dim])\n",
    "\n",
    "\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEModel(keras.Model):\n",
    "\n",
    "    def __init__(self, encoder):\n",
    "        super(AEModel, self).__init__()\n",
    "        self.model = encoder\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        #self.rmse = tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")\n",
    "        self.acc = tf.keras.metrics.Accuracy(name=\"Accuracy\")\n",
    "        self.prec = tf.keras.metrics.Precision(name=\"Precision\")\n",
    "        self.recall = tf.keras.metrics.Precision(name=\"Recall\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.acc, self.prec, self.recall]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def call(self, inp):\n",
    "        \n",
    "        pred = self.model(inp, training=False)\n",
    "        \n",
    "        return pred         \n",
    "    \n",
    "\n",
    "\n",
    "    def train_step(self, batch):\n",
    "\n",
    "        x, noise, step, seq, no_emb_seq = batch                            #self.aug(batch)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.model([x, step], training=True)\n",
    "            loss = self.loss(pred, noise)                       # prediting noise\n",
    "  \n",
    "\n",
    "        grads_model = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(grads_model, self.model.trainable_variables))\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        \n",
    "        return {\"loss\": self.loss_tracker.result(), \n",
    "                \"accuracy\": self.acc.result(), \n",
    "                \"precision\": self.prec.result(), \n",
    "                \"recall\": self.recall.result()}\n",
    "    \n",
    "\n",
    "model = AEModel(encoder)\n",
    "\n",
    "opt = GCLAMB(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.MeanAbsoluteError())     # \"binary_crossentropy\", tf.keras.losses.MSE, tf.keras.losses.MeanAbsoluteError(), FFT_loss_1D\n",
    "\n",
    "\n",
    "#model.build(input_shape=[None, sequence_length, inp_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor l in model.layers:\\n    print(lay.name, lay.output_shape)\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#x = InvertedResidual(64, (1, 1), expansion_factor=6)(x)\n",
    "#kernel_constraint=max_norm(2.0)\n",
    "#x = RestoreUnmaskedTokens()([x, mask_input, mask])\n",
    "#x = Conv2DTranspose(32, kernel_size=(3, inp_dim), strides=(2, 1), activation=\"LeakyReLU\", kernel_regularizer=l1(l1_reg), bias_regularizer=l1(l1_reg), padding=\"SAME\")(x)\n",
    "#x = Conv2D(32, (3, inp_dim), activation=\"LeakyReLU\", kernel_regularizer=l1(l1_reg), bias_regularizer=l1(l1_reg), padding=\"same\")(x)\n",
    "#x = Conv2DTranspose(1, kernel_size=1, strides=1, activation=\"linear\", padding=\"SAME\", dtype='float32')(x)\n",
    "#x = Cropping1D([0, predict_len])(x)\n",
    "#x = GlobalAveragePooling1D()(x)\n",
    "# Dense(32, activation = 'LeakyReLU', kernel_regularizer=l2(0.01))\n",
    "# Reshape([64, 129])\n",
    "# Conv1D(32, 9, activation='relu', input_shape=[129])\n",
    "# Dropout(p)\n",
    "# BatchNormalization()\n",
    "# Permute((2, 1), input_shape=(64, 129))\n",
    "# LSTM(64, return_sequences = True)\n",
    "# Flatten()\n",
    "# GRU(64, return_sequences = True)\n",
    "# Concatenate(axis=1)([x, y]) \n",
    "# Reshape([-1, 128])(inp)\n",
    "#x = Rescaling(scale=1.0/255.0)(x)\n",
    "#outp = tf.cast(x, tf.dtypes.float16) # Rescaling(scale=255.0)(x)\n",
    "#x = GaussianNoise(0.2)(x)\n",
    "#x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "#outp = Dense(len(POSSIBLE_LABELS), activation=\"softmax\")(x)\n",
    "#x = PositionEmbedding(timesteps, embed_dim)(x)\n",
    "#x = RandomMask(maxLen=timesteps, masked_rate=0.3)(x)\n",
    "#x = RepeatVector(28, input_shape=[30])(x)  # 28x vector\n",
    "#x = TimeDistributed(Dense(28, activation=\"sigmoid\"))(x)\n",
    "#x = ActivityRegularization(l1=1e-3)(x)\n",
    "#x = Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"SAME\", activation=\"selu\")\n",
    "\n",
    "#print(x.shape)\n",
    "\n",
    "\"\"\"\n",
    "for l in model.layers:\n",
    "    print(lay.name, lay.output_shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk5nmX20VJRt",
    "outputId": "e65aa96d-6b75-4add-e5ae-11f41151e1d1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "gc.collect()\n",
    "\n",
    "K.set_value(model.optimizer.learning_rate, 0.001)\n",
    "batch_size = 64\n",
    "\n",
    "try:\n",
    "    batched_DS = M15_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    hist = model.fit(batched_DS, callbacks=callbacks,\n",
    "                    batch_size = batch_size, epochs = 4000, steps_per_epoch = 50)  # initial_epoch , validation_data=(valX[:32], valX[:32])\n",
    "    \n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.title(\"Loss curve\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")\n",
    "\n",
    "\n",
    "# Constant -> MAE = 0.316-0.32 with large BS 2048\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model.save_weights(projDir + 'weights/test_2.hdf5')\n",
    "#model.save(projDir + 'models/' + exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "(1, 128, 2)\n",
      "Iter:  199 0.36849616486375764 0.012520887 -0.701701939 1.87777615 std: 0.385058641\n",
      "Iter:  198 0.3721995503901395 0.0124946581 -0.688367963 1.86034203 std: 0.380117148\n",
      "Iter:  197 0.37592116997287095 0.0124685662 -0.674874663 1.84284556 std: 0.375189334\n",
      "Iter:  196 0.37966082913989896 0.0124426093 -0.661571085 1.82563496 std: 0.370362908\n",
      "Iter:  195 0.38341832876176424 0.0124167893 -0.648260117 1.80861425 std: 0.365605026\n",
      "Iter:  194 0.38719346504596236 0.0123911053 -0.634972811 1.79177 std: 0.360921115\n",
      "Iter:  193 0.3909860295324269 0.0123655563 -0.621759236 1.77522278 std: 0.35632202\n",
      "Iter:  192 0.39479580909014683 0.0123401452 -0.608416498 1.75873852 std: 0.351775\n",
      "Iter:  191 0.39862258591493016 0.0123148691 -0.59527117 1.74258387 std: 0.347334862\n",
      "Iter:  190 0.40246613752832566 0.012289729 -0.58198 1.72656858 std: 0.342934281\n",
      "Iter:  189 0.4063262367777139 0.0122647267 -0.569022179 1.71098292 std: 0.338671595\n",
      "Iter:  188 0.410202651837579 0.0122398594 -0.555853546 1.69545388 std: 0.334445059\n",
      "Iter:  187 0.4140951462119715 0.0122151291 -0.542903066 1.68015325 std: 0.330318779\n",
      "Iter:  186 0.41800347873817345 0.0121905347 -0.530041277 1.66511118 std: 0.326268107\n",
      "Iter:  185 0.4219274035915751 0.0121660763 -0.517220438 1.65027285 std: 0.322289586\n",
      "Iter:  184 0.425866670291774 0.0121417549 -0.504578412 1.63573825 std: 0.318412662\n",
      "Iter:  183 0.4298210237099051 0.0121175693 -0.49199459 1.62137079 std: 0.314608365\n",
      "Iter:  182 0.4337902040772116 0.0120935198 -0.479345679 1.60706079 std: 0.310867399\n",
      "Iter:  181 0.4377739469948648 0.0120696053 -0.467101365 1.59332871 std: 0.307271868\n",
      "Iter:  180 0.4417719834450425 0.0120458277 -0.454882473 1.5796901 std: 0.303741038\n",
      "Iter:  179 0.4457840398032719 0.0120221879 -0.442676634 1.56623781 std: 0.300281614\n",
      "Iter:  178 0.44980983785204776 0.0119986832 -0.430620313 1.55317545 std: 0.296931446\n",
      "Iter:  177 0.45384909479572977 0.0119753145 -0.418486387 1.54022968 std: 0.293643028\n",
      "Iter:  176 0.45790152327672884 0.0119520826 -0.406752467 1.52774858 std: 0.290492505\n",
      "Iter:  175 0.46196683139298717 0.0119289858 -0.394884974 1.51530766 std: 0.287399352\n",
      "Iter:  174 0.46604472271675884 0.0119060259 -0.38302651 1.50315177 std: 0.284401298\n",
      "Iter:  173 0.47013489631469674 0.011883202 -0.37125507 1.49120927 std: 0.281485736\n",
      "Iter:  172 0.47423704676925077 0.0118605131 -0.359679133 1.47957098 std: 0.278681159\n",
      "Iter:  171 0.4783508642013827 0.0118379612 -0.348254651 1.46838188 std: 0.275988549\n",
      "Iter:  170 0.4824760342946015 0.0118155442 -0.336844057 1.45743 std: 0.27337873\n",
      "Iter:  169 0.48661223832032424 0.0117932633 -0.32530126 1.44644272 std: 0.270858079\n",
      "Iter:  168 0.4907591531645648 0.0117711164 -0.313976914 1.43589962 std: 0.268443525\n",
      "Iter:  167 0.4949164513559548 0.0117491074 -0.302678049 1.4255439 std: 0.266126692\n",
      "Iter:  166 0.49908380109509887 0.0117272334 -0.291459829 1.41541946 std: 0.263902813\n",
      "Iter:  165 0.5032608662852666 0.0117054945 -0.280281931 1.40551937 std: 0.261770129\n",
      "Iter:  164 0.507447306564423 0.0116838915 -0.269354641 1.39585519 std: 0.259739488\n",
      "Iter:  163 0.5116427773385995 0.0116624236 -0.258311868 1.3862052 std: 0.257787347\n",
      "Iter:  162 0.5158469298166048 0.0116410907 -0.247455195 1.37685466 std: 0.255927324\n",
      "Iter:  161 0.5200594110460781 0.0116198938 -0.236669064 1.36775219 std: 0.254158676\n",
      "Iter:  160 0.5242798639508828 0.011598831 -0.226125434 1.35896027 std: 0.252485782\n",
      "Iter:  159 0.5285079273698415 0.0115779024 -0.215616733 1.35033107 std: 0.250892729\n",
      "Iter:  158 0.5327432360968112 0.0115571106 -0.205222175 1.34189451 std: 0.249385431\n",
      "Iter:  157 0.5369854209220958 0.0115364529 -0.194810838 1.33364546 std: 0.247948483\n",
      "Iter:  156 0.5412341086751961 0.0115159303 -0.18468672 1.32568645 std: 0.246596009\n",
      "Iter:  155 0.5454889222688935 0.0114955418 -0.174487859 1.31779146 std: 0.245312825\n",
      "Iter:  154 0.5497494807446646 0.0114752874 -0.164448097 1.31013954 std: 0.244105339\n",
      "Iter:  153 0.5540153993194241 0.011455168 -0.154682308 1.30284584 std: 0.242972776\n",
      "Iter:  152 0.5582862894335912 0.0114351837 -0.145052388 1.29574466 std: 0.241907522\n",
      "Iter:  151 0.5625617588004748 0.0114153326 -0.135620311 1.28888345 std: 0.24090986\n",
      "Iter:  150 0.5668414114569749 0.0113956165 -0.126228184 1.28222775 std: 0.239967763\n",
      "Iter:  149 0.5711248478155918 0.0113760326 -0.117106482 1.27577615 std: 0.239089176\n",
      "Iter:  148 0.575411664717739 0.0113565838 -0.108025506 1.26940429 std: 0.238267452\n",
      "Iter:  147 0.5797014554883527 0.0113372682 -0.0991830304 1.26347399 std: 0.2375056\n",
      "Iter:  146 0.5839938099917924 0.0113180857 -0.0902165 1.25750911 std: 0.236793175\n",
      "Iter:  145 0.5882883146890222 0.0112990364 -0.0815182 1.25175166 std: 0.236128867\n",
      "Iter:  144 0.5925845526960687 0.0112801213 -0.0729755089 1.24628043 std: 0.235515162\n",
      "Iter:  143 0.5968821038437436 0.0112613374 -0.0646822453 1.2409482 std: 0.234946668\n",
      "Iter:  142 0.6011805447386248 0.0112426886 -0.0563682355 1.23579955 std: 0.234419703\n",
      "Iter:  141 0.6054794488252844 0.0112241721 -0.0481137671 1.23081493 std: 0.233933195\n",
      "Iter:  140 0.6097783864497551 0.0112057868 -0.0401115417 1.22600579 std: 0.233489871\n",
      "Iter:  139 0.6140769249242247 0.0111875348 -0.0322638527 1.22139895 std: 0.233084738\n",
      "Iter:  138 0.6183746285929457 0.0111694159 -0.024414055 1.21687424 std: 0.232709631\n",
      "Iter:  137 0.6226710588993513 0.0111514293 -0.0193499569 1.21260822 std: 0.232367367\n",
      "Iter:  136 0.6269657744543636 0.011133573 -0.014362162 1.20855498 std: 0.232056245\n",
      "Iter:  135 0.6312583311058837 0.0111158499 -0.00939292461 1.20447493 std: 0.231773242\n",
      "Iter:  134 0.6355482820094475 0.0110982573 -0.00458889548 1.20048749 std: 0.231516153\n",
      "Iter:  133 0.6398351777000377 0.0110807968 0.000203148913 1.19673395 std: 0.231285721\n",
      "Iter:  132 0.6441185661650353 0.0110634677 0.00492707267 1.1932236 std: 0.231078446\n",
      "Iter:  131 0.648397992918296 0.011046269 0.00950449239 1.19199932 std: 0.230890483\n",
      "Iter:  130 0.6526730010753395 0.0110292006 0.0139963487 1.19129241 std: 0.230726659\n",
      "Iter:  129 0.6569431314296321 0.0110122645 0.0184183642 1.19067681 std: 0.230578199\n",
      "Iter:  128 0.6612079225299503 0.0109954579 0.0227584448 1.19014275 std: 0.230447918\n",
      "Iter:  127 0.6654669107588066 0.0109787825 0.0270799417 1.1896261 std: 0.23033385\n",
      "Iter:  126 0.6697196304119223 0.0109622367 0.031232506 1.18922591 std: 0.23023501\n",
      "Iter:  125 0.6739656137787282 0.0109458202 0.0353986695 1.18881893 std: 0.230147719\n",
      "Iter:  124 0.6782043912238774 0.0109295323 0.0394672714 1.18842149 std: 0.230075344\n",
      "Iter:  123 0.6824354912697499 0.0109133758 0.0433811955 1.18808556 std: 0.23001574\n",
      "Iter:  122 0.6866584406799314 0.0108973477 0.0472372 1.18782735 std: 0.229965925\n",
      "Iter:  121 0.6908727645436477 0.0108814491 0.0510470197 1.1876775 std: 0.229927123\n",
      "Iter:  120 0.6950779863611325 0.0108656781 0.0547409281 1.18748903 std: 0.229899868\n",
      "Iter:  119 0.699273628129912 0.0108500365 0.0583340861 1.18731487 std: 0.22987923\n",
      "Iter:  118 0.7034592104319823 0.0108345225 0.0618275218 1.18715513 std: 0.229869843\n",
      "Iter:  117 0.7076342525218613 0.0108191362 0.0652235448 1.18709683 std: 0.229865775\n",
      "Iter:  116 0.711798272415492 0.0108038792 0.0686429441 1.18699348 std: 0.229866594\n",
      "Iter:  115 0.7159507869799758 0.0107887471 0.0719043687 1.18694758 std: 0.229877949\n",
      "Iter:  114 0.7200913120241145 0.0107737435 0.0750400349 1.18685973 std: 0.229896039\n",
      "Iter:  113 0.7242193623897359 0.0107588666 0.0782663673 1.18690979 std: 0.229911312\n",
      "Iter:  112 0.7283344520437833 0.0107441172 0.0813393518 1.18690884 std: 0.229933605\n",
      "Iter:  111 0.7324360941711417 0.0107294936 0.0842817575 1.18702555 std: 0.229962096\n",
      "Iter:  110 0.7365238012681802 0.0107149947 0.0871196911 1.18705451 std: 0.229994476\n",
      "Iter:  109 0.7405970852369835 0.0107006244 0.0899348333 1.18711114 std: 0.230031744\n",
      "Iter:  108 0.7446554574802509 0.0106863771 0.092650868 1.18714082 std: 0.230075091\n",
      "Iter:  107 0.7486984289968337 0.0106722554 0.0954289 1.18732595 std: 0.230112389\n",
      "Iter:  106 0.7527255104778904 0.0106582567 0.0979438499 1.18741405 std: 0.230160519\n",
      "Iter:  105 0.7567362124036296 0.0106443837 0.100565121 1.18752885 std: 0.230211228\n",
      "Iter:  104 0.7607300451406179 0.0106306355 0.103006884 1.18765807 std: 0.230261177\n",
      "Iter:  103 0.7647065190396239 0.0106170103 0.105533466 1.18782842 std: 0.230310157\n",
      "Iter:  102 0.7686651445339739 0.0106035089 0.107709385 1.18797541 std: 0.230362445\n",
      "Iter:  101 0.7726054322383897 0.0105901305 0.109584697 1.1881597 std: 0.230417\n",
      "Iter:  100 0.7765268930482836 0.0105768749 0.111378916 1.18834865 std: 0.230471477\n",
      "Iter:  99 0.780429038239481 0.0105637405 0.113139778 1.18863988 std: 0.230522305\n",
      "Iter:  98 0.7843113795683443 0.010550729 0.114871562 1.18890584 std: 0.230575725\n",
      "Iter:  97 0.7881734293722684 0.0105378386 0.11651697 1.18916309 std: 0.230634138\n",
      "Iter:  96 0.7920147006705205 0.0105250673 0.117756799 1.18938625 std: 0.230689168\n",
      "Iter:  95 0.7958347072653944 0.0105124181 0.118799224 1.1897248 std: 0.230740204\n",
      "Iter:  94 0.7996329638436518 0.010499889 0.119986758 1.19000387 std: 0.230792224\n",
      "Iter:  93 0.8034089860782194 0.0104874792 0.121103317 1.19030881 std: 0.230843157\n",
      "Iter:  92 0.8071622907301145 0.0104751894 0.122204214 1.19059241 std: 0.230897695\n",
      "Iter:  91 0.8108923957505672 0.010463017 0.123341069 1.1908443 std: 0.230951801\n",
      "Iter:  90 0.8145988203833112 0.0104509611 0.1243857 1.19120908 std: 0.231001168\n",
      "Iter:  89 0.8182810852670127 0.0104390243 0.125517011 1.19146621 std: 0.231047198\n",
      "Iter:  88 0.8219387125378059 0.0104272058 0.126614228 1.19174206 std: 0.231096804\n",
      "Iter:  87 0.8255712259319062 0.0104155019 0.12763685 1.19201434 std: 0.231145814\n",
      "Iter:  86 0.8291781508882702 0.0104039144 0.128701448 1.19228506 std: 0.231192812\n",
      "Iter:  85 0.8327590146512707 0.0103924414 0.129795104 1.1925652 std: 0.231235802\n",
      "Iter:  84 0.8363133463733574 0.010381083 0.130879566 1.19291162 std: 0.231276676\n",
      "Iter:  83 0.8398406772176716 0.0103698382 0.131997 1.19321489 std: 0.231317058\n",
      "Iter:  82 0.843340540460583 0.010358707 0.133206487 1.19346058 std: 0.231354684\n",
      "Iter:  81 0.8468124715941189 0.0103476876 0.134337157 1.19379652 std: 0.231386542\n",
      "Iter:  80 0.8502560084282533 0.0103367809 0.135417908 1.19411302 std: 0.231418461\n",
      "Iter:  79 0.8536706911930254 0.0103259832 0.13647759 1.19434106 std: 0.231452063\n",
      "Iter:  78 0.8570560626404552 0.0103152962 0.137574658 1.19461751 std: 0.231481835\n",
      "Iter:  77 0.8604116681462255 0.0103047192 0.138672367 1.1948061 std: 0.231509596\n",
      "Iter:  76 0.8637370558110983 0.0102942502 0.139760986 1.19506204 std: 0.231533021\n",
      "Iter:  75 0.867031776562034 0.0102838883 0.140839741 1.19534111 std: 0.231555149\n",
      "Iter:  74 0.8702953842529827 0.0102736317 0.141911924 1.19560468 std: 0.23157762\n",
      "Iter:  73 0.8735274357653144 0.0102634821 0.143020853 1.19581723 std: 0.231597528\n",
      "Iter:  72 0.8767274911078582 0.0102534359 0.144138858 1.1961354 std: 0.23160851\n",
      "Iter:  71 0.8798951135165177 0.0102434913 0.145248532 1.19639397 std: 0.231618166\n",
      "Iter:  70 0.8830298695534324 0.01023365 0.146332756 1.19664323 std: 0.231626421\n",
      "Iter:  69 0.8861313292056522 0.0102239093 0.147481233 1.1968025 std: 0.23162818\n",
      "Iter:  68 0.8891990659832945 0.0102142673 0.148537308 1.19699979 std: 0.231629372\n",
      "Iter:  67 0.8922326570171527 0.0102047222 0.149628416 1.19724524 std: 0.231624648\n",
      "Iter:  66 0.8952316831557243 0.0101952758 0.150745884 1.19740617 std: 0.231616631\n",
      "Iter:  65 0.8981957290616277 0.0101859225 0.151846 1.19756019 std: 0.231606707\n",
      "Iter:  64 0.9011243833073767 0.0101766624 0.152954713 1.19770586 std: 0.231593758\n",
      "Iter:  63 0.9040172384704822 0.0101674944 0.1540135 1.19781685 std: 0.231579095\n",
      "Iter:  62 0.9068738912278499 0.010158415 0.155026346 1.19792092 std: 0.231561571\n",
      "Iter:  61 0.9096939424494431 0.010149424 0.156106144 1.19808269 std: 0.231540248\n",
      "Iter:  60 0.9124769972911813 0.0101405177 0.157180801 1.1982193 std: 0.231512055\n",
      "Iter:  59 0.9152226652870424 0.0101316953 0.158176422 1.19830585 std: 0.231481805\n",
      "Iter:  58 0.9179305604403415 0.010122953 0.159259856 1.19839716 std: 0.231447875\n",
      "Iter:  57 0.9206003013141525 0.0101142898 0.160271063 1.19845414 std: 0.231415331\n",
      "Iter:  56 0.9232315111208469 0.010105703 0.161329478 1.19851339 std: 0.231374562\n",
      "Iter:  55 0.9258238178107169 0.0100971879 0.162442923 1.19853616 std: 0.231328771\n",
      "Iter:  54 0.928376854159656 0.0100887436 0.163480058 1.19858658 std: 0.231277749\n",
      "Iter:  53 0.9308902578558669 0.0100803627 0.164498702 1.19862986 std: 0.231226683\n",
      "Iter:  52 0.9333636715855687 0.0100720469 0.165482223 1.19861507 std: 0.231172293\n",
      "Iter:  51 0.9357967431176747 0.0100637916 0.166504115 1.19859838 std: 0.231112346\n",
      "Iter:  50 0.9381891253874126 0.0100555895 0.167511016 1.19858408 std: 0.23104924\n",
      "Iter:  49 0.9405404765788598 0.0100474395 0.168574646 1.19847858 std: 0.230981797\n",
      "Iter:  48 0.9428504602063653 0.0100393323 0.169538453 1.19841623 std: 0.230911583\n",
      "Iter:  47 0.9451187451948329 0.010031268 0.170562625 1.19833386 std: 0.230836585\n",
      "Iter:  46 0.9473450059588361 0.0100232391 0.171586931 1.19822907 std: 0.230755419\n",
      "Iter:  45 0.9495289224805413 0.0100152362 0.17255941 1.19814467 std: 0.230671719\n",
      "Iter:  44 0.9516701803864107 0.0100072585 0.173497 1.19804811 std: 0.230585217\n",
      "Iter:  43 0.9537684710226606 0.00999929383 0.174413502 1.19792295 std: 0.230493501\n",
      "Iter:  42 0.9558234915294489 0.00999133661 0.175351724 1.19780385 std: 0.230399668\n",
      "Iter:  41 0.9578349449137677 0.00998337846 0.176316231 1.19769597 std: 0.230301753\n",
      "Iter:  40 0.9598025401210158 0.00997540914 0.177153632 1.19755554 std: 0.230198726\n",
      "Iter:  39 0.9617259921052262 0.00996741559 0.178052843 1.19736195 std: 0.230090037\n",
      "Iter:  38 0.9636050218979272 0.00995939225 0.178910568 1.19718492 std: 0.229980305\n",
      "Iter:  37 0.9654393566756109 0.00995132234 0.179808363 1.19704664 std: 0.229865715\n",
      "Iter:  36 0.9672287298257886 0.00994319376 0.180654064 1.19685078 std: 0.229745284\n",
      "Iter:  35 0.9689728810116095 0.00993498694 0.181517541 1.19664598 std: 0.229624\n",
      "Iter:  34 0.9706715562350208 0.00992669 0.182422236 1.19639528 std: 0.229498133\n",
      "Iter:  33 0.9723245078984482 0.00991827715 0.183293223 1.19614279 std: 0.229367718\n",
      "Iter:  32 0.9739314948649754 0.00990973227 0.184147 1.19588482 std: 0.22923094\n",
      "Iter:  31 0.9754922825170027 0.0099010272 0.184973955 1.19560337 std: 0.229090631\n",
      "Iter:  30 0.9770066428133635 0.00989213586 0.185843259 1.1953119 std: 0.228946134\n",
      "Iter:  29 0.9784743543448807 0.00988302566 0.186722204 1.19498789 std: 0.228797197\n",
      "Iter:  28 0.9798952023883438 0.00987366 0.187580407 1.19466138 std: 0.228648365\n",
      "Iter:  27 0.9812689789588862 0.009864 0.1884792 1.19432402 std: 0.228490695\n",
      "Iter:  26 0.9825954828607482 0.00985399447 0.18930614 1.19402146 std: 0.228330418\n",
      "Iter:  25 0.9838745197364055 0.00984359346 0.190073535 1.19367611 std: 0.228165224\n",
      "Iter:  24 0.985105902114048 0.00983273 0.190845713 1.19327271 std: 0.227998897\n",
      "Iter:  23 0.986289449453392 0.00982133206 0.191735625 1.19280601 std: 0.227826208\n",
      "Iter:  22 0.9874249881898103 0.00980931055 0.192472056 1.19240737 std: 0.227648422\n",
      "Iter:  21 0.9885123517767647 0.0097965626 0.193263099 1.19192243 std: 0.227465659\n",
      "Iter:  20 0.9895513807265275 0.00978296623 0.194043636 1.19150209 std: 0.227281094\n",
      "Iter:  19 0.9905419226491766 0.00976837147 0.194768116 1.19101429 std: 0.227092728\n",
      "Iter:  18 0.991483832289852 0.0097526 0.195518404 1.19052815 std: 0.226901501\n",
      "Iter:  17 0.9923769715642599 0.00973543059 0.196280465 1.19004071 std: 0.226703\n",
      "Iter:  16 0.9932212095924134 0.00971659 0.19702363 1.18947864 std: 0.226502612\n",
      "Iter:  15 0.994016422730598 0.00969573762 0.197809726 1.18892241 std: 0.226299047\n",
      "Iter:  14 0.9947624946015492 0.00967243407 0.198601037 1.18838108 std: 0.226091787\n",
      "Iter:  13 0.9954593161228352 0.00964612141 0.199262723 1.18782294 std: 0.225879788\n",
      "Iter:  12 0.996106785533432 0.00961605739 0.199964106 1.18726099 std: 0.225663036\n",
      "Iter:  11 0.9967048084184832 0.00958125386 0.200698525 1.18664527 std: 0.225442424\n",
      "Iter:  10 0.9972532977322359 0.00954034831 0.201379582 1.18597829 std: 0.225223377\n",
      "Iter:  9 0.9977521738191455 0.00949141942 0.20206584 1.18533 std: 0.224998847\n",
      "Iter:  8 0.9982013644331403 0.00943166483 0.202756584 1.18471086 std: 0.224766642\n",
      "Iter:  7 0.9986008047550423 0.00935683306 0.203409374 1.18406963 std: 0.224537119\n",
      "Iter:  6 0.9989504374081352 0.00926012918 0.20409663 1.18337274 std: 0.224303767\n",
      "Iter:  5 0.9992502124718767 0.00913000293 0.204746827 1.18272567 std: 0.224072218\n",
      "Iter:  4 0.9995000874937502 0.00894505437 0.205349952 1.18207657 std: 0.223840564\n",
      "Iter:  3 0.99970002749925 0.00866065 0.205888897 1.18143976 std: 0.223611623\n",
      "Iter:  2 0.999850005 0.00816510152 0.206441432 1.18080223 std: 0.223393157\n",
      "Iter:  1 0.99995 0.00707106804 0.20692949 1.18027413 std: 0.223196909\n",
      "End\n",
      "(128, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# eval prediction\n",
    "T = 200     # steps\n",
    "\n",
    "seq, seq2, step, orig, no_emb_seq = get_random_seq_diffusion(M15_candles)\n",
    "\n",
    "#sinVec2Float(seq, 8)\n",
    "\n",
    "\n",
    "#step = tf.expand_dims(tf.expand_dims(step, axis=0), axis=0)\n",
    "\n",
    "tf.print(\"Start\")\n",
    "prediction = tf.expand_dims(seq, axis=0)\n",
    "\n",
    "print(prediction.shape)\n",
    "\n",
    "alphas = []\n",
    "\n",
    "beta_t = 0.0      \n",
    "alpha_t = 1.0\n",
    "std_mod = 0.01\n",
    "\n",
    "for k in range(T):\n",
    "    beta_t = k / T * std_mod\n",
    "    alpha_t *= 1.0 - beta_t\n",
    "    alphas.append(alpha_t)\n",
    "    \n",
    "    \n",
    "#print(alphas[:10])\n",
    "\n",
    "for i in reversed(range(1, T)): \n",
    "\n",
    "    \n",
    "    beta_t = i / tf.cast(T, tf.float32) * std_mod\n",
    "    step_i = tf.expand_dims(tf.expand_dims(i, axis=0), axis=0)\n",
    "\n",
    "    \n",
    "    inv_noise = model([prediction, step_i], training=False) * (beta_t / tf.sqrt(1.0 - alphas[i]))\n",
    "    prediction = (prediction - inv_noise) / tf.sqrt(1.0 - beta_t) \n",
    "    \n",
    "    \n",
    "    min_val = tf.math.reduce_min(prediction)\n",
    "    max_val = tf.math.reduce_max(prediction)\n",
    "    std = tf.math.reduce_std(prediction)\n",
    "    \n",
    "    #prediction = (prediction - min_val) / (max_val - min_val + 1e-6) * 2.0 - 1.0\n",
    "    \n",
    "    prediction = tf.clip_by_value(prediction, -8.0, 8.0)\n",
    "    #prediction = (prediction - tf.reduce_mean(prediction)) / tf.math.reduce_std(prediction)\n",
    "    \n",
    "    \n",
    "    #tf.print(\"Inv noise std:\", tf.math.reduce_std(inv_noise))\n",
    "    tf.print(\"Iter: \", i, alphas[i], (beta_t / tf.sqrt(1.0 - alphas[i])), min_val, max_val, \"std:\", std)\n",
    "    \n",
    "min_val = tf.math.reduce_min(prediction)\n",
    "max_val = tf.math.reduce_max(prediction)\n",
    "prediction = (prediction - min_val) / (max_val - min_val + 1e-6)\n",
    "\n",
    "tf.print(\"End\")\n",
    "prediction = prediction[0]\n",
    "print(prediction.shape)\n",
    "#prediction = sinVec2Float(prediction)\n",
    "\n",
    "\n",
    "#orig_decoded = sinVec2Float(orig)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "#plt.plot(real_L, color=\"blue\")\n",
    "#plt.plot(output_L, color=\"red\")\n",
    "\n",
    "#plt.plot(sample[:, 0], color=\"blue\")\n",
    "#plt.plot(prediction[:, 0], color=\"red\")\n",
    "\n",
    "#plt.plot(chart_data[:, 0], color=\"blue\")\n",
    "\n",
    "for i in range(prediction.shape[0]):\n",
    "    plt.plot((i, i), (prediction[i, 0], prediction[i, 1]), color=\"blue\")\n",
    "    plt.plot((i, i), (no_emb_seq[i, 0], no_emb_seq[i, 1]), color=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Real:\", result)\n",
    "#print(\"Pred\", prediction)\n",
    "\n",
    "#for i in range(10):\n",
    "#    plt.plot(np.squeeze(prediction[i]), color=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZD2Uw1o-pR-",
    "outputId": "0dca2785-bb43-4a0c-854d-290329fd07ba"
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"embedding_18\" (type Embedding).\n\nindices[80,0,0] = -1 is not in [0, 200) [Op:ResourceGather]\n\nCall arguments received:\n   inputs=tf.Tensor(shape=(256, 128, 2), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-97fd9d9768b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mBS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean result:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-345242ac8aa2>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"embedding_18\" (type Embedding).\n\nindices[80,0,0] = -1 is not in [0, 200) [Op:ResourceGather]\n\nCall arguments received:\n   inputs=tf.Tensor(shape=(256, 128, 2), dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "seq, y, result, levels = get_random_trade(M15_candles)\n",
    "\n",
    "\n",
    "inp1 = tf.expand_dims(seq, axis=0)\n",
    "inp2 = tf.expand_dims(levels, axis=0)\n",
    "\n",
    "for i in batched_DS.take(1):        # jenom jeden batch\n",
    "    inp1 = i[0]\n",
    "    inp2 = i[3]\n",
    "    real = i[2]\n",
    "    \n",
    "BS = inp1.shape[0]\n",
    "\n",
    "prediction = model([inp1, inp2], training=False)\n",
    "\n",
    "tf.print(\"Mean result:\", tf.reduce_mean(prediction))\n",
    "\n",
    "round_pred = prediction > 0.31\n",
    "tf.print(\"Trades taken:\", tf.reduce_sum(tf.cast(round_pred, tf.float32)), \"out of\", BS)\n",
    "\n",
    "\n",
    "sum_R = 0.0\n",
    "for i in range(BS):\n",
    "    if round_pred[i]:\n",
    "        sum_R += real[i] \n",
    "    \n",
    "tf.print(\"Won trades\", sum_R)\n",
    "\n",
    "    \n",
    "#min_val = tf.math.reduce_min(prediction)\n",
    "#max_val = tf.math.reduce_max(prediction)\n",
    "#prediction = (prediction - min_val) / (max_val - min_val + 1e-6)\n",
    "\n",
    "tf.print(\"End\")\n",
    "\n",
    "prediction = prediction[0]\n",
    "print(prediction.shape)\n",
    "\n",
    "\n",
    "\n",
    "#fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "\n",
    "#plt.plot(seq[:])\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(prediction.shape[0]):\n",
    "#    plt.plot((i, i), (seq[i, 0], seq[i, 1]), color=\"blue\")\n",
    "#    plt.plot((i, i), (prediction[i, 0], prediction[i, 1]), color=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Real:\", result)\n",
    "#print(\"Pred\", prediction)\n",
    "\n",
    "#for i in range(10):\n",
    "#    plt.plot(np.squeeze(prediction[i]), color=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 0. 1. 1.]], shape=(256, 17), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "to_denoise, noise, step, orig  = get_random_seq_diffusion(M15_candles)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "\n",
    "for i in range(prediction.shape[0]):\n",
    "    plt.plot((i, i), (to_denoise[i, 0], to_denoise[i, 1]), color=\"blue\")\n",
    "    plt.plot((i, i), (orig[i, 0], orig[i, 1]), color=\"red\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-d0bfb3150a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# eval prediction - show candles\n",
    "\n",
    "def binVec2Float(input, bin_size):\n",
    "    vec = np.power(2.0, np.arange(bin_size-1, -1, -1))\n",
    "\n",
    "    output = []\n",
    "    for i in input:\n",
    "        x = np.round_(i) > 0\n",
    "        output.append(np.dot(vec, x) / 2**bin_size)\n",
    "    \n",
    "    return np.array(output)\n",
    "        \n",
    "        \n",
    "sample = get_random_seq(M15_candles)[0]\n",
    "\n",
    "print(sample.shape)\n",
    "print(tf.expand_dims(sample, axis=-1).shape)\n",
    "\n",
    "prediction = model(tf.expand_dims(sample, axis=0), training=True)[0]\n",
    "#prediction = model.predict(tf.expand_dims(sample, axis=0))[0]\n",
    "print(sample.shape)\n",
    "\n",
    "bin_size = 8\n",
    "N = 3\n",
    "\n",
    "\n",
    "#output_L = binVec2Float(prediction[:, :bin_size], bin_size)\n",
    "#output_H = binVec2Float(prediction[:, bin_size:], bin_size)\n",
    "\n",
    "#real_L = binVec2Float(sample[:, :bin_size], bin_size)\n",
    "#real_H = binVec2Float(sample[:, bin_size:], bin_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(sample.shape[0]):\n",
    "    plt.plot((i, i), (sample[i, 0], sample[i, 1]), color=\"blue\")\n",
    "    plt.plot((i, i), (prediction[i, 0], prediction[i, 1]), color=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(10):\n",
    "#    plt.plot(np.squeeze(prediction[i]), color=\"red\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2e7d2ecac0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights\n",
    "\n",
    "\n",
    "encoder.load_weights(\"encoder_RNN_64_3\")\n",
    "#encoder.save_weights(\"encoder_RNN_64_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_random_seq(M15_candles)[0]\n",
    "\n",
    "print(sample.shape)\n",
    "print(tf.expand_dims(sample, axis=-1).shape)\n",
    "\n",
    "prediction = encoder(tf.expand_dims(sample, axis=0), training=True)[0]\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reversed - eval prediction\n",
    "\n",
    "\n",
    "balance = 1000 # in $\n",
    "risk = 0.01\n",
    "RR = 1.0\n",
    "\n",
    "wins = 0\n",
    "losses = 0\n",
    "trades_without_NN = 0\n",
    "\n",
    "\n",
    "\n",
    "prediction = model.predict(X_reversed_dataset)\n",
    "\n",
    "print(X_reversed_dataset.shape, prediction.shape)\n",
    "#print(prediction[0:40])\n",
    "\n",
    "\n",
    "for i, res in enumerate(Y_data):\n",
    "\n",
    "    margin = balance * risk\n",
    "    \n",
    "    if prediction[i] < 0.5:   # noped by AI\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    if res == 1:\n",
    "        balance = balance + margin*RR\n",
    "        wins = wins+1\n",
    "        #print(i, \"- Win\", balance)\n",
    "    if res == -1:\n",
    "        balance = balance - margin\n",
    "        losses=losses+1\n",
    "        #print(i, \"- Loss\", balance)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "print(\"Balance:\", balance)\n",
    "print(wins+losses,\"trades taken out of\", Y_data.shape[0], \"setups\")\n",
    "print(\"Winrate:\", wins / (wins+losses))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show layers output\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "inp = get_random_seq(M15_candles)\n",
    "inp = tf.convert_to_tensor(inp, tf.float32)\n",
    "\n",
    "mdl = encoder\n",
    "       \n",
    "layer_outputs = [layer.output for layer in mdl.layers[:]] \n",
    "generate = True\n",
    "if generate:\n",
    "    for i, l in enumerate(mdl.layers):\n",
    "        print(i, l.name, l.output_shape)\n",
    "\n",
    "    get_activations = Model(inputs=mdl.input, outputs=layer_outputs)\n",
    "    activations = get_activations.predict(inp)\n",
    "\n",
    "\n",
    "\n",
    "print(\"All activations:\", len(activations))\n",
    "for i in activations:\n",
    "    print(\"Activations:\", i.shape, np.amin(i), np.amax(i))\n",
    "    \n",
    "    \n",
    "    \n",
    "layer_i = 28\n",
    "print((activations[layer_i][0].T).shape)\n",
    "print((activations[layer_i][1].T).shape)\n",
    "\n",
    "x1 = (activations[layer_i][0].T)\n",
    "x2 = (activations[layer_i][1].T)\n",
    "\n",
    "x = [np.array(x1), np.array(x2)]\n",
    "\n",
    "\n",
    "#x = activations[0][0]\n",
    "#print(\"x\", x.shape)\n",
    "\n",
    "#print(\"Min, max: \", np.min(x), np.max(x))\n",
    "#print(\"AE: \", x[0, :24, :24])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(24, 5))\n",
    "\n",
    "plt.stairs(x[0].T, color=\"red\")\n",
    "plt.stairs(x[1].T-x[0].T, color=\"blue\")\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(Y_data, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show output interval\n",
    "\n",
    "print(\"### ENCODER ###\")\n",
    "   \n",
    "layer_outputs = [layer.output for layer in encoder.layers[:]] \n",
    "\n",
    "inp = get_random_seq(M15_candles)\n",
    "inp = tf.convert_to_tensor(inp, tf.float32)\n",
    "\n",
    "\n",
    "generate = True\n",
    "if generate:\n",
    "    get_activations = Model(inputs=encoder.input, outputs=layer_outputs)\n",
    "    activations = get_activations.predict(inp)\n",
    "    \n",
    "print(\"         Min      Max       SqrtVar   \")\n",
    "for i, l in enumerate(encoder.layers):\n",
    "        print(\"Layer\", i, l.name, l.output_shape)\n",
    "        print(\"  \", np.min(activations[i][0]), np.max(activations[i][0]), np.sqrt(np.var(activations[i][0])), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "layer_num = 12\n",
    "x = activations[5:9]\n",
    "print(x[0].shape)\n",
    "\n",
    "aspect_ratio = 64 / 16\n",
    "\n",
    "x_count = 7\n",
    "y_size = 128 / x_count\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(y_size * aspect_ratio, y_size))\n",
    "\n",
    "for i, xr in enumerate(x):\n",
    "    x_shp = x[i][0].shape[0]\n",
    "    y_shp = x[i][0].shape[2]\n",
    "    tmp = tf.reshape(x[i][0], (x_shp, y_shp))\n",
    "    fig.add_subplot(1, 5, i+1)\n",
    "    plt.imshow(tmp, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show kernels\n",
    "\n",
    "\n",
    "mdl = encoder\n",
    "\n",
    "inp = get_random_seq(M15_candles)\n",
    "inp = tf.convert_to_tensor(inp, tf.float32)\n",
    "\n",
    "layer_weights = [layer.weights for layer in mdl.layers[:]] \n",
    "\n",
    "generate = True\n",
    "if generate:\n",
    "    for i, l in enumerate(mdl.layers):\n",
    "        print(i, l.name, l.output_shape)\n",
    "\n",
    "    get_weights_model = Model(inputs=mdl.input, outputs=layer_weights)\n",
    "    weights = get_weights_model.predict(np.expand_dims(inp, axis=0))\n",
    "\n",
    "layer_num = 10\n",
    "\n",
    "weights = layer_weights[2]\n",
    "print(weights)\n",
    "\n",
    "\n",
    "\n",
    "#print(weights[layer_num].shape)\n",
    "\n",
    "x = np.array(weights)[0]\n",
    "x = np.transpose(x, (2, 0, 1, 3))[0]\n",
    "x = np.transpose(x, (2, 1, 0))   # transpose\n",
    "\n",
    "\n",
    "\n",
    "aspect_ratio = 64 / 64\n",
    "\n",
    "x_count = 4\n",
    "y_size = 32 / x_count\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(y_size * aspect_ratio, y_size))\n",
    "\n",
    "for i, xr in enumerate(x):\n",
    "    fig.add_subplot(x.shape[0], x_count, i+1)\n",
    "    plt.imshow(xr, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGruwIc0Q2ad"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "\n",
    "model = load_model(projDir + 'models/' + exp_name)\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLLV6JrIMWd_"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "exp_name = \"Contrastive_1024candles_to_2048_25layer_res_dconv\"\n",
    "model.save_weights(projDir + 'weights/' + exp_name + '.hdf5')\n",
    "#model.save(projDir + 'models/' + exp_name)\n",
    "\n",
    "encoder.save_weights(projDir + 'weights/encoder_2048_contrastive.hdf5')\n",
    "encoder.save(projDir + 'models/encoder_2048_contrastive')\n",
    "\n",
    "\n",
    "print('Saved')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "testing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "d04ced9d2f3d780184266d6c04c38b10d0bc5dc91923fa3055e4cade559214a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
