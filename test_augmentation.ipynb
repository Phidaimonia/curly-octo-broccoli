{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtKotjXjVJRV"
   },
   "source": [
    "Based on tensorflow starter code from https://www.kaggle.com/alexozerin/end-to-end-baseline-tf-estimator-lb-0-72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iofpintREkxd",
    "outputId": "96aa3a6f-e9e7-4bae-ba24-52ab07223e11"
   },
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "#%pip install keras_tqdm\n",
    "#%pip install tensorflow-addons\n",
    "#%pip install tensorflow-io\n",
    "#%pip install numba\n",
    "#%pip install tqdm\n",
    "#%pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zch7gOTgVJRd",
    "outputId": "1c69f19a-22d7-4337-a132-7ed42b097edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9598045810683859788\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7365364736\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 5903594735982669208\n",
      "physical_device_desc: \"device: 0, name: DML, pci bus id: <undefined>\"\n",
      "xla_global_id: -1\n",
      "]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import array \n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "\n",
    "from keras.layers import Input, Conv2D, Flatten, MaxPooling2D, Conv1D, MaxPooling1D, Add, Concatenate, LocallyConnected1D\n",
    "from keras.layers import Activation, BatchNormalization, GlobalMaxPooling1D, GlobalMaxPool2D, GlobalAveragePooling1D\n",
    "from keras.layers import Dense, Dropout, Reshape, LSTM, Layer, LayerNormalization, InputLayer, Permute, GRU, Cropping1D\n",
    "from keras.layers import TimeDistributed, Conv2DTranspose, UpSampling2D, MultiHeadAttention, Embedding, Rescaling, Masking\n",
    "from keras.layers import ZeroPadding1D, ZeroPadding2D, GaussianNoise, DepthwiseConv2D, Cropping2D, RepeatVector, RNN, AveragePooling2D\n",
    "from keras.layers import Conv1DTranspose, GlobalMaxPooling1D, DepthwiseConv1D\n",
    "import fast_attention\n",
    "\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.constraints import max_norm\n",
    "from keras import activations, losses, optimizers\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.optimizers import LAMB \n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#from numba import jit, njit, prange\n",
    "\n",
    "from random import *\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TerminateOnNaN\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from my_layers import ScaleNorm, L1Norm, TransformerBlock, DenseBlock, PositionEmbedding, RandomMask, RestoreUnmaskedTokens\n",
    "from my_layers import FourierEmbeddingLayer, LinearPositionEmbedding, AugmentAmplitude, ConstantLayer\n",
    "from my_layers import DynamicIntervals, RatioAugment\n",
    "\n",
    "\n",
    "import gc as gc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "projDir = ''\n",
    "\n",
    "\n",
    "model_dtype = \"float32\"\n",
    "\n",
    "K.set_floatx(model_dtype)\n",
    "K.set_epsilon(1e-6)\n",
    "#tf.keras.mixed_precision.experimental.set_policy(model_dtype)\n",
    "\n",
    "tf.config.run_functions_eagerly(False)\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')       # uncomment to run on CPU\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "DEVICE = \"/device:CPU:0\"\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candle count aaaa 5679762\n",
      "Loaded candles: (5679762, 3)\n",
      "M15 candles: (5679762, 2)\n",
      "Candle count aaaa 371569\n",
      "Loaded test candles: (371569, 3)\n",
      "M15 candles: (371569, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load all\n",
    "\n",
    "candles = pd.read_csv(\"history_EURUSD.csv\")\n",
    "candles = candles.to_numpy()\n",
    "candles = fixGaps(candles)\n",
    "print(\"Loaded candles:\", candles.shape)     # [high, low, time]\n",
    "\n",
    "#M15_candles = convertToTimeframe(candles, TF = 15)\n",
    "M15_candles = candles[:, :2]                   # test\n",
    "M15_candles = tf.convert_to_tensor(M15_candles, dtype=tf.float32)\n",
    "print(\"M15 candles:\", M15_candles.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_candles = pd.read_csv(\"history_GBPJPY.csv\")\n",
    "test_candles = test_candles.to_numpy()\n",
    "test_candles = fixGaps(test_candles)\n",
    "print(\"Loaded test candles:\", test_candles.shape)     # [high, low, time]\n",
    "\n",
    "#M15_test_candles = convertToTimeframe(test_candles, TF = 15)\n",
    "M15_test_candles = test_candles[:, :2]                   # test\n",
    "M15_test_candles = tf.convert_to_tensor(M15_test_candles, dtype=tf.float32)\n",
    "print(\"M15 candles:\", M15_test_candles.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN TEST   \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAKrCAYAAABm0Z2rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABRxklEQVR4nO3df6x0+XkQ9ue76xgcbngd8Iamu956q3GhaVVm6ZIgkeq9QAMO/eFaequatMAikJUqb8VVK5XQP4pQ/0mVqhrQG7As132DoFhoIcWKXFxEuy+NSIqd7gCxg2HkhXjtgJ1CF25wSe09/WPOmXvvuXPuOWfmzJw553w+0u7cOXN+fO/MnHnvPOd5nm/KsiwAAAAAGLen+h4AAAAAAIcnCAQAAAAwAYJAAAAAABMgCAQAAAAwAYJAAAAAABPwtr4O/K53vSt7z3ve09fhAQAAAEbnp3/6p38hy7Jntj3WWxDoPe95T3zmM5/p6/AAAAAAo5NS+vtVjykHAwAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJiA2iBQSuljKaWvpJR+puLxlFL64ymlVUrpb6aUfkP3wwQAAABgH00ygR5HxPvuePx7I+K9+X8fiog/uf+wAAAAAOjS2+pWyLLsr6aU3nPHKu+PiD+VZVkWET+VUnpnSunbsyz7+a4GCQBMxMXFzfuLRavNGq4OADBJtUGgBp6NiC9eu/9GvuxWECil9KFYZwvF888/38GhAYBRWS6PuRkAwKR00Rg6bVmWbVsxy7KPZFn2UpZlLz3zzDMdHBoAAACAJroIAr0REe++dv+5iPhyB/sFAGjl4uJ2RdndD+y4PwCAAeqiHOwTEfEwpfTxiPiuiHhTPyAAoA+VZWHKzAAA6oNAKaU/GxHnEfGulNIbEfFHIuKbIiKyLPtwRHwyIn5nRKwi4p9FxO871GABgJGqSrepWp53gG662aL1gAAAxqfJ7GC/q+bxLCJ+oLMRAQDTU5VyU5OKs+NmAACT1EU5GADASVut1rezfocBANArQSAAYPQuL/seAQBA/7qYHQwAAACAEycIBACMzsPVRTxcXTRe31TwAMAUKAcDAE7ffL6+zTs+VwVsisDP7HLZaLfFfjSSBgCmQBAIADh9+ZTwcX4eEdVBm3Lwp4gdRcX6gj8AwJQIAgEAo7WIi4iojAFVUhoGAIyRIBAAMFilKrHbdkz1kSEEAIyRIBAAMFhFps8rq2bry/ABAKZMEAgAOB3l1J5NU5+brmb+Wq9XrHWZ356dbd+9DB8AYMoEgQCA01FqAL25X1JuAD2brW+LIE9xv1AVFAIAmBJBIACgmXItVUWApm7zlpt1ohwUAgCYIkEgAKCZPWupOinFqukEvTpbPz5vPR/Ymp5BAMCYCQIBAMORpxGtXrmIiGvBnjw49CjWjz+I80a7K8eU9AwCAMZMEAgA6MYu5WL5Nqt8dq+qqq3yrpez9b43wZ5NL6H6Q15XbkEEADBmgkAAQDd2SaPJt7m8bLQaAAB7EAQCAHZT1+k5f/wiFtsWx2JxlQF067F9xwYAwC2CQADAbor0nKpuyvnjy4rNIm5nAG0eK5r1lNT0hb62Wc2Kldu12gwAYFAEgQCA/ZQjJnWRmi3OzkoLKrKL6nr4XG1Ws2LN4fQIAgDGSBAIAOhWTaTm4epi/cNFRHztaxHveEfMSh2h6yrNAABoTxAIAGhnh0yf62aX+XbLiPjGN0r7vLnrqkqzTflW3RD2HCsAwJgIAgEA7ew4r/qtwM18HvGTP1na581tqmI3mwyhi/n2Fcor5mOtaDUEADAJgkBwKnasfVAyAQxF8Tm1fHxtwePzbnZ6mNUBAEZFEAhOxY6lCiocgJOxQ5rN6my9Td2Wx87gUUUGAIyRIBCcmq5Se8qNNHbcn0wjoLIxT1npg2K1yn+Y3Vpz49Fsvc2Ddrs+uB0r3gAATpogEJyahpeda7+TdXT52lVwYNcPgsvLux+/uFgHisozgx2UyDYAMGGCQDBQgjPA0BWfY0ct9fLhCQBM2FN9DwCocHHRvASj/eqtHXr/wDTNZpJyAACORSYQnKqWV6trV9+zBMLFc6APpnQHAOiOIBCcmkNNSSOKAxzKASM1nWUJme4LAEAQCHpXNYtXxZQ0T17M17+32Ot4F7G4cbiWm28o4wDqPggeri7WP1wceiB3MN0XAIAgEPSu5VXpe6/n68/zm3nL3eQrtjvqrc0Baq3O5hERMbtcrhcsby4HAOC4BIFgKEopOMWV9QevLiLi2sXt0nqr1fr2UFMwm225Bw2fdK8NfXs0W0RExGJ5vnU5AADHJQgEp6Kup0YpBWdelctTWm+ZpwzNds79yY8337p7mUF9aPike23YW92UgBWfWztuBgDAgQkCwaloma5Rm9mTf8t6lPf+eRDnbUd0Q7mdhh6rMAF1J3jF51Z5s7OzRpsBAHBggkAwEpvGq0VwaBO1Wd+0LQuru5Kvx2oHKuq1GpdxqfdiIA5VjrqXlueP0w0AGANBIBiJTePVijqLy8t2+yuu5CvbOKCKLIu2Tb7haMb0gdDw/JH1CACMiSAQjE3Hl6ld9R6echaXDAY6M8E3kaxHAGBMBIHg1NXVZdU9XlKUhcUplmfQCc272Vv5c2XHDKDNZsvdhwIAQHcEgeBUNa1BaPgNv2jM2rYsDJigcj3ojhlAm83O9xpNt9R3AQATJggEp6rjGoSiMavvPSdo33qthtsrC6O1Mb5Zyp+tGkQDABMiCAQDszqbR0TEvFRfcbW8Qn71+2y1rFojIuqry8bUF/Zk7BuZa7i9ACC9afHBcfTPmJYnhvMIABgyQSAYmEezRUREPJhfrBfk30g2y6s2zC9bz5bnd+6/blYwV7+HQ9ULJ6PFB4fPGACAwxEEgqGqKBfrqlRhFF/EBl7mcWs8LZuAm9WI1lq+xwAAGBZBIBgZWR/XDLzM49Z4Tm2AjE9dKiAAAIMmCASMX02KTzn54dQyguDovPkBAEZJEAgYn3JUpyaDppz8sFm9vJ/8i3HF4t6p5KFvk3wP7hk1FnQGAI5JEAiGYhOh6HMQA7Fj2dStHjoV++m9Kqui43Pv42LyJllNtueJ57wFAI5JEAiGYhOhaLZ63RX5h6tihcUuo6FPe3Z8lnnAoXlvAQCcJkEgGJnaacHzFWalFUZZxtH1HOmbJ2mxdfGhvvg+eXF9gPv3tj++WuU/zNY3dVkYMg8AAGCaBIFgZGqTRIoVHt9cYZSBga7nSO+pPOze6/kB5tsfv7y8eV8WBgAAsI0gEPSlZerNoTJ1RpkBtKdNqdys12FcK9nbbpMBBBzfnh+ePnsBgD4IAkFfWqaPtM02qSsJOju7ud+uK6eGbHa57HsIEVE/jnIGEHBEGkIDAAMkCARdq2sQU7r8W2RzdJ10UlcSNCsdsOvKqZPUUfOeIkPn0Wy//XStbbNvDaIHqKMXzWt/eja9v15bHOV43gMAME2CQNC1usu7pcf3zubYc+r4P/rmRf7T4sbu2lit1l8ojv5louW3mNUry4iImEW77cppUntnCpXrQPL9lxcX2Vq3xlF6vHgPzWveBOXXVibCAJTf48WL1vK9X7Ubtmj7ubJjIL8I2v7Eg/Vx7j1e3jx+YccP1rpfo/weqCpPEyQCgHERBIKhazl1fNn9e8utu2tqPl9/CerlS2XLg24Cbk23K6Imh2owXdr/8vzm4ltfKksvTpHNVeyunN1Vs/m4s77Gouq9euBy0knb9XOlpSKYnMeAYvl4t+NXabsb7xEAmAZBIDiUHa/UF4Zy9XWx6ODLQ80vX3mFurxC11fu930R6l7U/H7lauf7Hb6xHetClJN0aNcPgIrtmr42XsMT0HOHaA2qAWBaBIFgX1V/QVdERjYBiFIEojKQ0rDcq3UZ1yl1gq4ZQ+0QyyUyZfnvunnu8yvwRQ+OuLfYull5dw/bzsbV8Lnd+SUo/V5V5WBV742rHkLNBlB+Pk7hrTMadU9mRQlh1XZVu6t6DYvlDw/Uo4wrxXP9crHgSCdSVcCvfPhT+qcBAOieIBDs69ClAw3LvVpfyR9gJ+jKLyd131ry3/VR/vBHV+frH17PF8y3b1beXfHa3erV05fS7/Wg4k1S9d5o29vIl8IeVZQQbr7Ztww4VvWHMuPc4fV1HjU97gD/aQAAWhAEAvrTsg6h/OVkk9nzaumBGuVeOpuMmIbDKbY/1VnCjk1J0QE07dJbPik225XWq9lN+dRp+5oqKWruKgPvMLwWAMBdBIGA/pTTEo7UkLVskxGT3zTN9Nl7lrA6A6nLOPHhDVNVyk7T7SpU7W6zfNloN5WH3WV2wakpPjcOlVG462vhtQOAaRAEAo6n4hL1RZ61sDhaJ+S71c2yVVZc2b+4WEREhxkxQ6vL2CElSBZRjR2fmPJ7sm53m6njH+90uNr9c1vbz5m22r4WXjsAmAZBIODwavqWlBfXlTPsXU6xb4ZNafviyn7Rm6fSses0mpYUVaze9Eth2wbT148li+gwGr8np6zuc6AUoew8Ma+nTD/lYgAwbYJAwOFVfcmpmPms7jvR3mVY+Ze61SsXd+6vXB6xWq0XzPPtz145j4gWZWn7Bp1qHy6t1/J4TVcvf3fd5fUQ/KmhNufw6jLtSm/SzhPzqnZ44OCQ0j0AmDZBINhVy8upt6YFPnU7pIVUJp5UbdBw5rN9VY2raOi8WG4fwK3mucv1ggf5/aoG05uysFajvEPNc3/1cGdHbHS8oVSpDdKOtTlFs3QG7EgnmPIvAJgmQSDYVdOrtHkE4rtfabf7o6fslw+4w1Xo8iabMqGK3hetf8fSBquzeURUzvC+UXfle98GrcX2jUtwBnIJXtlID/Z8bxRZacV7stjdB55crH/Ib25FAGpe7F1LBQel4Ru+7nNtV00/z9jBgZuP6W0GwJAIAsG+6lL3N31jtj9c/OFfsdnhdVB6ULWLujKh1ocsbVBk8jy4veZWVX+g32rQ2vKLeDkjaOeBnBglWz3Y871RfJ48mC1v7u58fb+ybVP+Yvf+edSnhrMVbj7XOi7bavt5RgsHfgNP4vwAYDQEgaCtqkviO6buF3/492bX8V97Hhb5fqp2UZSoHHo2nM4MJEjTlU0JUVevj1nCqu35i9Zl5FwFEs63b1Czw/LnUdXmo369mn4mFus9ztfr+EnZfG42XF/m3haeFAC4RRAI2hprV822V7VbXPrcNE5ueIy61aqyFdq+JpvV7x5O/Q7yge5bVtaXxo2tm+qglHC09vxFd86eqzqpbj3e7HiTeb3a2Hu2wZuL256Xdf80je2frEa8UQHgFkEg2NXYLoHXXf3u4ip3wyvsdatVZk+1HNtVqUyrzW7vIB9oOdNpcBlQuaLnSdsstaH+vr04dipN3Ul1pCbtbNHxc1/1lhrbP1kAwG4EgeBQ6tJZSld/y1dp6zY7uKYDilh/+7+4iGJ2qnKGTZG58/hifX9Rdag7DrFt/VO/yHvrSv6xL8VXPVF5AKKcuVQEf8q9nKp2U37dOs8oGrOu37zlbJK6k6SiTKbNaX/Hbtim4yfLc98/rwEAQyQIBIfS8sr7renIazY7uKYDms/XQaBr3xaLTZeP17ebjJKrVbYfquIQVet3NoPyvlGl0va3glrFgpoXr/MYUdUTVTQrL2fsrNbLy7GcYjdV/WiK15kelbNJ6k6Sivd609O+Zjds0/GT5bnvn9cAgCESBALa2RYJyP8S3kydfCvX56baRsSbY9y9n/LqOwfI9o0qlba/FRxpOLC+yzXqZjnbjE/jZ6hWfrN3lC7iHOqAqeIBQBAIhuJkmnre0X10U0ZU+tJTTrSpLBuqyMipKxfr7GpszZPc9WvQWylB1S9S9bzXrFfp2jeiyV4xr/tWWPMmaDm51217vmmrysOGUpJ5SMVz/3L5garm2zt68uL6QMt7izvXO5l/I05B1YlhqngAEASCg9vx21J5s96vLJa/YVwfUHmwpdmyyhfEV6vSvsr7zDNqblVRnW8fUmd/eNc8yV2/BkebaO6u1+66oldQXhbW9PctXudbwT3fiOqfg5rHq/owlU61anu+aavKwzovyRyg4rkvep7Nd55mcK18mr75wnrBvdfz/ZYeL+v934hTUnfidExQFIAhEQSCQyv+Mn98vtNmJ/Ml665vGBW/Y7nnzOZ3Wt6xr+vrx8X6h4u7D1s8R0NNxT/4eJseIF9vtjxvtfu6MrJRa/qmq0nZ2cysVnO4k/tcmJKK17DoefagHKUurb8pg61Qfgvdf229YPnOm/vVjHgHBz5xnJcADIkgEBxJcbW4PPPSydkjLaW4ct14mq86LaMKkwxC0K+mb7qaOqquZlZrfPp2lLowqQyItr/kgV7jSTzXAMDBCALBkRRXixctsyyObo+0lOLKtcuhTFZdmkbDlIFdsz0an74dpS7IgKhXlwEEAHBMgkDQEyn9h+O5PRBPbLXiualK06hK0Sml0lTtprx5OQOndQZQ3bgabr7jbialqwwgdlD1xjRLGAATJggEPRl1Sn9NjUjjEpIda01G/dz2qeaJ3TTInTdb//q6g3/N6qI2Vd8G8+WrVy7u3E1583IGTusMoLpxNdx8x92MW+lNPZhS4DGqemOaJQyACRMEYvxK2QsXsbhxvzxzVXk5O6ipEWlcQqLWZFA2DXIX+YIGr9toX+KWHyDFc7fnbjgFpTf1YEqBAYBJEARi/EqX5JZbVzrelbviqnBTkyyzaFlzUl5cl5QBvevoTem9fcI2GUHrm/Jn/8177XcLALALQSAm79htTqqu+FeZZCZAy5qT8uJyVsmpPYeDaa2zZ2OLptOeT1JHb8pTe29zzSYjaH1T/ux/sOduj0V/GwAYF0EgxqvhN221++PV2xXzmvde62a+fSkGWvX7VCwvFr+8pSFu3Wk52C+cHTc3Ovn3xpQ0jdoe6EU7Ozvo7mv5N/KE7PkBOdjPVwA6JQjEeLX8y3Xv73ANd1BXujQqNd9adp7RqOHqvf2hW2oIO69YbTB/iFe9SSuW3/Wernu/D/Z8qGou1lLv712utP1H4UAv2mx20N1XGk3T9jHZ88XwWgIQIQjEGNV8CXu4Wj9eTs3fu0Ftwx3UlS6NSs23lp1nNOp29YMp3mM/cdHrMDimPd98p/LeJUbctbyZif/6p2XP4PJgSpABOApBIMan6lJXfllzduhLYTtmrTBeo7v62jJF4OJi3R9odq05UPl9L+sAaqjlmS4ZQAB0SBCI8SvXVzw+v7G4cwPNWoHGyikCpVmQNudWfv96D6Ti5/L7XtYB1PBNfn8HjjYLZgMwBIJAjF/DGaUORRo2o1eaBam4u3x8tcpstl4uyMNU+Ow/oqZZUntGm5+8uD7Oj93ffpzWu8/H/eTJzcX3X1vceLzhbm6Nw3sQgG0EgRivE6mzGsxMUADUKhq+1+nss196Sb0jPTf3Xl8fZ3mvox3m4773+t2PN9zNrpsDMDGCQAxe+crcw9V6+ezVxY31NtNWtz1AwyuMdasp+4IR6LhBq8+F4SlPKlBn79e4nF7SU2+gk3zvlgfVceqLNkwAjJEgEINXvjJ3ebm+Lf/xVlwROztreYA9r8QxIaUr9oO9gF9OXahptl612bZzbfAZcRq0UuFopTdHfhOd9OdYeVAdD/LYv3ORZTY/7mEBmBhBIEar6o+36zMUQadKV+zLfRlO8kvUNuXL3lUNLkrrlTfbdq65os5YDeb8bknT9uMpsswe9DsMAEZOEIjB2WT4xMWRjrPjdm03ZLR8iQI4QQf+B/vQfw9o/AzALgSBGJyrq63LG8uLlPWz1X773zf1faxXg2mhouZp8KVQdM6XONhB1YnT9h/wYr2aaE25p2DTw1Q+Xhp/02bjVfuv+rflpEv5AOiNIBCjsfnbbdnNfmRtsLOKLxKywyjz5Wz4qr6Ad/7a9vyN/qQCClWD2HVu9Jpfqvxw3WFqn6tS9OZR65zj7eOpWu7vGQCuEwRi9FxpB+BQqr6Ad/7Fu+dZwgYVUDj0c5I/94uagH/tc7VZce8RAUBjgkCM3q106WU/44DBU8/GGNW9r8uz4HW0252dVErOQDWdAbHKsZ97rzkAHRIEYjI2F+zOexwEDJl6Nsao7n1dngWvo93ubFApOSeq6QyIXWuYmnxrYgqvOQAdEgRiusqp9KU/zh7mDaaLPtOz0uN1f8spQwPgZPQ8deVBDn+oDJnNP+CLG4e5lUlc/oe+4pd78uJ6vWe/ut7BbLZ988Lm16lIJyv2F/e2H6+s/DSZxRRg2gSBmJ6qPxpL9/O14vJy++NNZwVRQcPg7fkmdg7cprqDo+v5zXaQw+/aCLpOabDFYVav3L1elXuvr9cr/pwoPgBqN6+I0hT7a1qbWE4k8rkDMG2CQAxG8Tfew9X6h1szwTf9I7CquWZJcaWu+GNptbq5vClX2hi8Pd/ENzbv+BL0UK5oVyUMqO7g4HpOSz3K4Q/0AVD8vRH5Tdt//ys1bAg9lM83AIZFEIjBKIIxL1+ufyiuqJ2dlVZoquGl+GL/RUbQalMf1u5wQHR+Cbr3K9oN05zqxilbioM5kQygTUBlz+nQ79J10GSW/71ROaHEjil95cBYeTcyBQE4JEEgBqcIynzpmXlERMzv5w+0/WupnEZesf3swfo4q1fWj2/KwwA6+rbpSj9jtwmoHNDOQZNdo7A1KX3Fbs9KqcvlcZZ3I1MQgEMSBGJwinTs2auLmw/s+tdS3V9b+eOz5fpxV+agfxqvw46OXGN0lQHUy+GbOdBgFps6sm72t7pVBw8A7QkCQaEu/zp//Gy1vHN1adxweL2fXx3VbykD4+iOfPKUM4B6P3ebqKrPaqvlL1t3GJnIAHRBEAgKLTOCqlaXxg0ToAwM9nPAlKDyrlsfqljx8Xm7DfdMUfR5AMAxCAJBWd2luNLjVau7wg/XdFS/1VsZ2I4HrmoAC0dXzm6pmrJuVzWRls0kDrmiz96jHQ6/ma2z4vFyAs7Rso86zvwpFE/td5+tN9i1v5JMZQAiBIEYo81fOTfvNlb3l2jp8arVXdGDazr61tHbl5cdD1zVABaOrpym2vXJVLO/8vTqRWnTLsMYXFlU+Q+R5fqm6edB8RwtZ+sNPro637rbOjKVAYhoGARKKb0vIv5YRDwdER/NsuyHSo/fi4g/HRHP5/v877Is+x87His0s/kr5+ZdABi9Q5VZ5ft9WDQnvrj5cJGd86g4fHmFCpvG0eXVr42/nLT08vah3VK3/Gh/H5QPdL7f7oqAmr9vANhFbRAopfR0RPxIRHxPRLwREZ9OKX0iy7LPXVvtByLic1mW/XsppWci4vMppT+TZdkvHWTUANCHHeu5lIFxNIdKl8v3OyuycEqHKbJzvvuVi/UPs+3jKII+RXnYprRp++rXD31LEcyperzt8rJVXn41b7b6bRUnftvPg1vrL9sPBQAKTTKBvjMiVlmWfSEiIqX08Yh4f0RcDwJlEfEtKaUUEWcR8Y8i4usdjxXu1rBXD8DOdrz07oo9U1HuV7MJpMzzx4tgUn5/n5jVoWfnfJSXXz2oW7HqD46KE7/p50Gx21vrnzfbHgC2aRIEejYivnjt/hsR8V2ldR5FxCci4ssR8S0R8R9lWfZWJyOEphr26gEAjmMTSFnkC4oZtxq6uFiXmpV7Cm3TW8+bA/3B4e8YAA7hqQbrpC3LstL93xHr5NR/MdZZs49SSr/y1o5S+lBK6TMppc989atfbTlUAABGYT5vlLK7XO7eCLrhIQBgUppkAr0REe++dv+5WGf8XPf7IuKHsizLImKVUno9In5dRPz16ytlWfaRiPhIRMRLL71UDiQBMEZtLuVf2yTClXA4umOdfMX+88ygorF0ofmnRf0hqjKDfM4AMEVNgkCfjoj3ppReiIgvRcQHI+L7Suv8XET8toj4P1JKvyYifm1EfKHLgQIwUDtcyu9tKniYuuLkq5ha66pZ8nKn3Vc1Wy5/RFTN7HVdVQ+gquyf8j59zgAwRbVBoCzLvp5SehgRn4r1FPEfy7Lssyml788f/3BE/DcR8Til9LdiXT72h7Is+4UDjhsAgEOpiKw8ikVERDwouhPny8uZPJtATGk3TZstXz/82dl6f8WyYmaxIoOnHNypyuwptu+6gTQADEmTTKDIsuyTEfHJ0rIPX/v5yxHx27sdGgCsNckKAPZQd5Jtaqu2L3+0vLl40wi6vP4OZrP1YV557mJzf9vQmuqtgTQAnIBGQSDoU/F36cNV/kMXjQKAw9vhcnvVJq7gQ0ttI6dVJ1VVbVVNx+Wmhy/KwwrFFPPFv/nPPFM8srgqQWvZ7bludb2BAJgSQSBOXvF36cv5H4bAQOxwub1uE1fwoaGmkdK6yGpVZKQmYtL08EV52Ga3y/OIuAoGza9d+NlkALWM1tStLqgMwJQIAgEADNW+aSx7RlbHVKo5pt8FAKoIAgEwOMrCIFd3ErQt52p5clXNzFUu4axT1Uj6mHyeADAFgkAAnKyqK/PKwqChtuVcDU+upudm0wSlYr3l42brAwC7EQTi5G0aQgPDVZ7juWEJS+9X5tWHcKq6TodrmLJzrMMWDaPnsVzPP+9cBIBOCAJx8mYaQsPwFXM8F1/kWn6DbDkZUHfa1rTAseyaDlf1Xm6YsrNvFl758FWHLRpGP4jziMvLg0SEqwJaTncAxkwQCIDj2fEbZO9TN/c+AOhIz+/lUzqVqj6OTmmMANC1p/oeAAAAAACHJwgEAAAAMAHKwQA4rB0abNzapLIp7KLVfsu7WUS+oKj/2LH5bLnPtR62cACa9QDA3gSBADisHRps3NrkfNnBQLb1ll3WrbDTfnuf1Qz2VRNw6XqWsMKbL8xLh5+vZweLOFiznkP9LgBwigSBAJich6uL9Q+z/fZTzviRAcRo1ARc9p0lrMr919Y7vn91pINHZw71uwDAKRIEAmA49rxkXwR/Zpe7bV+omuleJgEno+fSqU4Pf6TfRbUZAFMgCATAcOx5yX7f4E+hKtijrISTMaap4I/0u5gaHoApEAQCYPSevHgRERH3SsuLViN1VWFNy7yUlQAAcMoEgRiMollkzPscBTBE915fRkTE2dn6/uXlzduNilQemT1wN6VUADAMgkAMRtEsEhix8lzrHW8+y1N+KoM6UnlgJ0qpAGAYBIE4XabZgekpojM7nv/l4E6xm5eLBXm6QlEGtllc3lE5rWG5fXEVWREcnX8zAYAGBIE4XeovYLo6Ov9v7SZPV3hUWv6gvGE5reF8++IqsiI4Ov9mAgANCAIBMFjFlO9PXswX3Fvk9y9u3K9TlUQhmAMAwJgIAgFwumrqqjZTvhcNnvPVi0bQ85fX989K5V9lVUkUKmw4eeVm5moRAYA7CAJx8lZn84gwKRhMUk0qTvH5sAkGVW2+/eFavldz8oo3+Z5N1Xfl3ACAYREE4uQ9mi0iYkvPDmDyis+HxfI8Iq7KwzY6SuVRFsbJ6+lN6twAgGERBAJgNG5lBGmWCwAAG0/1PQAAAAAADk8m0InblPhH8cOip5EAHFDbsq1NM9ybi8/O1reXl3Gnqj4mEocAABgzQaATd/WFZFm9EsDQtY2+FAHx8/VN0SD6wWy5fXelqE9VPP38/M7NAABg0ASBAOhPR42brxrIn29fYccsSsmXAACMiSDQ0PQ0BSzAQZRTdjpKvSnKwgAAgCuCQEOjYQUwBlXBnpYB7tu7WS+YVey+/f4AAGA8BIEGYrVa385m/Y6jS+UqEM2vYUI6Os9v72a//fr4AQBgzASBBqJuppshup3UdGsBAAAA0JGn+h4AAAAAAIcnE+hEdTRhziA9efEiIiKe/Wq+YEQlcAAAANAXQaATNeX+z/deX0ZExAgr4AAAAKA3gkADs2kQbap4AAAAoAVBoIHZNIgeUarQw9VFRESs+h0GAAAAjJog0Imbz/Mflj0O4sBml8uIuCr/Ojtb3y5j3sdwAAAAYJQEgU5cUe21fNznKLpV1/R6ljeC/gOxOPRQAAAAYDIEgTi6ciVbkfnzpWfmxRrHGwwAAABMhCAQvSsyf2avLtY/nJ/3NRQAAAAYLUGggSj3yZmPIFtmCv2OAAAA4FQIAg1EuU/OgzjvbSxd2cxuf97jIAAAAGAinup7AAAAAAAcnkwgjqZuVjAAAADgcASBOJpiVrBNL6CG2q4PAAAA3CYIxNFtegEdaH0AAADgNj2BAAAAACZAJtCp00gHAAAA6IAg0KkrGukAAAAA7EEQiNOTd4Ke9zoIAAAAGBdBoI4UVVsfeLL+4f5ri6Mc98mL6+P92P318RaRD2TI3ZTzsS96HQQAAACMiyBQR/7ap/5pPPX2p+Plv788zAGKedKXN+/fe7xesLxXrHig4wMAAACDJgi0pyIT5z//2/8g3nrqmyK+5UAHKjJ7zkv3H5/fWhUAAACgTBBoT/deX0ZExLfEm/FWvD0i3tHreFar9e2ji/Vt06qwopytcv3aFQAAAIBTJgjUkRRZREp9DyMuL9e3bScVq13fLGUAAAAwaIJAHcjeyiJFnEQQqHNFBhAAAAAwaIJAHdgEgZ7qLwhU9I0+WzVbvxzbebjKFxTLi7KvPAOoKDObXd+4YWmYOBIAAAD0TxCoA9lbb61/SE/1NoZNPGbZbP1yddfLl8s7ty/KzLZu3PJYAAAAwPEJAnUgeyuLiIh0xEygIrvm5fKCkmL2svuvLQ46HgAAAOC0CQJ1oYcgUJFdc3ZWWlBSzF52CoqSNQAAAOD4BIG6kOVBoKeP3xNoNjvs/lcNeww1YXZ5AAAA6I8gUBeyt+Ifxzsj/cu/Pt75+t/oezQRca3Rc0s3GkBHqRdQ13SMBgAAgKMRBOpClsWve+rvxre/9mos33ne92giImJWNHpu6aBBn7KihE2dGAAAABycIFAXsiz+yS97V3x73+O4Q9ukm1uNpyPi5//pr4g3X7yI+/dKK+1b56VODAAAAA5OEKgDKcviF9/xrhvLuoqPtFZk1ZQaRX/3KxcREfFotoiI+nKxbX2mv+2tfxhPv/6LEfM7VgIAAABOkiBQB1Jk8f+e3QwC9RYfKaJOj89vLC6Xh81jfb9p+dfZWcSb/6TYeL6+FQQCAACAwRAE6sRb8fVf+av7HkQrxaxiVXGccqbQbBax/Af5nSLQdH7e/cAAAACAgxAE2lMWEU9FFm/9qnUm0NnZYY93KwmnIivnzRfWy5/96np5VcbP6mx+436RMbRrY2kAAADgNAkC7Sl7K4sUEemZdRCoyLA5lFtJOBVZOfdfu7m8KuOn6BG02f/yfOt61236HdWuCQAAAJwKQaB9vZVFRMTb/oV31ax4UxFI+cCTixvL798vflrcuf2tWdU7mma9yAwqMoGK+0UPoYirgNJqtb6d9dYFGwAAAGhKEGhP2VtvRUTEL3+uXRCoCKS8/Pry5gP3ymtudyvesmcApogh/cR8vZ/5K+cRcZUp9GB+EfGTP3lj3U3FmAbRAAAAcPIEgfaU5ZlA3/zubhtDbxozd1xeVrXfWzGkZdxeIZ9xrFh3+bi7cQEAAACHJQi0rzwI9C0v3MwEuppda7G+aVoylafZzA6UXaPhMwAAAEyTINC+snUQ6FvfezMIdCvY0jSoUwSJ8qybg9nMKtZstYjr/YEAAACAoREE2lf2VmSR4pvf9c1bHz7ZmbQ2s4o1Wy3iWn+ghocofncAAACgf4JA+8qyyCJFeiqt7+epM8XMWbtWdW2blWsnm4yfPfezg+KQHU1cBgAAAOxBEGhfeRBoI0+debS8uVoRFHp0sb696hm03VXWzfl+4ztWeVmDIQAAAAD9EQTaU8qyiOtBoFw5+6VoEbSZGj5fUGT8FD2Ejl1CVZmls+WB8qKqbKXK36Fpc2wAAACgc4JAe/qF9K74+tt++a3l5TjHkyfziLgKpLz55vqHR/fWKy6W5xGxpYRq2ckw480X5luXV8ZjtjxQXlSVrVRZedZDSRoAAACwJgi0p9/x1l+Kb/zSN2rXu//aYn27WbK+X1XttQm4VDzeVnH8XugQDQAAAL0TBOrA029/eu99nJ2tb29VYY2hq7IMIAAAAOidINCJmM3Wt7eqsPTPAQAAADogCERnylVfmxnQZsceCQAAAFAmCNSzq2qvefVKA1Gu+ipmPAMAAAD6JwjUs6tqr0X1SgAAAAB7eqrvATAeD1cXVyVgAAAAwEmRCURnlH8BAADA6RIE4vjKHaQBAACAgxME4vjKHaQBAGinuKh21WDymJsDMFCCQBzf1ZRoAADsYs+Laq7JAUyTIBB7W61abuCSEwAAABydIBB7u7zsewQAAABAHVPEAwAAAEyATCAO5uystEAvIAAAAOiNIBAHM5vlPxTBH72AAAAAoDeCQBye4A8AAAD0ThCIzm2qvpY9DgIAAAC4QRCIzm0Sf857HAQAAABwg9nBAAAAACZAJhCdMRsYAAAAnC5BIDqzmQ2soCE0AAAAnAzlYAAAAAATIAgEAAAAMAGCQAAAAAATIAgEAAAAMAGCQAAAAAATIAgEAABDMZ+v/wOAHZgiHgAAhmKxWN+en++0eRE/Wi47GAsAg9MoEyil9L6U0udTSquU0g9WrHOeUlqmlD6bUnrS7TABAIB9LRZXcSQApqc2Eyil9HRE/EhEfE9EvBERn04pfSLLss9dW+edEfEnIuJ9WZb9XErp2w40XgAAAAB20CQT6DsjYpVl2ReyLPuliPh4RLy/tM73RcRfyLLs5yIisiz7SrfDBAAAAGAfTYJAz0bEF6/dfyNfdt2/EhHfmlJ6NaX00yml37NtRymlD6WUPpNS+sxXv/rV3UYMAAAAQGtNGkOnLcuyLfv5NyPit0XEOyLiJ1NKP5Vl2d+5sVGWfSQiPhIR8dJLL5X3wUCdneU/mKkCAAAATlaTINAbEfHua/efi4gvb1nnF7Is+8WI+MWU0l+NiF8fEX8nGL3ZLP9Bl0EAAAA4WU3KwT4dEe9NKb2QUnp7RHwwIj5RWucvRsS/lVJ6W0rpmyPiuyLiZ7sdKgAAAAC7qs0EyrLs6ymlhxHxqYh4OiI+lmXZZ1NK358//uEsy342pfSXIuJvRsRbEfHRLMt+5pADBwAAAKC5JuVgkWXZJyPik6VlHy7d/+GI+OHuhgYAAABAV5qUgwEAAAAwcIJAAAAAABMgCAQAAAAwAYJAAAAAABMgCAQAAAAwAY1mB4Nt5vPNT/0NAgAAAGhEEIidLRabn/obBAAAANCIcjAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAAACACRAEAgAAAJgAQSAAABiqi4v1f/1sDsDAvK3vAQAAADtaLvvcHICBkQkEAAAAMAGCQAAAAAAToBwMAADGomjws1jstFmh5eYADIQgEAAAjMWOTX70BgKYBuVgAAAAABMgCAQAAAAwAYJAAAAAABMgCAQAAAAwARpDAwDA0JWn9wKALQSBAABg6EzvBUADysEAAGBsLi72yg7ac3MATpRMIAAAGJs9M4MkFgGMk0wgAAAAgAkQBAIAAACYAOVgAAAwdPP5zfs71nMVu1EOBjBOgkAAADB0i8XN++fne+1mx80BOHHKwQAAAAAmQCYQAABMXLmaDIBxEgQCAICJK1eTATBOysEAAAAAJkAQCAAAAGACBIEAAAAAJkAQCAAAAGACBIEAAAAAJkAQCAAAxuriYv0fAIQp4gEAYLyWy75HAMAJkQkEAABsJZEIYFxkAgEAAFtJJAIYF5lAAAAAABMgCAQAAAAwAYJAAAAAABMgCAQAAAAwAYJAAAAAABMgCAQAAAAwAYJAAAAAABMgCAQAAGMzn6//62dzAE7U2/oeAAAA0LHFYn17ft7H5gCcKJlAAAAAABMgCAQAAAAwAYJAAAAAABMgCAQAAGN3cbH+D4BJ0xgaAADGqpjia7nscxQAnAhBIAAAGCvTfAFwjXIwAAAAgAkQBAIAAACYAEEgAAAAgAkQBAIAAACYAEEgAAAAgAkQBAIAAACYAEEgAACYmPl8/R8A0/K2vgcAAAAc12Kxvj0/73MUABybTCAAAACACRAEAgAAAJgAQSAAAACACdATCAAAhqajrs6aQwNMiyAQAAAMTdHZ+TR2A8BAKAcDAAAAmABBIAAAAIAJEAQCAAAAmABBIAAAAIAJEAQCAAAAmABBIAAAmIqLi/V/AEySKeIBAGDs5vP17XLZ5ygA6JkgEAAAjN1isb49P+9zFAD0TDkYAAAAwAQIAgEAAABMgCAQAAAAwAQIAgEAAABMgCAQAAAAwASYHQwAAKbm4mJ9W8wa1nKzQsvNAeiZIBAAAEzNcnnMzQA4EY3KwVJK70spfT6ltEop/eAd6/3GlNI3UkoPuhsiAADQp4uL21lAAAxPbSZQSunpiPiRiPieiHgjIj6dUvpElmWf27LefxsRnzrEQAEAgH4UGUDz+c37AAxLk3Kw74yIVZZlX4iISCl9PCLeHxGfK633n0XEn4+I39jpCAEAgF6Ugz5FD6Dz8+OPBYD9NQkCPRsRX7x2/42I+K7rK6SUno2ID0TEb407gkAppQ9FxIciIp5//vm2YwUAAI5I0AdgXJr0BEpblmWl+4uI+ENZln3jrh1lWfaRLMteyrLspWeeeabhEAEAAADYV5NMoDci4t3X7j8XEV8urfNSRHw8pRQR8a6I+J0ppa9nWfY/dzFIAAAAAPbTJAj06Yh4b0rphYj4UkR8MCK+7/oKWZa9UPycUnocET8uAAQAAABwOmqDQFmWfT2l9DDWs349HREfy7Lssyml788f//CBxwgAAHRhx+m9is0AGLYmmUCRZdknI+KTpWVbgz9Zlr28/7AAAIDO7djpudgMgGFr0hgaAAAAgIETBAIAAACYAEEgAAAAgAkQBAIAAACYAEEgAAAAgAkQBAIAAACYAEEgAAAAgAkQBAIAABiKi4v1f92sBkzM2/oeAAAAAA0tl12uBkyMTCAAAACACRAEAgAAGCllYcB1ysEAAABGSlkYcJ1MIAAAAIAJkAkEAABTVa4TWix22rzlZnSp5WvoNYNpEwQCAICp2rNWSKnRCWj5InjNYNoEgQAAAE5NTcpO8fDD1fp2Njv0gIAxEAQCAAA4NeWUnTzqs8qDPsWjl5dHGg8wCoJAAAAApy4PCgn6APsQBAIAAOhKqYyrde/t0gblsq86T17MN7hXd6Cth9MwGkZOEAgAAKZmPl/f6hLcvdJz2voprti+nAFUvISburDcvdfzBfNoxFsApkUQCAAApqZI9zg/32s3D1cXxQ7vXG/Q05JXpMrU/k6b7RZblz95sr57/7Wb+2va6Lk47vLx+nZVyhQqXptHs+0DLP9awDQIAgEAADuZXS4brTfobJOKwdf+TqUVrgJm6+X3Xt++elXPn7Ozuw9XbFesV/faDPo1AXYmCAQAAHBgTQNmldvXZAatzuYREfFgtj5OXZBHRSBMkyAQAACwn0HXe1U4Vr1Ufpxy4+dNeVdN8KdQlH09iPNG63dUEQgMjCAQAACwXdPgTimdZBQxoeJ3KqfMlHr97P275vudlcrAivKuTRlZORh0oCCV2cJg3ASBAACA7XasFRpViVE5ZWbf2b/KSkGmoqyrKB+bl6f/Kh24rldQW6N67YBbBIEAAIC9FKVLDSuXRmmTEVSzXnkWr02Q6fF5RFyVdS2W6/t1vYDqHge4ThAIAADYS9WMVlNyK4Nmk+Gzvikyduqeq2Kz1Wr9wyYTqHig8oA3dZ0hBIyDIBAAAEDXNmVk65siY6ccuykyiF4ub7Zc/7Bp9FxuzlPT0VmGELCNIBAAANDKpllx2a2ZrhbbHtZsOK4ydYqgUNELaJ4/fpX4s/nhTrfWr2jWXbWdXkAwDYJAAABAK0XT4nIT46qZrgqTDjTk0Zaz1TIibmfqXE3xvnYVKFtEE7fWL2UKlSc7K29nqniYBkEgAABgJ+Umxly5lXmTR1tmPT9XsrBg2gSBAABgqprWApXquMpNhzelTPnuiv09eTHf7t5ixwEOV1XmTedqDtD0JW7ZdxoYKEEgAACYqqa1QKWIQGUpU7671SsX6/Vez7eb7zS6UbiVeVOKyuzck6fYsCa1p3i4qidQeb2C8jAYJ0EgAACgU2MuE1sVTa/zQFjRJLv4ncuP31IKvO3ck6dlXZcyMCBCEAgAANhR21KjQZcY5b/EZTkr6vLm/cuKpthV+6u4C3AQgkAAAMBNdbVDuXIWS9Vmo5iBqvglHp9HxFUG0N772363O6V+TvSg4jXw0tAHQSAAAOCmqpSdmuDQoDN9WipnAJ2sKb0op6riNfDS0AdBIAAAYLtyHZdvrRvFDGmNy7+ObRQ1eEDXBIEAAIDtRlHHdRjFDGlFjGXv8rCuee2ALQSBAACAdnQxvpVpM5jyMGDSBIEAAIB2dLK91SgaYAgEgQAAgLWGs4Jx28n3CAIIQSAAAKBQ1US4ZflXsfrZap/BnKbV2TwiIub5/TdfyO/fW0ZExCureQCcKkEgAADgbi3LvzarLzsexwl4NFtERMSD/P7919b3iwbMxeMnq8j22rOkr6PdEJ5LjksQCAAAOCpfenvUcsr48mtV3DfzfHc8lxyTIBAAAExdaaargR+mV2P5Hat+j6H/XjB1gkAAADB1RZpHXtI08MP0aiy/41h+D+Cmp/oeAAAAAACHJxMIAABg7IpmPsCkCQIBAAC90CD6iDTzAUIQCAAAKGgQDTBqgkAAAMCaBtHQHSV4nCBBIAAA4KYiVaer1dV9DZ54xg6kunGCBIEAAICbWgZrKldX9zV4XkIYF0EgAADgMAZY9/XkxYuIiLh/r99xnIoBvoTAHQSBAAAAcvdeX65/mPc5CoDDEAQCAAAoWa3Wt7N+h8GEaJ3FMQgCAQAAlFxettyg1B27ZW9tJkzfJY5JEAgAAGBfpfQN2Rw0pe8SxyQIBAAAjE95TvPim3a+/CIWNx+O0vrQNfVenABBIAAAYHyqamvy5bcfrVh/6Mp1aTvWHHW0m2nzpHECBIEAAABKVmfziBjBJGHlrJMda4462s00afrDCREEAgAAxi8vxSlm/XqYl389mi22rl4sf3DYUTEFmv5wQgSBAACA8duUgc0jImJ2uextKAB9EQQCAAAmo8jwWSzPex0HQB+e6nsAAAAAAByeIBAAAADABCgHAwAAgKbyJuO3pkwrP3yEoUBbgkAAAMB4FdNzF5brm7Oz9e3D1UVERKwqNq/5vj95k3x+aqZ6n9xM8Pmb4KIU9prUe2JABIEAAIDxKn8TPV/fzGbr28v8G/tlabMidjS5L/QNeX7Y2My8xxAIAgEAAJQUsaPz8z5Hcbo8PzBMgkAAAMBkrc7mERExz/MYLsspQQAjIggEAAAcR0UDmT77yjyarQ/6al4nprwJGDNBIAAA4DgqIiwnEXjJm9ycrZZbHy4CVcD4PHnxIiIi7r+26HUcxyAIBAAAkKchzZbnWx8uAlXlycaA4bv3+rLvIRyNIBAAAEBDpr1mo5we1vDNUZdV1md5ZCvS4wZJEAgAADisivnEDzLNeMUXU99X6dyOb9y6rLKTKI+MuBWNuhWcOpmB0oYgEAAAcFgV84kfZJrxpn2H8m/g8w4PDW2UM30OEhTdR2kgJzMu9iIIBAAADF/bVJ/8G/ii63HAjg4SFD2ATUZQn4NgZ4JAAADA8JXTFHRwhoOQETRsgkAAAMD4nHxXXUZnk4222Lr45tIYUAfomx6uLtY/zNY3q1W+PNbLH80Wxx4SLQgCAQAAx1Xx5beT78Q1GUAShDiYpv2oah84bbPL5Y37l5f58ljeWpfTIwgEAAAcV9svy23URJAGlnQBpyuPqBaZQHNBoEEQBAIAAIADK5dNFeVUJ6+qzC2/v8x/j1fj/EgDYh+CQAAAAHBgy5hHxAAzZmoy9zYllttX48QIAgEAAMNVMzV825njJ6PjpsQD7XF8EEXj5FWxIM+UKRomjy1jZvOan69vNo2jTSJ/kgSBAACAYdgW0XnllYjZ7bqaYtXWfYZKnaNH20i6eGI6it4MtMfxQRSNky/7Hcbx5SfLzJvhpAkCAQAAx1FEVEpfEisW37ZthWJqolK0prxq42BOKRgyusyW8pPtC/vBrM7mN+5fvQfzH8b23Bcny+PzPkdBDUEgAADgOIoviefnTRbvtu/dHp6OTp5smijKvwpX78H8h4G9BldlXkdWk62mFLEdQSAAAGBYrqf1vPnmnWk+oy3n2lfj9Kuj7GYcSlOmj01R5nZ0NW8u7712BIEAAIBhaXHJX3ZAhY4ygiQWXZM/GY+W67sCkJwiQSAAAOC03THFl1IQTpX35G6evHgRERH3729/3Dm/H0EgAADgtN1R76EUhN5MJdXnyDV/917Pj3Nv++PO+f0IAgEAAEBbU0lFOdFZv+5IEOQOgkAAAMBpavEtT4nInjyBDIyMoN0IAgEAAKepxbc8Xwh3ZHovmBRBIAAAYDSUiLRkei+YFEEgAABgNIqElqn07IVjWZ3NIyLimWfW93c9x4pA7QeerH+4/9ri5gPF8Vbr29lst+OwnSAQAAAwOlrbQLcezRYREfHqq+v7FTO41yoCtS8Xs4CVH8hdXu54AO4kCAQAAACsHaimstjtw9Vh9k8zgkAAAADA2oFqKjcZQJfLTvdLO4JAAAAAMFV5is6TJ+u79+/ly/esqSwyf4rdVGUAPXnx4uZxOzpg+fisCQIBAADAVOUpOvdez+/PO93txqwiA+he0Rto3+OWDlg+PmuCQAAAwOAVlSu++EG/zs6Ocxzn/G4EgQAAgH6U6jWKcpGLi/X9Rb5a1VTRFxfrx2azq5KP8/NDDBTGqzi/unKwKd03DasX6/+vb+KV5/Ll+XGL8rK4tzjQQIZNEAgAAOhH6RL+plzklYt8wfqmPFV08V1wuTSNNOzr0OdQEZQpt/wpMoZqj1+T8lMuM+usvGykBIEAAICTUv5StzqbR0Sz8o+OJzQC9rQJypQUGUO15VxN0/zUhzUiCAQAAPRrU+ZxU1Gm8mi2iIiIB4v8gfPqXZkJCPazKb/sdxgbm6rRqgcKxcn/+PyAoxm+RkGglNL7IuKPRcTTEfHRLMt+qPT4fxwRfyi/exkR/2mWZX+jy4ECAAAjVbpy37hMBOjc0c67hpk7lQ/L+NlJbRAopfR0RPxIRHxPRLwREZ9OKX0iy7LPXVvt9Yi4n2XZP04pfW9EfCQivusQAwYAAMatcZkIcLKKRu+VZO70okkm0HdGxCrLsi9ERKSUPh4R74+ITRAoy7K/dm39n4qI57ocJAAAMCIVGQDHmloaTkpplryaxYNR7u3VlU1w6VTq1QamSRDo2Yj44rX7b8TdWT6/PyL+l30GBQAAjFjxrfb6NF9xe2rpoiF0lfk84s03NYNmoCqCoYPvb9zRL1AVFN4Elwb/RPWjSRAobVmWbV0xpd8S6yDQd1c8/qGI+FBExPPPP99wiAAAwCjVzPpTNISu2xwGqeL933QyrJO1Y5lX0ZC6cCsoXHpcOdlumgSB3oiId1+7/1xEfLm8Ukrp34iIj0bE92ZZ9n9v21GWZR+Jdb+geOmll7YGkgAAAKBzVbNJ1aw+lWDjsRqyv/nCfOvyuuPWPV68Xi+3HdDENAkCfToi3ptSeiEivhQRH4yI77u+Qkrp+Yj4CxHxu7Ms+zudjxIAAJgc1R50quUbaWrvu2M1ZL//2mLr8qL885lniiXbB1IuEyu2K8att9jdaoNAWZZ9PaX0MCI+Fesp4j+WZdlnU0rfnz/+4Yj4ryPiV0fEn0gpRUR8Pcuylw43bAAAYOwGXxYDI1BOoDqUovzz1VfzBRUnfrlMrFw2Wn6cm5pkAkWWZZ+MiE+Wln342s9/ICL+QLdDAwAAJkHKD5ys4rRs24C9aXlZUR5Wtf/N8mW747NdoyAQAADAwTRM+TlWRgITUTM1e+X6E9W2N1LT8rKiPOx+zXGXj9sdn+0EgQAAgJMmUYhO1byhKt9nu6bE0C3P/14EgQAAgJOmNxCd2vcNNZXpwjpyu+Hznjz/exEEAgAAYLpulXkttj68iHEofp8PPFn/cO/Ax7vV8JleCQIBAAAwXTV1hmMrQyx+n5dfX/9QZOrMdV6eBEEgAABgULQEgf0Vs3f9xINFREQ8WJ53e4D8RJ3vuX2hGC/7EQQCAAAGRUsQaO6qnC3/IS9sK2bv2pxP5x0fON/x4s6V6rcvFONt6uHqIiIinry4vl/MQjZ1gkAAAABMTzmlrFT3NZZZ6a7Gv6xeacCqXqfZZb7g8oiDGQBBIAAAAKannFJWmi2sPInYarW+bZmQwoGZPbAdQSAAAACoUGSaFIklp6482VlRFlVEr8r3B6OmGdjm4eX6pmh4PRvKC3ckgkAAAABQocg0WT7ucxTNlcuiXi4FQTZBkaF1WK9pBrZ5+GIeERE/MV8vmD0+P9CAhkkQCAAAAHKbTJmKlsabRsvbH97dwXa8VpSzbYy1w3qpIfVQgnfHIggEAAAAubryoYM1ij7Qjoup1S81SCYEgQAAANhVnr3ycJNlsthl842xJqfsoiojqSphqFhebPdotl6hmFp96LOc0Q1BIAAAAHaTRxZmO2aZnFJg4la5VM+qMpKqnrPvfuXixnZ/9M31/bi3vmnbKLkcoBu8A5fbDYUgEAAAcBqazv4DB1CUSxXlU0dTvLH3jIgVwZ0i2PPg3s39FZlBi+X5neM4Wy27GM7pGd0vtBtBIAAA4DQ0nf0HDqgon6rLHOmslK3Y8Px8t+1LAymCPQ+i5f7yccyqgkRjMfGMIEEgAAAAKKvJHDmZxJJ8IEUG0C2bTKOG+8vXr9jb8J3MC9cPQSAAAAAYuCID6JY842V+kd9f1uyoNMU64yIIBAAAAKeiVN7VVYPmovpp+bib/TFMgkAAAABwKkrlSm2rl64aqM+3Pv7mC9uXMw2CQAAAAHDiHq4uIuJa2VdFitBVv+PF1sfvv7Z9OdMgCAQAAAAtdTSze60i+FNMAV/cX+VTuX/pmXwg9w47jqFbrda3m9nfJkoQCAAAAFrad2b3SqXoUhH8OTuLG/eX+Wxgj+4tOh7AOF1e9j2C0yAIBAAAAKeiiC49Pr+xuMhgKTKPKmcDo5minO6qfm4SBIEAAADoxp5frDv9Xl6xs/Li4v7LHRzyGKoaO8+3L5684vn66lfX9+exXP9w6Dq+EyUIBAAAwF5WeWnSfMcv1gfpr1Oxs/Li4n5RblU3mL6DLZvGzuc3l08soaWx4vkqyvYezC/WPwgCAQAAQHtFadKDcmSioYP112lh0zC4ZjCCLQN3Cm+2Hj3V9wAAAAAAODxBIAAAAIAJUA4GAADAeBWdn+vUNPvZ9Aw6sr6OyzgJAgEAADBeRQPgTcPnivVqmv1segYd2ea4fXekZhQEgQAAABi2PNvnIhabRQ9XpcDNpiHwkcbUNR2p6YAgEAAAAMOWZ/ssry26vOxjIHsoZfooAzuMojpw0ecgeiQIBAAAAH0rZfrMHszXPxTlbCXzux+mxPO1JggEAAAAVRo2lm7af7qxTfna+S4PU+L5WhMEAgAAgLKGqSMyTBgSQSAAAAC6tWm8suhzFPtpmDoiw4QhEQQCAACgW9JiGICL1cOIi4iX+x7IEQkCAQAAAJOzvJzdnFJuAgSBAAAAGKbOuzHDuAkCAQAAcFjlYE1Nr6DGqys7g1YEgQAAADislsEasZ1riunHdnsYbhAEAgAAoJm2s36VUnpWq/XtrKvxTEHNcz3kCdg4PkEgAAAAmqlL0SnSUor1itt8+aUUH+iVIBAAAADdKNJSzs9vLL6I9fKXY738FPo5n8IY4NgEgQAAAGinZQSlSAA6O7t5v6ycSLSrh6uLePZrq4iYbUrQHl1sHxNMiSAQAAAA7ZTKvGJZerwimjOraQZUkUjU2uxyGe/4xmVERFxebh0KTJIgEAAAALvZRG2qlpcfOKyHq4ujHo/hWq0ivva1iHf0PZAjEwQCAADgMCoyherKvnYtC5tdttyAySneW5fLiD/4//1wvH31TJ/DOTpBIAAAAA6jIlOoLlGodSJRV82EGL3ivbV8HPFrs8/H05df6nM4RycIBAAAQCeKftHFF+3aFePuFa/Ku7avVzR9nr2aP/74vObAMG2CQAAAAHSiNhGnZcZOXXlX0fS5ieLQBUlDTJEgEAAAANs1Tu25e/ONnhpGXz90oYchQO8EgQAAANiuSJe5Fc1pt/mhFcN7+ZAHKacSwQAJAgEAAHC3E6+dKoZ3dra+vbyM+NrTZ3E2n2/6Bs1L27SO6eyYDQWnRBAIAACAXtQ1fq5Slfkzm61vl8uIL71jFs8sFvFouV72oLSumA5TJAgEAADAQVVl3dQ1fq5y4olJcLIEgQAAALhpxx5AVWTdwGkQBAIAAOCmcqpN102R8/2drZZ3rlbYc5Ky/TT83fWNZggEgQAAALhb19GXfH+z5fmdqxWNnnst/2r4u8t2YggEgQAAAOhXRapP0ei5vBqwG0EgAAAA1spRlmPVODVM9dEQGvYjCAQAAMBaOcqixglGRRAIAACA0fnhrz2MZy76HgWcFkEgAAAA+lGUm9XUeTVc7YbPf2MWX2qxPkyBIBAAAAD9KMrNzs+7WA2o8VTfAwAAAIAunZ1FPP1036OA0yMIBAAAMHXz+V4zge25eedms4h3vKPvUXDKzs4iIvU9iuNTDgYAADB1e9ZbKddiaGaziOU/6HsUxycIBAAAQKcuLnrawbUO0vOzVcR83qqZNIydIBAAAACdKgIvO5eI7Rq5uZaStJg9ilg8kJ0E1wgCAQAAcBBFTAY4DYJAAAAAjMu1FKRTalgNfRMEAgAA4DRU9QLaLF9ERMTDVcV6hWspSLKR4IogEAAAAKehqhdQvrwI/swu1/dXZ/NDjwhGRRAIAACAQSgHfx7NFr2NBYZIEAgAAIBBEfyB3QgCAQAAcJpKXZ1XqzsfhlZWT//aiLNnNhlmUyAIBAAAwGkqdXV+tLzzYWhuPo+fePMDEffvx+zxed+jORpBIAAAAGBaFot8rrmI5eMex3FkgkAAAAD0q6jrKmYHU+cFByEIBAAAQL+Kuq7z85v3gU4JAgEAAHAaajKAJAhxCG++MO97CEcjCAQAAMBpqMkAkiDEIdx/bdH3EI7mqb4HAAAAAMDhyQQCAADgJnVXMEqCQAAAANyk7gpGSTkYAAAAwAQIAgEAAABMgCAQAAAAwAQIAgEAAABMgCAQAAAAwAQIAgEAAABMgCAQAAAAwAQIAgEAAABMgCAQAAAAwAQIAgEAAABMgCAQAAAAwAQIAgEAAABMwNv6HgAAAADjMp/3PQJgG0EgAAAAOrVY9D0CYBvlYAAAAAATIAgEAAAAMAGCQAAAAAATIAgEAAAAMAGCQAAAAAATIAgEAAAAMAGCQAAAAAATIAgEAAAAMAGNgkAppfellD6fUlqllH5wy+MppfTH88f/ZkrpN3Q/VAAAAAB2VRsESik9HRE/EhHfGxHfERG/K6X0HaXVvjci3pv/96GI+JMdjxMAAACAPTTJBPrOiFhlWfaFLMt+KSI+HhHvL63z/oj4U9naT0XEO1NK397xWAEAAADY0dsarPNsRHzx2v03IuK7GqzzbET8/PWVUkofinWmUDz//PNtxwoAAMAhzed9bg4cWJMgUNqyLNthnciy7CMR8ZGIiJdeeunW4wAAAPRosehzc+DAmpSDvRER7752/7mI+PIO6wAAAADQkyZBoE9HxHtTSi+klN4eER+MiE+U1vlERPyefJaw3xQRb2ZZ9vPlHQEAAADQj9pysCzLvp5SehgRn4qIpyPiY1mWfTal9P354x+OiE9GxO+MiFVE/LOI+H2HGzIAAAAAbTXpCRRZln0y1oGe68s+fO3nLCJ+oNuhAQAAANCVJuVgAAAAAAycIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABAgCAQAAAEyAIBAAAADABKQsy/o5cEpfjYi/38vBu/euiPiFvgcBJ8Z5Ads5N2A75wbc5ryA7Zwbd/uXsix7ZtsDvQWBxiSl9Jksy17qexxwSpwXsJ1zA7ZzbsBtzgvYzrmxO+VgAAAAABMgCAQAAAAwAYJA3fhI3wOAE+S8gO2cG7CdcwNuc17Ads6NHekJBAAAADABMoEAAAAAJkAQCAAAAGACBIH2kFJ6X0rp8ymlVUrpB/seDxxTSuljKaWvpJR+5tqyX5VS+ssppb+b337rtcf+cH6ufD6l9Dv6GTUcVkrp3Sml/z2l9LMppc+mlP5gvty5waSllH55Sumvp5T+Rn5u/NF8uXODyUspPZ1Sei2l9OP5fecFk5dS+nsppb+VUlqmlD6TL3NudEAQaEcppacj4kci4nsj4jsi4nellL6j31HBUT2OiPeVlv1gRPyVLMveGxF/Jb8f+bnxwYj41/Jt/kR+DsHYfD0i/ossy/7ViPhNEfED+fvfucHU/fOI+K1Zlv36iJhHxPtSSr8pnBsQEfEHI+Jnr913XsDab8mybJ5l2Uv5fedGBwSBdvedEbHKsuwLWZb9UkR8PCLe3/OY4GiyLPurEfGPSovfHxE/mv/8oxHxH1xb/vEsy/55lmWvR8Qq1ucQjEqWZT+fZdn/lf/8T2P9R/2z4dxg4rK1y/zuN+X/ZeHcYOJSSs9FxL8TER+9tth5Ads5NzogCLS7ZyPii9fuv5Evgyn7NVmW/XzE+stwRHxbvtz5wuSklN4TES9GxP8Zzg0oSl6WEfGViPjLWZY5NyBiERH/ZUS8dW2Z8wLWFwr+15TST6eUPpQvc2504G19D2DA0pZl2dFHAcPgfGFSUkpnEfHnI+Iiy7J/ktK2U2C96pZlzg1GKcuyb0TEPKX0zoj4sZTSv37H6s4NRi+l9O9GxFeyLPvplNJ5k022LHNeMFa/OcuyL6eUvi0i/nJK6W/fsa5zowWZQLt7IyLefe3+cxHx5Z7GAqfiH6aUvj0iIr/9Sr7c+cJkpJS+KdYBoD+TZdlfyBc7NyCXZdn/ExGvxrpvg3ODKfvNEfHvp5T+XqxbS/zWlNKfDucFRJZlX85vvxIRPxbr8i7nRgcEgXb36Yh4b0rphZTS22PdiOoTPY8J+vaJiPi9+c+/NyL+4rXlH0wp/bKU0gsR8d6I+Os9jA8OKq1Tfv6HiPjZLMv++2sPOTeYtJTSM3kGUKSU3hER/3ZE/O1wbjBhWZb94SzLnsuy7D2x/i7xv2VZ9p+E84KJSyn9ipTStxQ/R8Rvj4ifCedGJ5SD7SjLsq+nlB5GxKci4umI+FiWZZ/teVhwNCmlPxsR5xHxrpTSGxHxRyLihyLiz6WUfn9E/FxE/IcREVmWfTal9Oci4nOxnj3pB/KyABib3xwRvzsi/lbe+yQi4r8K5wZ8e0T8aD5by1MR8eeyLPvxlNJPhnMDyvybwdT9mliXDUesYxb/U5Zlfyml9OlwbuwtZZlSOQAAAICxUw4GAAAAMAGCQAAAAAATIAgEAAAAMAGCQAAAAAATIAgEAAAAMAGCQAAAAAATIAgEAAAAMAH/P/yuf/l3qokFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Candles -> points\n",
    "JIT_enabled = False\n",
    "\n",
    "#@jit(nopython=True, parallel=False)\n",
    "def candlesToPoints(candles, ds_size=-1):\n",
    "\n",
    "    point_sequence = candles[:ds_size, 0:2].flatten()                           # create HLHLHL... sequence                              \n",
    "    \n",
    "    mask = np.ones(point_sequence.shape, np.bool8)\n",
    "    \n",
    "    for i in range(len(point_sequence)-1):                                     # remove double H/Ls using mask\n",
    "        if point_sequence[i] == point_sequence[i+1]:\n",
    "            mask[i] = False\n",
    "            \n",
    "    point_sequence = point_sequence[mask]                                       # apply mask\n",
    "    mask = np.ones(point_sequence.shape, np.bool8)\n",
    "    \n",
    "    for i in range(len(point_sequence)-3):                                     # remove double moves\n",
    "        if not mask[i]:\n",
    "            continue\n",
    "        \n",
    "        if (point_sequence[i] == point_sequence[i+2]) and (point_sequence[i+1] == point_sequence[i+3]):\n",
    "            mask[i] = False\n",
    "            mask[i+1] = False\n",
    "            \n",
    "    return point_sequence[mask] \n",
    "    \n",
    "\n",
    "def fixGaps(candles):\n",
    "  \n",
    "    candle_count = candles.shape[0]\n",
    "    \n",
    "    for i in range(candle_count-1):\n",
    "        c1, c2 = candles[i], candles[i+1]\n",
    "        \n",
    "        if c2[1] < c1[0]:                       # second candle high is lower than first candle low\n",
    "            candles[i+1, 1] = c1[0]             # fill the gap\n",
    "            \n",
    "        if c2[0] > c1[1]:                       # second candle low is higher than first candle high\n",
    "            candles[i+1, 0] = c1[1]\n",
    "    \n",
    "    return candles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# M1 Candles -> M15 candles\n",
    "@tf.function(jit_compile=JIT_enabled)\n",
    "def convertToTimeframe(candles, TF = 15):\n",
    "    candles_count = tf.shape(candles)[0] // TF      \n",
    "\n",
    "    tmp = candles[:candles_count*TF]\n",
    "    \n",
    "    tmp = tf.reshape(tmp, [candles_count, TF, candles.shape[1]])[:, :, :2]     # split into 15m intervals  (N,15,2)\n",
    "    tmp = tf.reshape(tmp, [candles_count, TF * 2]) # flatten last two axes to (N, 30), this contains both highs and lows\n",
    "\n",
    "    lows = tf.reduce_min(tmp, axis=-1, keepdims=True)             \n",
    "    highs = tf.reduce_max(tmp, axis=-1, keepdims=True)\n",
    "\n",
    "    return tf.concat((lows, highs), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=JIT_enabled)\n",
    "def vec2fourier(seq, emb_dim=8):\n",
    "    sequence_length = tf.shape(seq)[0]\n",
    "    seq = tf.reshape(seq, [-1])\n",
    "    \n",
    "    x = tf.cast(seq * 3.14159265358, dtype=tf.float32)   # 0...2PI\n",
    "    \n",
    "    w = tf.range(emb_dim, delta=1, dtype=tf.float32)\n",
    "    w = tf.math.pow(2.0, w)                         # 1, 2, 4, 8...\n",
    "    \n",
    "    w = tf.expand_dims(w, axis=0)\n",
    "    w = tf.tile(w, multiples=(tf.shape(x)[0], 1)) \n",
    "\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    x = tf.tile(x, multiples=(1, emb_dim)) \n",
    "\n",
    "    seq = tf.concat([tf.math.sin(x * w), tf.math.cos(x * w)], 1)\n",
    "    \n",
    "    seq = tf.reshape(seq, [sequence_length, -1])\n",
    "    return seq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def check_reaction(PA : tf.Tensor, entry : tf.float32, stop : tf.float32, RR = 2.0):          # exception for unnormalized PA\n",
    "    \"\"\"\n",
    "    Input - price - normalized to 0-1\n",
    "    Output - [Win_prob, Loss_prob]\n",
    "    \"\"\"\n",
    "    \n",
    "    seq_len = tf.shape(PA)[0]\n",
    "    \n",
    "    entry_size = tf.abs(entry-stop)\n",
    "    tg = entry + RR * entry_size     # only for longs\n",
    "    \n",
    "    beyond_stop_inv = tf.greater(tf.reduce_min(PA, axis=1), stop)      # mask of points that are below stop level, inverted\n",
    "    beyond_target_inv = tf.less(tf.reduce_max(PA, axis=1), tg)\n",
    "    \n",
    "    #tf.print(\"min_PA\", tf.reduce_min(PA, axis=1))\n",
    "    \n",
    "    #tf.print(\"beyond stop\", beyond_stop_inv)\n",
    "    #tf.print(\"beyond target\", beyond_target_inv)\n",
    "    \n",
    "    #tf.print(\"PA\", tf.shape(PA))\n",
    "    #tf.print(\"beyond\", tf.shape(beyond_stop))\n",
    "\n",
    "    indices_stop =   tf.cast(tf.range(0, seq_len, 1), tf.float32) + tf.cast(beyond_stop_inv, tf.float32)   * tf.cast(seq_len, tf.float32)   \n",
    "    indices_target = tf.cast(tf.range(0, seq_len, 1), tf.float32) + tf.cast(beyond_target_inv, tf.float32) * tf.cast(seq_len, tf.float32)  \n",
    "    # indices of values higher than stop get added a constant (seq_len) to it -> become higher than other indices\n",
    "\n",
    "   \n",
    "    stop_index = tf.cast(tf.reduce_min(indices_stop), tf.int32)\n",
    "    tg_index   = tf.cast(tf.reduce_min(indices_target), tf.int32)\n",
    "    \n",
    "    #tf.print(\"stop/tg index\", stop_index, tg_index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (stop_index >= seq_len) and (tg_index >= seq_len):\n",
    "        return tf.constant([1.0 / (1.0 + RR)])                      # neither stop nor target got hit\n",
    "    \n",
    "    if stop_index < tg_index:\n",
    "        return tf.constant([0.0])                                   # stop hit first\n",
    "    \n",
    "    if stop_index > tg_index:\n",
    "        return tf.constant([1.0])                                   # target hit first\n",
    "    \n",
    "    return tf.constant([1.0 / (1.0 + RR)])                          # both stop and tg hit in a single candle (stop_index == tg_index) -> can't tell\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=JIT_enabled)\n",
    "def amplitudeAugment(x : tf.Tensor):\n",
    "\n",
    "    shift = tf.random.uniform(shape=(1, 1), minval=0.0, maxval=2.0, dtype=model_dtype) \n",
    "    mul = tf.random.uniform(shape=(1, 1), minval=0.6, maxval=1.4, dtype=model_dtype)    \n",
    "    \n",
    "    shift = tf.tile(shift, multiples=(tf.shape(x)[-2], tf.shape(x)[-1]))        # expand the last dimension\n",
    "    mul = tf.tile(mul, multiples=(tf.shape(x)[-2], tf.shape(x)[-1]))            # expand the last dimension\n",
    "    \n",
    "    return tf.multiply(x, mul) + shift\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=JIT_enabled)\n",
    "def ratioAugment(x : tf.Tensor):\n",
    "    boundary = tf.random.uniform(shape=(1,), minval=0.0, maxval=1.0, dtype=model_dtype) \n",
    "    shift = tf.random.uniform(shape=(1,), minval=-0.5, maxval=0.5, dtype=model_dtype) \n",
    "    \n",
    "    x_shape = tf.shape(x)\n",
    "    x = tf.reshape(x, [-1]) # flatten\n",
    "    \n",
    "    mask = tf.cast(tf.math.greater(x, boundary), dtype=model_dtype) # draw price boundary\n",
    "\n",
    "    boundary_expanded = tf.tile(tf.expand_dims(boundary, axis=-1), multiples=(1, tf.shape(x)[-1]))\n",
    "    tmp = tf.math.multiply(x - boundary_expanded, shift)                # Center at boundary, then mult\n",
    "    \n",
    "    x = x * (1.0 + tf.math.multiply(mask, tmp)) \n",
    "    \n",
    "    x = tf.reshape(x, x_shape)    # reshape back to original, now we can look at H/Ls separately\n",
    "    \n",
    "    max_amp = tf.reduce_max(x)          # now normalize back to [0, 1]\n",
    "    min_amp = tf.reduce_min(x)\n",
    "    \n",
    "    return (x - min_amp) / (max_amp - min_amp + 1e-6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def timeStretchAugment(x : tf.Tensor, min_TF : tf.int32, max_TF : tf.int32, output_length : tf.int32):\n",
    "    \n",
    "    input_size = tf.shape(x)[0]    \n",
    "    \n",
    "    intervals = tf.cast(tf.random.uniform(shape=(output_length-1,), minval=min_TF, maxval=max_TF, dtype=tf.int32), tf.float32)  # leave one slot for adjustment\n",
    "    \n",
    "    interval_lengths = intervals * tf.cast(input_size-2, tf.float32) / tf.reduce_sum(intervals) # one for adjustment, don't want to have very small interval\n",
    "    intervals = tf.cast(tf.math.floor(interval_lengths), tf.int32)\n",
    "    \n",
    "    adjust_amount = tf.expand_dims(input_size - tf.reduce_sum(intervals), axis=0)   # calculate residual interval\n",
    "    intervals = tf.concat([intervals, adjust_amount], axis=0)\n",
    "\n",
    "    slices = tf.RaggedTensor.from_row_lengths(x, intervals, validate=False)  \n",
    "    \n",
    "    \n",
    "    c_min = tf.cast(tf.math.reduce_min(slices, axis=1, keepdims=False), dtype=tf.float32)              # compute H/Ls, keepdims=False doesn't work for some reason\n",
    "    c_max = tf.cast(tf.math.reduce_max(slices, axis=1, keepdims=False), dtype=tf.float32)\n",
    "    \n",
    "    res = tf.concat([c_min, c_max], axis=1)\n",
    "    \n",
    "    c_min = tf.math.reduce_min(res, axis=1, keepdims=True)         \n",
    "    c_max = tf.math.reduce_max(res, axis=1, keepdims=True)\n",
    "\n",
    "    return tf.concat([c_min, c_max], axis=1)\n",
    "\n",
    "    \n",
    "      \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "#       Napady\n",
    "#   BarlowTwins augmentation - jedna PA, 2 nebo vic augmentovanych verzi musi mit stejny embedding vektor\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def simple_aug(x : tf.Tensor): \n",
    "    \n",
    "    max_amp = tf.reduce_max(x)          # now normalize back to [0, 1]\n",
    "    min_amp = tf.reduce_min(x)\n",
    "    \n",
    "    x = (x - min_amp) / (max_amp - min_amp + 1e-6)\n",
    "\n",
    "    for i in tf.range(5):   # 5 times\n",
    "        x = ratioAugment(x)\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "@tf.function(jit_compile=False) # random sequencing doesn't work with JIT\n",
    "def get_random_seq(samples : tf.Tensor) -> tf.Tensor:       \n",
    "\n",
    "    dataset_size = tf.shape(samples)[0]\n",
    "    sequence_length = 512 * 15\n",
    "    \n",
    "    \n",
    "    i = tf.random.uniform([], minval=0, maxval=dataset_size - sequence_length * 2 - 1, dtype=tf.int32)\n",
    "     \n",
    "    seq = samples[i:(i+sequence_length)]\n",
    "    \n",
    "    direction_flip = tf.cast(tf.squeeze(tf.random.uniform([], minval=0.0, maxval=1.0, dtype=tf.float32)) > 0.5, tf.float32) * 2.0 - 1.0\t# result either -1.0 or 1.0\n",
    "    seq = seq * direction_flip\n",
    "\n",
    "    \n",
    "    min_val = tf.math.reduce_min(seq)\n",
    "    max_val = tf.math.reduce_max(seq)\n",
    "    \n",
    "    seq = (seq - min_val) / (max_val - min_val + 1e-6)\n",
    "    seq = tf.cast(seq, dtype=tf.float32) \n",
    "\n",
    "    return seq      \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def get_random_trade(samples : tf.Tensor):      \n",
    "    \n",
    "    dataset_size = tf.shape(samples)[0]\n",
    "    \n",
    "    sequence_length = 128\n",
    "    look_ahead_length = 512     # how far in future to look for reaction\n",
    "    \n",
    "    timeframes = tf.constant([225, 15])       # in minutes, descending order\n",
    "    \n",
    "    ################# Pick random place\n",
    "    \n",
    "    left_index_boundary = sequence_length*timeframes[0]\n",
    "    right_index_boundary = dataset_size - look_ahead_length - 1\n",
    "    \n",
    "    i = tf.squeeze(tf.random.uniform([], minval=left_index_boundary, maxval=right_index_boundary, dtype=tf.int32))  # anchor, where PA ends (where the trade is taken) starts\n",
    "    \n",
    "    \n",
    "    ################# Gather data\n",
    "    \n",
    "    LTF_PA = samples[i-sequence_length*timeframes[1]:i+look_ahead_length*timeframes[1]]   # take both LTF PA and Future PA so we can normalize them together, then separate again\n",
    "    HTF_PA = samples[i-sequence_length*timeframes[0]:i]\n",
    "    \n",
    "    \n",
    "    ################# Augmentations\n",
    "    \n",
    "    LTF_PA = timeStretchAugment(LTF_PA, min_TF=7, max_TF = 23, output_length = sequence_length+look_ahead_length)\n",
    "    HTF_PA = timeStretchAugment(HTF_PA, min_TF=7, max_TF = 23, output_length = sequence_length)\n",
    "\t\n",
    "\n",
    "    #TF = tf.cast(tf.shape(HTF_PA)[0] // sequence_length, tf.int32)\n",
    "    #HTF_PA = convertToTimeframe(HTF_PA, TF = TF)\n",
    "\n",
    "    LTF_PA = simple_aug(LTF_PA)\n",
    "    HTF_PA = simple_aug(HTF_PA)\n",
    "    \n",
    "    ################# Align future PA\n",
    "    \n",
    "    future_PA = LTF_PA[sequence_length:]\n",
    "    LTF_PA = LTF_PA[:sequence_length]\n",
    "    \n",
    "    # Normalize the whole sequence so pred_PA is in the range 0-1\n",
    "    min_val = tf.math.reduce_min(LTF_PA)\n",
    "    max_val = tf.math.reduce_max(LTF_PA)\n",
    "    \n",
    "    LTF_PA = (LTF_PA - min_val) / (max_val - min_val + 1e-6)                      # normalizujeme PA a Future_PA do stejnych souradnic\n",
    "    future_PA = (future_PA - min_val) / (max_val - min_val + 1e-6)\n",
    "    # Use values from pred_PA to normalize future_PA\n",
    "    \n",
    "\n",
    "    \n",
    "    ################# Align PA so most recent value is 0\n",
    "    \n",
    "    LTF_entry = tf.random.uniform([], minval=LTF_PA[-1, 0], maxval=LTF_PA[-1, 1], dtype=tf.float32)         # entry inside the last candle H and L\n",
    "    #LTF_entry = minval=LTF_PA[-1, 0] - 0.01\n",
    "    \n",
    "    LTF_PA = (LTF_PA - LTF_entry)   # so entry will always be at price 0.0 \n",
    "    future_PA = (future_PA - LTF_entry)  \n",
    "    \n",
    "    HTF_entry = tf.random.uniform([], minval=HTF_PA[-1, 0], maxval=HTF_PA[-1, 1], dtype=tf.float32)\n",
    "    HTF_PA = (HTF_PA - HTF_entry)\n",
    "    \n",
    "    \n",
    "    \n",
    "\t################# Randomly flip the chart to account for shorts as well\n",
    "\t\n",
    "\t\n",
    "    direction_flip = tf.cast(tf.squeeze(tf.random.uniform([], minval=0.0, maxval=1.0, dtype=tf.float32)) > 0.5, tf.float32) * 2.0 - 1.0\t# result either -1.0 or 1.0\n",
    "    \n",
    "    #direction_flip = 1.0\n",
    "    HTF_PA = HTF_PA * direction_flip\n",
    "    LTF_PA = LTF_PA * direction_flip\n",
    "    future_PA = future_PA * direction_flip\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "    ################# Generate entry, stop levels and check the outcome of this trade (only on LTF)\n",
    "    min_stop_size = 0.1\n",
    "    max_stop_size = 0.3\n",
    "    RR = 1.0\n",
    "    \n",
    "    entry_size = tf.random.uniform([], minval=min_stop_size, maxval=max_stop_size, dtype=tf.float32)\n",
    "    #entry_size = LTF_PA[-1, 1] + 0.01\n",
    "    \n",
    "    stop = -entry_size    \n",
    "    target = entry_size * RR\n",
    "    \n",
    "    trade_result = check_reaction(future_PA, entry=0.0, stop=stop, RR=RR)   # entry always at 0.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ################# Now create embeddings\n",
    "    indices_embedding = tf.cast(tf.expand_dims(tf.range(sequence_length) / sequence_length, axis=-1), tf.float32)\n",
    "    \n",
    "    LTF_embedding = tf.concat([LTF_PA, indices_embedding], axis=-1)\n",
    "    HTF_embedding = tf.concat([HTF_PA, indices_embedding], axis=-1)\n",
    "    \n",
    "    return HTF_embedding, LTF_embedding, trade_result, tf.stack([stop, target])        #prices_embedding     #tf.stack([entry, stop])       #, unaugmented_PA\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#HTF_PA, LTF_PA, trade_result, levels = get_random_trade(M15_candles)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"BEGIN TEST   \\n\\n\")\n",
    "\n",
    "x = get_random_seq(M15_candles)\n",
    "x = tf.expand_dims(x, axis=0)\n",
    "\n",
    "dyn = DynamicIntervals(512, min_TF=3, max_TF=40)\n",
    "ratio = RatioAugment()\n",
    "\n",
    "x1 = dyn(x)\n",
    "x2 = dyn(x)\n",
    "\n",
    "N_augment = 5\n",
    "\n",
    "#for i in range(N_augment):\n",
    "#    x1 = ratio(x1)\n",
    "\n",
    "#for i in range(N_augment):\n",
    "#    x2 = ratio(x2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1 = x1[0]\n",
    "x2 = x2[0]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "plt.plot(x1[0], color=\"blue\")\n",
    "plt.plot(x2[0], color=\"red\")\n",
    "\n",
    "for i in range(x1.shape[0]):\n",
    "    plt.plot((i, i), (x1[i, 0], x1[i, 1]), color=\"blue\")\n",
    "    plt.plot((i, i), (x2[i, 0], x2[i, 1]), color=\"red\")\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.7642336  0.8009724 ]\n",
      " [0.76675844 0.78413993]\n",
      " [0.7642336  0.8009724 ]\n",
      " [0.77178067 0.77675796]\n",
      " [0.75400853 0.7816905 ]\n",
      " [0.77427495 0.7816905 ]\n",
      " [0.76675844 0.7816905 ]\n",
      " [0.751424   0.7816905 ]\n",
      " [0.7616942  0.77178067]\n",
      " [0.7642336  0.7914187 ]\n",
      " [0.76675844 0.7865754 ]\n",
      " [0.7792298  0.78900266]\n",
      " [0.7692752  0.7816905 ]\n",
      " [0.77675796 0.7792298 ]\n",
      " [0.76675844 0.7792298 ]\n",
      " [0.751424   0.77178067]\n",
      " [0.75400853 0.75400853]\n",
      " [0.75400853 0.75400853]\n",
      " [0.75400853 0.75400853]\n",
      " [0.75400853 0.75400853]\n",
      " [0.75400853 0.75400853]\n",
      " [0.75400853 0.82181937]\n",
      " [0.8126638  0.8285742 ]\n",
      " [0.7914187  0.8195463 ]\n",
      " [0.7816905  0.78900266]\n",
      " [0.77178067 0.7816905 ]\n",
      " [0.7642336  0.7792298 ]\n",
      " [0.7616942  0.77427495]\n",
      " [0.77427495 0.77675796]\n",
      " [0.77427495 0.7938238 ]\n",
      " [0.77427495 0.79860055]\n",
      " [0.7914187  0.7962176 ]\n",
      " [0.7938238  0.81034684]\n",
      " [0.79860055 0.82181937]\n",
      " [0.7962176  0.82181937]\n",
      " [0.80333036 0.80568016]\n",
      " [0.79860055 0.8126638 ]\n",
      " [0.808019   0.85038555]\n",
      " [0.81726474 0.8285742 ]\n",
      " [0.81034684 0.8285742 ]], shape=(40, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x1[210:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M15 dataset\n",
    "\n",
    "\n",
    "\n",
    "M15_data = tf.data.Dataset.from_tensor_slices([M15_candles])\n",
    "\n",
    "M15_data = (\n",
    "    M15_data.repeat()\n",
    "    .map(get_random_trade, num_parallel_calls=8, deterministic=False)       # get_random_seq_diffusion  get_dummy_seq  get_random_trade\n",
    "    .filter(lambda x,y, result, lvl: tf.reduce_any(tf.equal(result, [0.0, 1.0])))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "M15_test_data = tf.data.Dataset.from_tensor_slices([M15_test_candles])\n",
    "\n",
    "M15_test_data = (\n",
    "    M15_test_data.repeat()\n",
    "    .map(get_random_trade, num_parallel_calls=8, deterministic=False)    \n",
    "    .filter(lambda x,y, result, lvl: tf.reduce_any(tf.equal(result, [0.0, 1.0])))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#M15_data = tf.data.Dataset.zip((M15_data, M15_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kTBJBicAVJRr"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "exp_name = \"test_monte_carlo_8\"\n",
    "\n",
    "                \n",
    "callbacks = [EarlyStopping(monitor='loss',\n",
    "                           patience=400,\n",
    "                           verbose=1,\n",
    "                           mode='min'),\n",
    "             ReduceLROnPlateau(monitor='loss',\n",
    "                               factor=0.1,\n",
    "                               patience=100,\n",
    "                               verbose=1,\n",
    "                               min_delta=0.00001,\n",
    "                               mode='min'),\n",
    "             TerminateOnNaN()]\n",
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir gdrive/Shareddrives/edu_VAD/Anton/VAD_project/logs,   TensorBoard(log_dir= projDir + './logs', histogram_freq=0, write_graph=True)\n",
    "\n",
    "#              ModelCheckpoint(monitor='accuracy',\n",
    "#                             filepath= projDir + 'weights/{}'.format(exp_name) + '_{epoch:04d}.hdf5',\n",
    "#                             save_best_only=False,\n",
    "#                             save_freq=50,      # every 5 epochs\n",
    "#                             save_weights_only=True,\n",
    "#                             mode='max')\n",
    "\n",
    "#encoder.save_weights(projDir + 'encoder_4.hdf5')\n",
    "#predictor.save_weights(projDir + 'predictor_4.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SyQ9j9YjVJRs",
    "outputId": "4a2d8be7-57e7-458c-db4d-52f8db3cbf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32 16 64]\n"
     ]
    }
   ],
   "source": [
    "# Architecture\n",
    "\n",
    "\n",
    "with tf.device(DEVICE):\n",
    "\n",
    "    K.clear_session()\n",
    "    \n",
    "    \n",
    "    class ScaleNorm(Layer):\n",
    "        def __init__(self):\n",
    "            super(ScaleNorm, self).__init__()\n",
    "            \n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, x):\n",
    "            scale = tf.reduce_max(tf.abs(x), axis=0)\n",
    "            return x / (scale + 1e-8)\n",
    "\n",
    "\n",
    "    \n",
    "    class TransformerBlock(Layer):\n",
    "        def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "            super(TransformerBlock, self).__init__()\n",
    "\n",
    "            self.num_heads = num_heads\n",
    "            self.embed_dim = embed_dim\n",
    "            self.ff_dim = ff_dim\n",
    "            self.dropout_rate = rate\n",
    "\n",
    "            self.att = fast_attention.Attention(num_heads=num_heads, hidden_size=embed_dim, attention_dropout=rate)\n",
    "            #self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=rate)\n",
    "            \n",
    "            self.ffn = Sequential(\n",
    "                [Dense(ff_dim, activation=\"ReLU\", kernel_constraint=max_norm(10.0), bias_constraint=max_norm(10.0)),        # LeakyReLU\n",
    "                 Dense(embed_dim, kernel_constraint=max_norm(10.0), bias_constraint=max_norm(10.0)),]\n",
    "            )\n",
    "            self.norm1 = ScaleNorm()\n",
    "            self.norm2 = ScaleNorm()\n",
    "            self.dropout1 = Dropout(rate)\n",
    "            self.dropout2 = Dropout(rate)\n",
    "\n",
    "        @tf.function(jit_compile=False, experimental_follow_type_hints=True)\n",
    "        def call(self, inputs, training=True):\n",
    "            attn_output = self.att(inputs, inputs, bias=None)      # , bias=None\n",
    "            attn_output = self.dropout1(attn_output, training=training)\n",
    "            out1 = self.norm1(inputs + attn_output)                    # layernorm\n",
    "            ffn_output = self.ffn(out1)    \n",
    "            ffn_output = self.dropout2(ffn_output, training=training)\n",
    "            return self.norm2(inputs + out1 + ffn_output)     \n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(TransformerBlock, self).get_config()\n",
    "            cfg.update({'num_heads': self.num_heads,\n",
    "                        'embed_dim': self.embed_dim,\n",
    "                        'ff_dim': self.ff_dim,\n",
    "                        'dropout_rate': self.dropout_rate})\n",
    "            return cfg\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    class PositionEmbedding(Layer):\n",
    "        def __init__(self, maxlen, embed_dim):\n",
    "            super(PositionEmbedding, self).__init__()\n",
    "            self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "            self.maxlen = maxlen\n",
    "\n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, x):\n",
    "            #maxlen = tf.shape(x)[-1]\n",
    "            positions = tf.range(start=0, limit=self.maxlen, delta=1)\n",
    "            positions = self.pos_emb(positions)\n",
    "            return x + positions\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(PositionEmbedding, self).get_config()\n",
    "            cfg.update({'pos_emb': self.pos_emb,\n",
    "                        'maxlen': self.maxlen})\n",
    "            return cfg\n",
    "        \n",
    "        \n",
    "    \n",
    "    class InstanceNorm(Layer):\n",
    "        def __init__(self):\n",
    "            super(InstanceNorm, self).__init__()\n",
    "\n",
    "\n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, x):\n",
    "\n",
    "            return (x - tf.reduce_mean(x, axis=0)) / (tf.math.reduce_std(x, axis=0) + 1e-8)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    def FFT_loss_1D(y_true, y_pred):\n",
    "            \n",
    "        spec1 = tf.signal.fft(tf.cast(y_true, dtype=tf.dtypes.complex64)) / (y_true.shape[-1] ** 0.5)\n",
    "        spec2 = tf.signal.fft(tf.cast(y_pred, dtype=tf.dtypes.complex64)) / (y_pred.shape[-1] ** 0.5)\n",
    "\n",
    "        return  tf.math.reduce_mean(tf.math.log(1.0 + tf.cast(tf.abs(spec1-spec2), dtype=tf.float32))) * 100 \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    class InvertedResidual1D(Layer):\n",
    "        def __init__(self, filters, strides, expansion_factor=2, trainable=True,\n",
    "                    name=None, **kwargs):\n",
    "            super(InvertedResidual1D, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "            self.filters = filters\n",
    "            self.strides = strides\n",
    "            self.expansion_factor = expansion_factor\t# allowed to be decimal value\n",
    "            self.act = tf.nn.leaky_relu  #tf.nn.leaky_relu\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            input_channels = int(input_shape[-1])\n",
    "            \n",
    "            l2_reg = 0.0\n",
    "            \n",
    "            self.ptwise_conv1 = Conv1D(filters=int(input_channels*self.expansion_factor), kernel_size=1, use_bias=True, \n",
    "                                       kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "        \n",
    "            self.dwise = DepthwiseConv1D(kernel_size=3, strides=self.strides, padding='same', use_bias=True, \n",
    "                                        kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "            \n",
    "            self.ptwise_conv2 = Conv1D(filters=self.filters, kernel_size=1, use_bias=True, \n",
    "                                       kernel_constraint=max_norm(6.0), bias_constraint=max_norm(6.0))\n",
    "\n",
    "            self.bn1 = ScaleNorm()\n",
    "            self.bn2 = ScaleNorm()\n",
    "            self.bn3 = ScaleNorm()\n",
    "            \n",
    "            self.dropout1 = Dropout(0.1)\n",
    "            self.dropout2 = Dropout(0.1)\n",
    "            \n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, input_x):\n",
    "\n",
    "            x = self.ptwise_conv1(input_x)\n",
    "            x = self.dropout1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.act(x)\n",
    "            \n",
    "            x = self.dwise(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.act(x)\n",
    "\n",
    "            x = self.ptwise_conv2(x)\n",
    "\n",
    "\n",
    "            if input_x.shape[1:] == x.shape[1:]:\n",
    "                x = x + input_x                     #self.bn3(x + input_x)\n",
    "            return x\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(InvertedResidual1D, self).get_config()\n",
    "            cfg.update({'filters': self.filters,\n",
    "                        'strides': self.strides,\n",
    "                        'expansion_factor': self.expansion_factor})\n",
    "            return cfg\n",
    "        \n",
    "        \n",
    "        \n",
    "    class ResConv1D(Layer):\n",
    "        def __init__(self, filters, trainable=True,\n",
    "                    name=None, **kwargs):\n",
    "            super(ResConv1D, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "            self.filters = filters\n",
    "            self.act = tf.nn.relu  #tf.nn.leaky_relu\n",
    "\n",
    "        def build(self, input_shape):\n",
    "                       \n",
    "            \n",
    "            self.residual = Conv1D(filters=self.filters, kernel_size=1, use_bias=True, \n",
    "                                       kernel_constraint=max_norm(12.0), bias_constraint=max_norm(12.0))\n",
    "            \n",
    "            self.conv = Conv1D(filters=self.filters, kernel_size=3, use_bias=True, padding=\"SAME\",\n",
    "                                       kernel_constraint=max_norm(12.0), bias_constraint=max_norm(12.0))\n",
    "            \n",
    "\n",
    "            self.norm = ScaleNorm()\n",
    "\n",
    "        def call(self, input_x):\n",
    " \n",
    "            x = self.conv(input_x)\n",
    "            \n",
    "            if input_x.shape[1] == x.shape[1]:\n",
    "                x += self.residual(input_x)\n",
    "            \n",
    "            x = self.norm(x)\n",
    "            x = self.act(x)\n",
    "        \n",
    "            return x\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(ResConv1D, self).get_config()\n",
    "            cfg.update({'filters': self.filters})\n",
    "            return cfg\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class RandomMask(Layer):\n",
    "        def __init__(self, maxLen=64, masked_rate=0.75):\n",
    "            super(RandomMask, self).__init__()\n",
    "\n",
    "            self.maskedRate = masked_rate\n",
    "            self.maxLen = maxLen\n",
    "            self.trainable = False\n",
    " \n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, inputs, training=None):\n",
    "            \n",
    "            batch_size = tf.shape(inputs)[-3]   # or 0 ?\n",
    "            mask = tf.random.uniform(shape=(batch_size, self.maxLen,), minval=0.0, maxval=1.0, dtype=model_dtype)      # stateless_uniform\n",
    "            mask = tf.cast(tf.math.greater(mask, self.maskedRate), dtype=model_dtype) \n",
    "            \n",
    "            mask = tf.expand_dims(mask, axis=-1)\n",
    "            mask = tf.tile(mask, multiples=(1, 1, tf.shape(inputs)[-1]))        # expand the last dimension\n",
    "            \n",
    "            if training: \n",
    "                return tf.math.multiply(inputs, mask), mask\n",
    "            \n",
    "            return inputs, tf.ones(tf.shape(inputs))        # ones = no mask\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(RandomMask, self).get_config()\n",
    "            cfg.update({'maskedRate': self.maskedRate,\n",
    "                        'maxLen': self.maxLen})\n",
    "            return cfg\n",
    "        \n",
    "    \n",
    "    class RestoreUnmaskedTokens(Layer):\n",
    "        def __init__(self, maxLen=64):\n",
    "            super(RestoreUnmaskedTokens, self).__init__()\n",
    "\n",
    "            self.maxLen = maxLen\n",
    "            self.trainable = False\n",
    "\n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, inputs, training=None):\n",
    "            \n",
    "            reconstructed, original, mask = inputs\n",
    "            \n",
    "            rec = tf.math.multiply(reconstructed, 1.0 - mask)\n",
    "            remain = tf.math.multiply(original, mask)\n",
    "            \n",
    "            if training: \n",
    "                return rec + remain\n",
    "            \n",
    "            return reconstructed\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(RestoreUnmaskedTokens, self).get_config()\n",
    "            cfg.update({'maxLen': self.maxLen})\n",
    "            return cfg\n",
    "        \n",
    "        \n",
    "    \n",
    "    class ConstantLayer(Layer):\n",
    "        def __init__(self, latent_len = 128, embed_dim = 64, trainable=True, name=None, **kwargs):\n",
    "            super(ConstantLayer, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "            self.latent_len = latent_len\n",
    "            self.embed_dim = embed_dim\n",
    "\n",
    "        def build(self, input_shape):\n",
    "\n",
    "            self.latent_array = self.add_weight(\n",
    "                shape=(self.latent_len, self.embed_dim),\n",
    "                initializer=\"random_normal\",\n",
    "                trainable=True,\n",
    "            )                           \n",
    "            \n",
    "            \n",
    "        def call(self, input_x):\n",
    "            bs = tf.shape(input_x)[0]\n",
    "            x = tf.expand_dims(self.latent_array, axis=0)\n",
    "            \n",
    "            return tf.tile(x, multiples=(bs, 1, 1))\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(ConstantLayer, self).get_config()\n",
    "            cfg.update({'latent_len': self.latent_len, \n",
    "                        'embed_dim': self.embed_dim})\n",
    "            return cfg\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    class FourierEmbeddingLayer(Layer):\n",
    "        def __init__(self, embed_dim = 8, trainable=False, name=None, **kwargs):\n",
    "            super(FourierEmbeddingLayer, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "            self.embed_dim = embed_dim // 2\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            channel_count = input_shape[-1]\n",
    "            self.input_len = input_shape[-2]  # sequence length\n",
    "            \n",
    "            self.w = tf.range(self.embed_dim, delta=1, dtype=tf.float32)\n",
    "            self.w = tf.math.pow(2.0, self.w)                         # 1, 2, 4, 8...\n",
    "            \n",
    "            self.w = tf.reshape(self.w, [1, 1, 1, -1])       # set batch size to 1, this tensor will be tiled at runtime.    #tf.expand_dims(self.w, axis=0)\n",
    "            self.w = tf.tile(self.w, multiples=(1, self.input_len, channel_count, 1)) \n",
    "                  \n",
    "            \n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, seq):\n",
    "            batch_size = tf.shape(seq)[0]\n",
    "            channel_count = tf.shape(seq)[-1]\n",
    "\n",
    "            x = tf.cast(seq * 2.0 * 3.14159265358, dtype=tf.float32)   # 0...2PI\n",
    "\n",
    "            x = tf.expand_dims(x, axis=-1)\n",
    "            x = tf.tile(x, multiples=(1, 1, 1, self.embed_dim))  # expand [..., channels, 1] to [..., channels, emb_dim]\n",
    "            \n",
    "            w = tf.tile(self.w, multiples=(batch_size, 1, 1, 1)) # adjust for batch size\n",
    "\n",
    "            seq = tf.concat([tf.math.sin(x * self.w), tf.math.cos(x * self.w)], -1)\n",
    "            seq = tf.reshape(seq, [batch_size, self.input_len, channel_count*self.embed_dim*2])\n",
    "            \n",
    "            return seq\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(FourierEmbeddingLayer, self).get_config()\n",
    "            cfg.update({'input_len': self.latent_len, \n",
    "                        'embed_dim': self.embed_dim})\n",
    "            return cfg\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    class AttentionPooling(Layer):\n",
    "        def __init__(self, embed_dim=64, sequence_len=128, heads=4, trainable=True, name=None, **kwargs):\n",
    "            super(AttentionPooling, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "            self.sequence_len = sequence_len\n",
    "            self.embed_dim = embed_dim\n",
    "            self.heads = heads\n",
    "            \n",
    "            self.att = MultiHeadAttention(num_heads=heads, key_dim=embed_dim)\n",
    "            self.ffn = Sequential(\n",
    "                [Dense(embed_dim*2, activation=\"ReLU\", kernel_constraint=max_norm(10.0), bias_constraint=max_norm(10.0)),        # LeakyReLU\n",
    "                 Dense(embed_dim, kernel_constraint=max_norm(10.0), bias_constraint=max_norm(10.0)),]\n",
    "            )\n",
    "            self.layernorm = LayerNormalization(epsilon=1e-6)\n",
    "            \n",
    "\n",
    "        def build(self, input_shape):\n",
    "\n",
    "            self.latent_array = self.add_weight(\n",
    "                shape=(self.sequence_len, self.embed_dim),\n",
    "                initializer=\"random_normal\",\n",
    "                trainable=True,\n",
    "            )                           \n",
    "            \n",
    "        @tf.function(jit_compile=False)\n",
    "        def call(self, x):\n",
    "            batch_size = tf.shape(x)[0]\n",
    "\n",
    "            const = tf.expand_dims(self.latent_array, axis=0)\n",
    "            \n",
    "            const = tf.tile(const, multiples=(batch_size, 1, 1))\n",
    "\n",
    "            x = self.att(const, x)\n",
    "            \n",
    "            return self.layernorm(x + self.ffn(x))\n",
    "            \n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            cfg = super(AttentionPooling, self).get_config()\n",
    "            cfg.update({'sequence_len': self.sequence_len, \n",
    "                        'embed_dim': self.embed_dim, \n",
    "                        'heads': self.heads})\n",
    "            return cfg\n",
    "        \n",
    "\n",
    "\n",
    "emb = AttentionPooling(embed_dim=64, sequence_len=16, heads=4)      \n",
    "\n",
    "x = tf.zeros([32, 128, 64])\n",
    "\n",
    "x = emb(x)\n",
    "\n",
    "tf.print(tf.shape(x))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_54 (InputLayer)       [(None, 128, 3)]          0         \n",
      "                                                                 \n",
      " fourier_embedding_layer_25   (None, 128, 24)          0         \n",
      " (FourierEmbeddingLayer)                                         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 64)                196672    \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,832\n",
      "Trainable params: 200,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################ encoder\n",
    "\n",
    "\n",
    "inp_dim = 3\n",
    "\n",
    "sequence_length = 128\n",
    "embed_dim = 32\n",
    "fourier_dim = 8\n",
    "\n",
    "patch_size = 4\n",
    "\n",
    "\n",
    "################################\n",
    "inp = Input(shape=[sequence_length, inp_dim])\n",
    "x = inp    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = FourierEmbeddingLayer(embed_dim=fourier_dim)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "#x = InvertedResidual1D(16, 1, expansion_factor=4)(x)\n",
    "#x = InvertedResidual1D(16, 2, expansion_factor=4)(x)\n",
    "\n",
    "#x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)\n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)\n",
    "\n",
    "x = Dense(64, activation = 'LeakyReLU')(x)\n",
    "\n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)\n",
    "x = Dense(64, activation = 'LeakyReLU')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x = InvertedResidual1D(32, 2, expansion_factor=2)(x)\n",
    "\n",
    "#x = InvertedResidual1D(32, 2, expansion_factor=2)(x)\n",
    "\n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)\n",
    "#x = Dense(64, activation = 'LeakyReLU')(x)\n",
    "#x = PositionEmbedding(sequence_length // patch_size, 64)(x)\n",
    "\n",
    "#x = TransformerBlock(64, 2, 128)(x)\n",
    "#x = TransformerBlock(64, 2, 128)(x)\n",
    "#x = TransformerBlock(64, 2, 128)(x)\n",
    "#x = AttentionPooling(embed_dim=embed_dim, sequence_len=32, heads=4)(x)\n",
    "\n",
    "#x = Dense(out_dim, activation = 'LeakyReLU')(x)\n",
    "\n",
    "#x = GlobalAveragePooling1D()(x)\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "#x = LayerNormalization()(x)\n",
    "\n",
    "#x = Flatten()(x)\n",
    "#x = LayerNormalization()(x)\n",
    "\n",
    "\n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outp = x\n",
    "\n",
    "encoder = Model(inp, outp, name=\"encoder\")\n",
    "\n",
    "\n",
    "\n",
    "#encoder.compile(optimizer=opt, loss=FFT_loss_1D, metrics=[tf.keras.metrics.MeanSquaredError(), FFT_loss_1D])     # tf.keras.losses.MSE\n",
    "encoder.build(input_shape=[None, sequence_length, inp_dim])\n",
    "#encoder.load_weights('encoder_5.hdf5', by_name=True, skip_mismatch=True) \n",
    "\n",
    "#encoder.layers[2].trainable = False  # Freeze the layer\n",
    "#encoder.trainable = False\n",
    "\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"predictor\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_57 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " reshape_14 (Reshape)           (None, 1, 2)         0           ['input_57[0][0]']               \n",
      "                                                                                                  \n",
      " fourier_embedding_layer_26 (Fo  (None, 1, 16)       0           ['reshape_14[0][0]']             \n",
      " urierEmbeddingLayer)                                                                             \n",
      "                                                                                                  \n",
      " dense_154 (Dense)              (None, 1, 32)        544         ['fourier_embedding_layer_26[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " input_55 (InputLayer)          [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " input_56 (InputLayer)          [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_155 (Dense)              (None, 1, 32)        1056        ['dense_154[0][0]']              \n",
      "                                                                                                  \n",
      " dense_152 (Dense)              (None, 16)           1040        ['input_55[0][0]']               \n",
      "                                                                                                  \n",
      " dense_153 (Dense)              (None, 16)           1040        ['input_56[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_22 (Flatten)           (None, 32)           0           ['dense_155[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 64)           0           ['dense_152[0][0]',              \n",
      "                                                                  'dense_153[0][0]',              \n",
      "                                                                  'flatten_22[0][0]']             \n",
      "                                                                                                  \n",
      " scale_norm_18 (ScaleNorm)      (None, 64)           0           ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " dense_156 (Dense)              (None, 64)           4160        ['scale_norm_18[0][0]']          \n",
      "                                                                                                  \n",
      " dense_157 (Dense)              (None, 32)           2080        ['dense_156[0][0]']              \n",
      "                                                                                                  \n",
      " dense_158 (Dense)              (None, 1)            33          ['dense_157[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,953\n",
      "Trainable params: 9,953\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################ predictor\n",
    "\n",
    "inp_dim = 64\n",
    "\n",
    "inp1 = Input(shape=[inp_dim])\n",
    "inp2 = Input(shape=[inp_dim])\n",
    "#inp3 = Input(shape=[inp_dim])\n",
    "\n",
    "levels = Input(shape=[2])\n",
    "\n",
    "\n",
    "x1 = Dense(16, activation = 'LeakyReLU')(inp1)\n",
    "#x1 = Dense(128, activation = 'LeakyReLU')(x1)\n",
    "#x1 = Dense(64, activation = 'LeakyReLU')(x1)\n",
    "\n",
    "x2 = Dense(16, activation = 'LeakyReLU')(inp2)\n",
    "#x2 = Dense(128, activation = 'LeakyReLU')(x2)\n",
    "#x2 = Dense(64, activation = 'LeakyReLU')(x2)\n",
    "\n",
    "\n",
    "price_emb = Reshape([1, 2])(levels)\n",
    "price_emb = FourierEmbeddingLayer(embed_dim=8)(price_emb)\n",
    "\n",
    "price_emb = Dense(32, activation = 'LeakyReLU')(price_emb)\n",
    "price_emb = Dense(32, activation = 'LeakyReLU')(price_emb)\n",
    "price_emb = Flatten()(price_emb)\n",
    "\n",
    "\n",
    "x = Concatenate(axis=-1)([x1, x2, price_emb]) \n",
    "x = ScaleNorm()(x)\n",
    "\n",
    "#x = Dense(256, activation = 'LeakyReLU')(x)\n",
    "#x = Dense(128, activation = 'LeakyReLU')(x)\n",
    "#x = ScaleNorm()(x)\n",
    "\n",
    "x = Dense(64, activation = 'LeakyReLU')(x)\n",
    "x = Dense(32, activation = 'LeakyReLU')(x)\n",
    "x = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "outp = x\n",
    "\n",
    "predictor = Model([inp1, inp2, levels], outp, name=\"predictor\")\n",
    "\n",
    "\n",
    "\n",
    "#encoder.compile(optimizer=opt, loss=FFT_loss_1D, metrics=[tf.keras.metrics.MeanSquaredError(), FFT_loss_1D])     # tf.keras.losses.MSE\n",
    "predictor.build(input_shape=[[None, inp_dim], [None, inp_dim], [None, 2]])\n",
    "#predictor.load_weights('predictor_5.hdf5', by_name=True, skip_mismatch=True) \n",
    "\n",
    "predictor.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ae_model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Functional)        (None, 64)                200832    \n",
      "                                                                 \n",
      " predictor (Functional)      (None, 1)                 9953      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 210,785\n",
      "Trainable params: 210,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AEModel(keras.Model):\n",
    "\n",
    "    def __init__(self, encoder, predictor):\n",
    "        super(AEModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.predictor = predictor\n",
    "        #self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "\n",
    "    #@property\n",
    "    #def metrics(self):\n",
    "    #    return [self.loss_tracker]\n",
    "    \n",
    "    \n",
    "    \n",
    "    @tf.function(jit_compile=False)\n",
    "    def call(self, inp):\n",
    "        \n",
    "        HTF, LTF, levels = inp\n",
    "        \n",
    "        enc_HTF = self.encoder(HTF, training=False)\n",
    "        #enc_MTF = self.encoder(MTF, training=False)\n",
    "        enc_LTF = self.encoder(LTF, training=False)\n",
    "        \n",
    "        pred = self.predictor([enc_HTF, enc_LTF, levels], training=False)\n",
    "        \n",
    "        return pred         \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    @tf.function(jit_compile=False)\n",
    "    def train_step(self, batch):\n",
    "\n",
    "        HTF, LTF, result, levels = batch \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_HTF = self.encoder(HTF, training=True)\n",
    "            #enc_MTF = self.encoder(MTF, training=True)\n",
    "            enc_LTF = self.encoder(LTF, training=True)\n",
    "            \n",
    "            pred = self.predictor([enc_HTF, enc_LTF, levels], training=True)\n",
    "            \n",
    "            loss = self.compiled_loss(result, pred)   \t\t#self.loss(result, pred), regularization_losses=self.losses   \n",
    "            \n",
    "            #loss += sum(self.encoder.losses) + sum(self.predictor.losses)   # Add any extra losses created during the forward pass.\n",
    "\n",
    "  \n",
    "        learnable_params = (self.encoder.trainable_variables \n",
    "                            + self.predictor.trainable_variables)\n",
    "\n",
    "        grads_model = tape.gradient(loss, learnable_params)\n",
    "        self.optimizer.apply_gradients(zip(grads_model, learnable_params))\n",
    "        \n",
    "        #self.loss_tracker.update_state(loss)\n",
    "\n",
    "        self.compiled_metrics.update_state(result, pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\t\t\n",
    "        #return {\"loss\": self.loss_tracker.result()}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = AEModel(encoder, predictor)\n",
    "\n",
    "class GCLAMB(LAMB):\n",
    "    def get_gradients(self, loss, params):  # gradient centralization\n",
    "        grads = []\n",
    "        gradients = super().get_gradients()\n",
    "        for grad in gradients:\n",
    "            grad_len = len(grad.shape)\n",
    "            if grad_len > 1:\n",
    "                axis = list(range(grad_len - 1))\n",
    "                grad -= tf.reduce_mean(grad, axis=axis, keep_dims=True)\n",
    "            grads.append(grad)\n",
    "\n",
    "        return grads\n",
    "\n",
    "\n",
    "#SWA = tfa.optimizers.SWA\n",
    "opt = GCLAMB(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.binary_crossentropy, metrics=[keras.metrics.Recall(thresholds=0.333333), \n",
    "                                                                      keras.metrics.Precision(thresholds=0.333333), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  keras.metrics.TruePositives(thresholds=0.4), \n",
    "                                                                      keras.metrics.FalsePositives(thresholds=0.4)])     # tf.keras.losses.binary_crossentropy, tf.keras.losses.MSE, tf.keras.losses.MeanAbsoluteError(), FFT_loss_1D\n",
    "model.build(input_shape=[[None, sequence_length, 3], [None, sequence_length, 3], [None, 2]])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "class SAMModel(tf.keras.Model):\n",
    "    def __init__(self, orig_model, rho=0.05):\n",
    "        \"\"\"\n",
    "        p, q = 2 for optimal results as suggested in the paper\n",
    "        (Section 2)\n",
    "        \"\"\"\n",
    "        super(SAMModel, self).__init__()\n",
    "        self.orig_model = orig_model\n",
    "        self.rho = rho\n",
    "\n",
    "    @tf.function(jit_compile=False)\n",
    "    def train_step(self, data):\n",
    "        #(images, labels) = data\n",
    "        HTF, LTF, result, levels = data \n",
    "        inp = [HTF, LTF, levels]\n",
    "        \n",
    "        e_ws = []\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.orig_model(inp, training=True)\n",
    "            loss = self.compiled_loss(result, predictions)\n",
    "\t\t\t\n",
    "        trainable_params = self.orig_model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_params)\n",
    "        grad_norm = self._grad_norm(gradients)\n",
    "        scale = self.rho / (grad_norm + 1e-12)\n",
    "\n",
    "        for (grad, param) in zip(gradients, trainable_params):\n",
    "            e_w = grad * scale\n",
    "            param.assign_add(e_w)\n",
    "            e_ws.append(e_w)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.orig_model(inp, training=True)\n",
    "            loss = self.compiled_loss(result, predictions)    \n",
    "        \n",
    "        sam_gradients = tape.gradient(loss, trainable_params)\n",
    "        for (param, e_w) in zip(trainable_params, e_ws):\n",
    "            param.assign_sub(e_w)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(sam_gradients, trainable_params))\n",
    "        \n",
    "        self.compiled_metrics.update_state(result, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "        (images, labels) = data\n",
    "        predictions = self.orig_model(images, training=False)\n",
    "        loss = self.compiled_loss(labels, predictions)\n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def _grad_norm(self, gradients):\n",
    "        norm = tf.norm(\n",
    "            tf.stack([\n",
    "                tf.norm(grad) for grad in gradients if grad is not None\n",
    "            ])\n",
    "        )\n",
    "        return norm\n",
    "\t\t\n",
    "  \n",
    "\n",
    "SAM_model = SAMModel(model)\n",
    "SAM_model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[keras.metrics.Recall(thresholds=0.6), \n",
    "                                                                      keras.metrics.Precision(thresholds=0.6), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  keras.metrics.TruePositives(thresholds=0.6), \n",
    "                                                                      keras.metrics.FalsePositives(thresholds=0.6)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor l in model.layers:\\n    print(lay.name, lay.output_shape)\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#x = InvertedResidual(64, (1, 1), expansion_factor=6)(x)\n",
    "#kernel_constraint=max_norm(2.0)\n",
    "#x = Conv2DTranspose(32, kernel_size=(3, inp_dim), strides=(2, 1), activation=\"LeakyReLU\", kernel_regularizer=l1(l1_reg), bias_regularizer=l1(l1_reg), padding=\"SAME\")(x)\n",
    "#x = Conv2D(32, (3, inp_dim), activation=\"LeakyReLU\", kernel_regularizer=l1(l1_reg), bias_regularizer=l1(l1_reg), padding=\"same\")(x)\n",
    "#x = Conv2DTranspose(1, kernel_size=1, strides=1, activation=\"linear\", padding=\"SAME\", dtype='float32')(x)\n",
    "#x = Cropping1D([0, predict_len])(x)\n",
    "#x = GlobalAveragePooling1D()(x)\n",
    "# Dense(32, activation = 'LeakyReLU', kernel_regularizer=l2(0.01))\n",
    "# Reshape([64, 129])\n",
    "# Conv1D(32, 9, activation='relu', input_shape=[129])\n",
    "# Dropout(p)\n",
    "# BatchNormalization()\n",
    "# Permute((2, 1), input_shape=(64, 129))\n",
    "# LSTM(64, return_sequences = True)\n",
    "# Flatten()\n",
    "# GRU(64, return_sequences = True)\n",
    "# Concatenate(axis=1)([x, y]) \n",
    "# Reshape([-1, 128])(inp)\n",
    "#x = Rescaling(scale=1.0/255.0)(x)\n",
    "#outp = tf.cast(x, tf.dtypes.float16) # Rescaling(scale=255.0)(x)\n",
    "#x = GaussianNoise(0.2)(x)\n",
    "#x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "#outp = Dense(len(POSSIBLE_LABELS), activation=\"softmax\")(x)\n",
    "#x = PositionEmbedding(timesteps, embed_dim)(x)\n",
    "#x = RandomMask(maxLen=timesteps, masked_rate=0.3)(x)\n",
    "#x = RestoreUnmaskedTokens()([x, mask_input, mask])\n",
    "#x = RepeatVector(28, input_shape=[30])(x)  # 28x vector\n",
    "#x = TimeDistributed(Dense(28, activation=\"sigmoid\"))(x)\n",
    "#x = ActivityRegularization(l1=1e-3)(x)\n",
    "#x = Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"SAME\", activation=\"selu\")\n",
    "\n",
    "#print(x.shape)\n",
    "\n",
    "\"\"\"\n",
    "for l in model.layers:\n",
    "    print(lay.name, lay.output_shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk5nmX20VJRt",
    "outputId": "e65aa96d-6b75-4add-e5ae-11f41151e1d1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "377/500 [=====================>........] - ETA: 15s - loss: 0.6963 - recall_32: 0.9998 - precision_32: 0.4985 - true_positives_32: 11892.0000 - false_positives_32: 11961.0000\n",
      " Interrupted\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "gc.collect()\n",
    "\n",
    "K.set_value(model.optimizer.learning_rate, 0.0001)\n",
    "batch_size = 64\n",
    "\n",
    "try:\n",
    "    batched_DS = M15_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    hist = model.fit(batched_DS, callbacks=callbacks,\n",
    "                    batch_size = batch_size, epochs = 4000, steps_per_epoch = 500)  # initial_epoch , validation_data=(valX[:32], valX[:32])\n",
    "    \n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.title(\"Loss curve\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n Interrupted\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model.save_weights(projDir + 'weights/test_2.hdf5')\n",
    "#model.save(projDir + 'models/' + exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZD2Uw1o-pR-",
    "outputId": "0dca2785-bb43-4a0c-854d-290329fd07ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset\n",
      "Dataset prepared\n",
      "Successful trades: 63669 out of 128000 trades\n",
      "Lost trades: 64331 out of 128000 trades\n",
      "Can't tell cases: 0\n",
      "Real successful trades ratio: 0.497414052 \n",
      "\n",
      "\n",
      "Min/max probability of taken trades 0.528877735 0.593997121\n",
      "NN wins 6515 out of 12800\n",
      "Winrate: 50.8984375 %\n"
     ]
    }
   ],
   "source": [
    "# Eval on train dataset\n",
    "\n",
    "BS = 128000\n",
    "\n",
    "batched_DS = M15_data.batch(BS)\n",
    "\n",
    "\n",
    "\n",
    "tf.print(\"Generating dataset\")\n",
    "for i in batched_DS.take(1):        # only one batch\n",
    "    HTF_PA = i[0]\n",
    "    LTF_PA = i[1]\n",
    "    res = i[2]\n",
    "    levels = i[3]\n",
    "    \n",
    "tf.print(\"Dataset prepared\")\n",
    "\n",
    "\n",
    "win_probs_orig = tf.cast(tf.squeeze(res[:] > 0.99), tf.float32)      # only 0 or 1\n",
    "loss_probs_orig = tf.cast(tf.squeeze(res[:] < 0.01), tf.float32)      # only 0 or 1\n",
    "\n",
    "wins = tf.reduce_sum(win_probs_orig)\n",
    "losses = tf.reduce_sum(loss_probs_orig)\n",
    "    \n",
    "tf.print(\"Successful trades:\", wins, \"out of\", BS, \"trades\")\n",
    "tf.print(\"Lost trades:\", losses, \"out of\", BS, \"trades\")\n",
    "tf.print(\"Can't tell cases:\", BS - wins - losses)\n",
    "\n",
    "tf.print(\"Real successful trades ratio:\", wins / (wins + losses), \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "take_trade_ratio = 0.1\n",
    "\n",
    "\n",
    "\n",
    "prediction = model([HTF_PA, LTF_PA, levels], training=True)\n",
    "\n",
    "win_probs_pred = tf.squeeze(prediction[:, 0]) \n",
    "result = tf.math.top_k(win_probs_pred, sorted=False, k=int(BS * take_trade_ratio)).values\n",
    "\n",
    "tf.print(\"Min/max probability of taken trades\", tf.reduce_min(result), tf.reduce_max(result))\n",
    "\n",
    "\n",
    "mask = tf.cast(win_probs_pred > tf.reduce_min(result), tf.float32)\n",
    "win_count = tf.reduce_sum(win_probs_orig * mask)\n",
    "\n",
    "\n",
    "tf.print(\"NN wins\", win_count, \"out of\", int(BS * take_trade_ratio))\n",
    "tf.print(\"Winrate:\", win_count / int(BS * take_trade_ratio) * 100.0, \"%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset\n",
      "Dataset prepared\n",
      "Successful trades: 7940 out of 16000 trades\n",
      "Lost trades: 8060 out of 16000 trades\n",
      "Can't tell cases: 0\n",
      "Real successful trades ratio: 0.49625 \n",
      "\n",
      "\n",
      "Min/max probability of taken trades 0.560781598 0.63259685\n",
      "[3655 14859 1580 ... 9628 5419 15733]\n",
      "NN wins 106 out of 160\n",
      "Winrate: 66.25 %\n"
     ]
    }
   ],
   "source": [
    "# Eval on test dataset\n",
    "\n",
    "BS = 16000\n",
    "\n",
    "batched_DS = M15_test_data.batch(BS)\n",
    "\n",
    "\n",
    "\n",
    "tf.print(\"Generating dataset\")\n",
    "for i in batched_DS.take(1):        # only one batch\n",
    "    HTF_PA = i[0]\n",
    "    LTF_PA = i[1]\n",
    "    res = i[2]\n",
    "    levels = i[3]\n",
    "    \n",
    "tf.print(\"Dataset prepared\")\n",
    "\n",
    "\n",
    "win_probs_orig = tf.cast(tf.squeeze(res[:] > 0.99), tf.float32)      # only 0 or 1\n",
    "loss_probs_orig = tf.cast(tf.squeeze(res[:] < 0.01), tf.float32)      # only 0 or 1\n",
    "\n",
    "wins = tf.reduce_sum(win_probs_orig)\n",
    "losses = tf.reduce_sum(loss_probs_orig)\n",
    "    \n",
    "tf.print(\"Successful trades:\", wins, \"out of\", BS, \"trades\")\n",
    "tf.print(\"Lost trades:\", losses, \"out of\", BS, \"trades\")\n",
    "tf.print(\"Can't tell cases:\", BS - wins - losses)\n",
    "\n",
    "tf.print(\"Real successful trades ratio:\", wins / (wins + losses), \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "take_trade_ratio = 0.01\n",
    "\n",
    "\n",
    "\n",
    "prediction = model([HTF_PA, LTF_PA, levels], training=True)\n",
    "\n",
    "win_probs_pred = tf.squeeze(prediction[:, 0]) \n",
    "\n",
    "\n",
    "result = tf.math.top_k(win_probs_pred, sorted=False, k=int(BS * take_trade_ratio))\n",
    "win_indices = result.indices\n",
    "\n",
    "tf.print(\"Min/max probability of taken trades\", tf.reduce_min(result.values), tf.reduce_max(result.values))\n",
    "\n",
    "\n",
    "mask = tf.cast(win_probs_pred > tf.reduce_min(result.values), tf.float32)\n",
    "simulation_result = win_probs_orig * mask\n",
    "\n",
    "\n",
    "win_count = tf.reduce_sum(simulation_result)\n",
    "tf.print(\"NN wins\", win_count, \"out of\", int(BS * take_trade_ratio))\n",
    "\n",
    "\n",
    "tf.print(\"Winrate:\", win_count / int(BS * take_trade_ratio) * 100.0, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize won trades\n",
    "\n",
    "i = tf.squeeze(tf.random.uniform([], minval=0, maxval=win_indices.shape[0], dtype=tf.int32))  # anchor, where PA ends (where the trade is taken) starts\n",
    "    \n",
    "\n",
    "PA = LTF_PA[i]\n",
    "entry_stop = levels[i]\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.plot((0, PA.shape[0]), (entry_stop[1], entry_stop[1]), color=\"green\")\n",
    "plt.plot((0, PA.shape[0]), (0.0, 0.0), color=\"blue\")\n",
    "plt.plot((0, PA.shape[0]), (entry_stop[0], entry_stop[0]), color=\"red\")\n",
    "\n",
    "for i in range(PA.shape[0]):\n",
    "    plt.plot((i, i), (PA[i, 0], PA[i, 1]), color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins/losses - min: [0.406876326]  max: [0.705797315]\n",
      "Std [0.0620759092]\n"
     ]
    }
   ],
   "source": [
    "#print(prediction)\n",
    "tf.print(\"Wins/losses - min:\", tf.reduce_min(prediction, axis=0), \" max:\", tf.reduce_max(prediction, axis=0))\n",
    "tf.print(\"Std\", tf.math.reduce_std(prediction, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss with noisy targets 0.251463175\n",
      "Loss with real denoised targets 0.0282610357\n",
      "Prediction mean 0.492108047\n"
     ]
    }
   ],
   "source": [
    "# Dummy test\n",
    "\n",
    "\n",
    "BS = 8192\n",
    "\n",
    "batched_DS = M15_data.batch(BS).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "for i in batched_DS.take(1):        # only one batch\n",
    "    x = i[0]\n",
    "    noisy_res = i[1]\n",
    "    res = i[2]\n",
    "\n",
    "\n",
    "\n",
    "prediction = model(x, training=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.print(\"Train loss with noisy targets\", tf.reduce_mean(tf.square(prediction - noisy_res)))\n",
    "tf.print(\"Loss with real denoised targets\", tf.reduce_mean(tf.square(prediction - res)))\n",
    "tf.print(\"Prediction mean\", tf.reduce_mean(prediction))\n",
    "\n",
    "\n",
    "\n",
    "#tf.print(prediction[:6, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "to_denoise, noise, step, orig  = get_random_seq_diffusion(M15_candles)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "\n",
    "for i in range(prediction.shape[0]):\n",
    "    plt.plot((i, i), (to_denoise[i, 0], to_denoise[i, 1]), color=\"blue\")\n",
    "    plt.plot((i, i), (orig[i, 0], orig[i, 1]), color=\"red\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-d0bfb3150a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# eval prediction - show candles\n",
    "\n",
    "def binVec2Float(input, bin_size):\n",
    "    vec = np.power(2.0, np.arange(bin_size-1, -1, -1))\n",
    "\n",
    "    output = []\n",
    "    for i in input:\n",
    "        x = np.round_(i) > 0\n",
    "        output.append(np.dot(vec, x) / 2**bin_size)\n",
    "    \n",
    "    return np.array(output)\n",
    "        \n",
    "        \n",
    "sample = get_random_seq(M15_candles)[0]\n",
    "\n",
    "print(sample.shape)\n",
    "print(tf.expand_dims(sample, axis=-1).shape)\n",
    "\n",
    "prediction = model(tf.expand_dims(sample, axis=0), training=True)[0]\n",
    "#prediction = model.predict(tf.expand_dims(sample, axis=0))[0]\n",
    "print(sample.shape)\n",
    "\n",
    "bin_size = 8\n",
    "N = 3\n",
    "\n",
    "\n",
    "#output_L = binVec2Float(prediction[:, :bin_size], bin_size)\n",
    "#output_H = binVec2Float(prediction[:, bin_size:], bin_size)\n",
    "\n",
    "#real_L = binVec2Float(sample[:, :bin_size], bin_size)\n",
    "#real_H = binVec2Float(sample[:, bin_size:], bin_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(sample.shape[0]):\n",
    "    plt.plot((i, i), (sample[i, 0], sample[i, 1]), color=\"blue\")\n",
    "    plt.plot((i, i), (prediction[i, 0], prediction[i, 1]), color=\"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(10):\n",
    "#    plt.plot(np.squeeze(prediction[i]), color=\"red\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2e7d2ecac0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights\n",
    "\n",
    "\n",
    "encoder.load_weights(\"encoder_RNN_64_3\")\n",
    "#encoder.save_weights(\"encoder_RNN_64_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_random_seq(M15_candles)[0]\n",
    "\n",
    "print(sample.shape)\n",
    "print(tf.expand_dims(sample, axis=-1).shape)\n",
    "\n",
    "prediction = encoder(tf.expand_dims(sample, axis=0), training=True)[0]\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show layers output\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "inp = get_random_seq(M15_candles)\n",
    "inp = tf.convert_to_tensor(inp, tf.float32)\n",
    "\n",
    "mdl = encoder\n",
    "       \n",
    "layer_outputs = [layer.output for layer in mdl.layers[:]] \n",
    "generate = True\n",
    "if generate:\n",
    "    for i, l in enumerate(mdl.layers):\n",
    "        print(i, l.name, l.output_shape)\n",
    "\n",
    "    get_activations = Model(inputs=mdl.input, outputs=layer_outputs)\n",
    "    activations = get_activations.predict(inp)\n",
    "\n",
    "\n",
    "\n",
    "print(\"All activations:\", len(activations))\n",
    "for i in activations:\n",
    "    print(\"Activations:\", i.shape, np.amin(i), np.amax(i))\n",
    "    \n",
    "    \n",
    "    \n",
    "layer_i = 28\n",
    "print((activations[layer_i][0].T).shape)\n",
    "print((activations[layer_i][1].T).shape)\n",
    "\n",
    "x1 = (activations[layer_i][0].T)\n",
    "x2 = (activations[layer_i][1].T)\n",
    "\n",
    "x = [np.array(x1), np.array(x2)]\n",
    "\n",
    "\n",
    "#x = activations[0][0]\n",
    "#print(\"x\", x.shape)\n",
    "\n",
    "#print(\"Min, max: \", np.min(x), np.max(x))\n",
    "#print(\"AE: \", x[0, :24, :24])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(24, 5))\n",
    "\n",
    "plt.stairs(x[0].T, color=\"red\")\n",
    "plt.stairs(x[1].T-x[0].T, color=\"blue\")\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(Y_data, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show output interval\n",
    "\n",
    "print(\"### ENCODER ###\")\n",
    "   \n",
    "layer_outputs = [layer.output for layer in encoder.layers[:]] \n",
    "\n",
    "inp = get_random_seq(M15_candles)\n",
    "inp = tf.convert_to_tensor(inp, tf.float32)\n",
    "\n",
    "\n",
    "generate = True\n",
    "if generate:\n",
    "    get_activations = Model(inputs=encoder.input, outputs=layer_outputs)\n",
    "    activations = get_activations.predict(inp)\n",
    "    \n",
    "print(\"         Min      Max       SqrtVar   \")\n",
    "for i, l in enumerate(encoder.layers):\n",
    "        print(\"Layer\", i, l.name, l.output_shape)\n",
    "        print(\"  \", np.min(activations[i][0]), np.max(activations[i][0]), np.sqrt(np.var(activations[i][0])), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "layer_num = 12\n",
    "x = activations[5:9]\n",
    "print(x[0].shape)\n",
    "\n",
    "aspect_ratio = 64 / 16\n",
    "\n",
    "x_count = 7\n",
    "y_size = 128 / x_count\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(y_size * aspect_ratio, y_size))\n",
    "\n",
    "for i, xr in enumerate(x):\n",
    "    x_shp = x[i][0].shape[0]\n",
    "    y_shp = x[i][0].shape[2]\n",
    "    tmp = tf.reshape(x[i][0], (x_shp, y_shp))\n",
    "    fig.add_subplot(1, 5, i+1)\n",
    "    plt.imshow(tmp, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show kernels\n",
    "\n",
    "\n",
    "mdl = encoder\n",
    "\n",
    "inp = get_random_seq(M15_candles)\n",
    "inp = tf.convert_to_tensor(inp, tf.float32)\n",
    "\n",
    "layer_weights = [layer.weights for layer in mdl.layers[:]] \n",
    "\n",
    "generate = True\n",
    "if generate:\n",
    "    for i, l in enumerate(mdl.layers):\n",
    "        print(i, l.name, l.output_shape)\n",
    "\n",
    "    get_weights_model = Model(inputs=mdl.input, outputs=layer_weights)\n",
    "    weights = get_weights_model.predict(np.expand_dims(inp, axis=0))\n",
    "\n",
    "layer_num = 10\n",
    "\n",
    "weights = layer_weights[2]\n",
    "print(weights)\n",
    "\n",
    "\n",
    "\n",
    "#print(weights[layer_num].shape)\n",
    "\n",
    "x = np.array(weights)[0]\n",
    "x = np.transpose(x, (2, 0, 1, 3))[0]\n",
    "x = np.transpose(x, (2, 1, 0))   # transpose\n",
    "\n",
    "\n",
    "\n",
    "aspect_ratio = 64 / 64\n",
    "\n",
    "x_count = 4\n",
    "y_size = 32 / x_count\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(y_size * aspect_ratio, y_size))\n",
    "\n",
    "for i, xr in enumerate(x):\n",
    "    fig.add_subplot(x.shape[0], x_count, i+1)\n",
    "    plt.imshow(xr, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGruwIc0Q2ad"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "\n",
    "model = load_model(projDir + 'models/' + exp_name)\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "NLLV6JrIMWd_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D71D6A620>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D71D6A620>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D71D6B970>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D71D6B970>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D56AFCDC0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D56AFCDC0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D7729DF90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D7729DF90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D57145510>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D57145510>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D2BA5B0D0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D2BA5B0D0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D2BA5B7F0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D2BA5B7F0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D364F7310>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D364F7310>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D364F7370>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D364F7370>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D364F4880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D364F4880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D364F7580>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.normalization.layer_normalization.LayerNormalization object at 0x0000023D364F7580>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv1d_layer_call_fn, conv1d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv1d_1_layer_call_fn, conv1d_1_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2R_67_percent_inp128x10_outp1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2R_67_percent_inp128x10_outp1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "exp_name = \"2R_67_percent_inp128x10_outp1\"\n",
    "#model.save_weights(projDir + 'weights/' + exp_name + '.hdf5')\n",
    "model.save(projDir + 'models/' + exp_name)\n",
    "\n",
    "#encoder.save_weights(projDir + 'weights/encoder_2048_contrastive.hdf5')\n",
    "#encoder.save(projDir + 'models/encoder_2048_contrastive')\n",
    "\n",
    "\n",
    "print('Saved')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "testing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('TF_GPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "ba4216cb22bdc29773158426727ca107ddd2184d4813108b5037b6e90de98ea2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
